<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Kyle Caron</title>
<link>https://github.com/kylejcaron/kylejcaron.github.io/blog.html</link>
<atom:link href="https://github.com/kylejcaron/kylejcaron.github.io/blog.xml" rel="self" type="application/rss+xml"/>
<description>Welcome to my blog! I'm a self-taught data scientist interested in causal inference and bayesian methods. I mainly use this blog to formalize what I learn, but hopefully others find it helpful as well.</description>
<generator>quarto-1.1.163</generator>
<lastBuildDate>Sun, 09 Jul 2023 04:00:00 GMT</lastBuildDate>
<item>
  <title>Introduction to Surrogate Indexes</title>
  <link>https://github.com/kylejcaron/kylejcaron.github.io/posts/surrogates/2023-07-09-surrogate_index_intro.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>How should you design your experiments if the metric you want to change might take months to observe?</p>
<p>Inspired by <a href="https://www.nber.org/system/files/working_papers/w26463/w26463.pdf">Susan Athey’s paper on Surrogate indexes</a> and another working paper, <a href="https://ide.mit.edu/wp-content/uploads/2020/12/Targeting-for-long-term-outcomes.pdf?x73880">Target for Long Term Outcomes</a>, I’ve wanted to share my learnings about surrogate indexes for a long time.</p>
<p>I’m hoping to cover the following in a series of blog posts:</p>
<ol type="1">
<li><p>The surrogate index estimator</p></li>
<li><p>Surrogate Index in practice</p>
<ul>
<li>Fitting a surrogate index on a realistic dataset</li>
<li>Validating the surrogate index over a set of historical experiments</li>
</ul></li>
<li><p>Targeting Long Term Outcomes</p>
<ul>
<li>Optimizing a policy</li>
<li>Attempting multi-armed bandits for early optimization</li>
</ul></li>
</ol>
<p>By simulating the data generating process from scratch, I hope this can also be a helpful tool for others to build on so they can answer their own questions they may have about estimating Long Term Treatment Effects.</p>
</section>
<section id="background" class="level1">
<h1>Background</h1>
<p><strong>Surrogate indexes</strong> are an unbiased way to predict a long term treatment effect from an experiment, but of course they’re only unbiased if done correctly which is no easy feat.</p>
<p>At Policygenius, customers would take a long time to convert to a sale, and we found that optimizing for middle of the funnel was too easy to game - often we’d have hugely successful experiments that improved the whole top half of the funnel but we wouldn’t see any improvement in our true-north metric 6 months later, conversion to sale. Surrogate indexes were a natural way to try and solve that problem. <a href="https://arxiv.org/pdf/2106.01421.pdf">LinkedIn also has a case study</a> on their need to optimize long term outcomes and how they’re using surrogate indexes which is worth a read.</p>
</section>
<section id="the-surrogate-index-approach" class="level1">
<h1>The Surrogate Index Approach</h1>
<p>Surrogate indexes are a way to use short term proxies to estimate long-term treatment effects. For instance, lets say you’re a subscription company and you want to see how some intervention improves retention. But churn takes a long time to observe, so your experiment could go on for months. <strong>TLDR;</strong> is that with this approach, instead of measuring churn as your <strong>overall evaluation criteria (OEC</strong>), you measure <code>predicted churn</code> (with some caveats) as the OEC.</p>
<p>A common response might be “thats complicated, can we try something more simple for now?” Of course you can. You can always try to choose some single short term proxy as your OEC for an experiment. But be careful because you could end up over-optimizing that proxy and not seeing the improvement in your long term outcome that you want. Surrogate indexes instead have many short term proxies, and they are validated over a set of historical data to ensure they’re an unbiased estimator of long term treatment effects.</p>
<p>How do they work? Let’s start with a DAG</p>
<div class="cell">
<div class="cell-output-display">
<div>
<p>
<svg width="672" height="480" viewbox="0.00 0.00 134.00 188.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 184)">
<title>
G
</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-184 130,-184 130,4 -4,4"></polygon> <!-- X --> <g id="node1" class="node">
<title>
X
</title>
<ellipse fill="none" stroke="black" cx="27" cy="-162" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="27" y="-157.8" font-family="Times,serif" font-size="14.00">X</text> </g> <!-- S --> <g id="node2" class="node">
<title>
S
</title>
<ellipse fill="none" stroke="black" cx="63" cy="-90" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="63" y="-85.8" font-family="Times,serif" font-size="14.00">S</text> </g> <!-- X&#45;&gt;S --> <g id="edge1" class="edge">
<title>
X-&gt;S
</title>
<path fill="none" stroke="black" d="M35.35,-144.76C39.71,-136.28 45.15,-125.71 50.04,-116.2"></path> <polygon fill="black" stroke="black" points="53.23,-117.64 54.7,-107.15 47.01,-114.44 53.23,-117.64"></polygon> </g> <!-- Y --> <g id="node4" class="node">
<title>
Y
</title>
<ellipse fill="none" stroke="black" cx="63" cy="-18" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="63" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text> </g> <!-- S&#45;&gt;Y --> <g id="edge3" class="edge">
<title>
S-&gt;Y
</title>
<path fill="none" stroke="black" d="M63,-71.7C63,-63.98 63,-54.71 63,-46.11"></path> <polygon fill="black" stroke="black" points="66.5,-46.1 63,-36.1 59.5,-46.1 66.5,-46.1"></polygon> </g> <!-- Tx --> <g id="node3" class="node">
<title>
Tx
</title>
<ellipse fill="none" stroke="black" cx="99" cy="-162" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="99" y="-157.8" font-family="Times,serif" font-size="14.00">Tx</text> </g> <!-- Tx&#45;&gt;S --> <g id="edge2" class="edge">
<title>
Tx-&gt;S
</title>
<path fill="none" stroke="black" d="M90.65,-144.76C86.29,-136.28 80.85,-125.71 75.96,-116.2"></path> <polygon fill="black" stroke="black" points="78.99,-114.44 71.3,-107.15 72.77,-117.64 78.99,-114.44"></polygon> </g> </g>
</svg>
</p>
</div>
</div>
</div>
<p>DAGs are diagrams, where the arrows represent causal effects. In this case, there’s some set of customer features <img src="https://latex.codecogs.com/png.latex?X">, that influence some set of short term outcomes, <img src="https://latex.codecogs.com/png.latex?S"> (a surrogate index).</p>
<p>There’s also a treatment, <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BTx%7D">, that influences <img src="https://latex.codecogs.com/png.latex?S">. It may influence different short term outcomes in S in different ways.</p>
<p>Lastly there’s <img src="https://latex.codecogs.com/png.latex?Y">, our long-term outcome of interest. Notice that all of the effect of the treatment on <img src="https://latex.codecogs.com/png.latex?Y"> flows through <img src="https://latex.codecogs.com/png.latex?S">. This is saying that the entire causal effect of the treatment on <img src="https://latex.codecogs.com/png.latex?Y"> is explained by the effect of the treatment on <img src="https://latex.codecogs.com/png.latex?S">. Keep note of that, because its a key assumption for Surrogate Indexes to work.</p>
<p>A more detailed way to show this is through the use of <a href="https://academic.oup.com/ije/article/50/2/613/5998421">IDAGs</a>, a newer way to represent DAGs with interactions</p>
<div class="cell">
<div class="cell-output-display">
<div>
<p>
<svg width="672" height="480" viewbox="0.00 0.00 220.79 188.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 184)"> <polygon fill="white" stroke="transparent" points="-4,4 -4,-184 216.79,-184 216.79,4 -4,4"></polygon> <!-- x --> <g id="node1" class="node">
<title>
x
</title>
<ellipse fill="none" stroke="black" cx="27" cy="-162" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="27" y="-157.8" font-family="Times,serif" font-size="14.00">X</text> </g> <!-- s --> <g id="node2" class="node">
<title>
s
</title>
<ellipse fill="none" stroke="black" cx="61" cy="-90" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="61" y="-85.8" font-family="Times,serif" font-size="14.00">S</text> </g> <!-- x&#45;&gt;s --> <g id="edge1" class="edge">
<title>
x-&gt;s
</title>
<path fill="none" stroke="black" d="M34.89,-144.76C38.9,-136.49 43.89,-126.23 48.42,-116.9"></path> <polygon fill="black" stroke="black" points="51.7,-118.16 52.92,-107.63 45.4,-115.1 51.7,-118.16"></polygon> </g> <!-- y --> <g id="node3" class="node">
<title>
y
</title>
<ellipse fill="none" stroke="black" cx="61" cy="-18" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="61" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text> </g> <!-- s&#45;&gt;y --> <g id="edge3" class="edge">
<title>
s-&gt;y
</title>
<path fill="none" stroke="black" d="M61,-71.7C61,-63.98 61,-54.71 61,-46.11"></path> <polygon fill="black" stroke="black" points="64.5,-46.1 61,-36.1 57.5,-46.1 64.5,-46.1"></polygon> </g> <!-- t --> <g id="node4" class="node">
<title>
t
</title>
<ellipse fill="none" stroke="black" cx="99" cy="-162" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="99" y="-157.8" font-family="Times,serif" font-size="14.00">Tx</text> </g> <!-- t&#45;&gt;s --> <g id="edge2" class="edge">
<title>
t-&gt;s
</title>
<path fill="none" stroke="black" d="M90.19,-144.76C85.58,-136.28 79.84,-125.71 74.68,-116.2"></path> <polygon fill="black" stroke="black" points="77.61,-114.27 69.77,-107.15 71.46,-117.61 77.61,-114.27"></polygon> </g> <!-- X --> <g id="node5" class="node">
<title>
X
</title>
<ellipse fill="none" stroke="black" cx="176" cy="-162" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="176" y="-157.8" font-family="Times,serif" font-size="14.00">X</text> </g> <!-- ΔS_Tx --> <g id="node6" class="node">
<title>
ΔS_Tx
</title>
<ellipse fill="none" stroke="black" cx="176" cy="-90" rx="36.58" ry="18"></ellipse> <text text-anchor="middle" x="176" y="-85.8" font-family="Times,serif" font-size="14.00">ΔS_Tx</text> </g> <!-- X&#45;&gt;ΔS_Tx --> <g id="edge4" class="edge">
<title>
X-&gt;ΔS_Tx
</title>
<path fill="none" stroke="black" d="M176,-143.7C176,-135.98 176,-126.71 176,-118.11"></path> <polygon fill="black" stroke="black" points="179.5,-118.1 176,-108.1 172.5,-118.1 179.5,-118.1"></polygon> </g> <!-- Y --> <g id="node7" class="node">
<title>
Y
</title>
<ellipse fill="none" stroke="black" cx="176" cy="-18" rx="27" ry="18"></ellipse> <text text-anchor="middle" x="176" y="-13.8" font-family="Times,serif" font-size="14.00">Y</text> </g> <!-- ΔS_Tx&#45;&gt;Y --> <g id="edge5" class="edge">
<title>
ΔS_Tx-&gt;Y
</title>
<path fill="none" stroke="black" d="M176,-71.7C176,-63.98 176,-54.71 176,-46.11"></path> <polygon fill="black" stroke="black" points="179.5,-46.1 176,-36.1 172.5,-46.1 179.5,-46.1"></polygon> </g> </g>
</svg>
</p>
</div>
</div>
</div>
<p>The IDAG is shown on the right. The main difference is the new term, <img src="https://latex.codecogs.com/png.latex?%5CDelta%20S_%7B%5Ctext%7BTx%7D%7D"> It implies that <img src="https://latex.codecogs.com/png.latex?X"> impacts the effect of the treatment on <img src="https://latex.codecogs.com/png.latex?S">. More simply, the treatment will have different effects on <img src="https://latex.codecogs.com/png.latex?S"> for different people based on their background, <img src="https://latex.codecogs.com/png.latex?X">, also known as <strong>heterogeneous treatment effects (HTEs)</strong>.</p>
<blockquote class="blockquote">
<p>Typically we average over HTEs to just get a single average treatment effect (ATE) for experiments, and that’s what we’ll be doing here. But there are ways to estimate HTEs as well, and we’ll get to that in part 3 of this series.</p>
</blockquote>
<p>This DAG can be used to build a surrogate index. If you can identify a set, <img src="https://latex.codecogs.com/png.latex?S">, of shorter term proxies for <img src="https://latex.codecogs.com/png.latex?Y">, and the effect of the treatment on <img src="https://latex.codecogs.com/png.latex?Y"> is entirely explained by <img src="https://latex.codecogs.com/png.latex?S">, than you can use <img src="https://latex.codecogs.com/png.latex?%5Chat%7BY%7D%20=%20f(S,%20X,%20T)%20+%20%5Cepsilon"> as an unbiased estimator for <img src="https://latex.codecogs.com/png.latex?Y"> before <img src="https://latex.codecogs.com/png.latex?Y"> is actually observed. This also means that you can estimate the long term treatment effect by observing <img src="https://latex.codecogs.com/png.latex?S"> for each variant of an experiment and using it to predict <img src="https://latex.codecogs.com/png.latex?%5Chat%7BY%7D"> for each group, then taking the difference: <img src="https://latex.codecogs.com/png.latex?%0AE%5B%5Cdelta_%7B%5Ctext%7BLTO%7D%7D%5D%20=%20E%5B%5Chat%7BY%7D%20%7C%20T=1%5D%20-%20E%5B%5Chat%7BY%7D%20%7C%20T=0%5D%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?%5Cdelta_%7B%5Ctext%7BLTO%7D%7D"> is the treatment effect on the long term outcome.</p>
<p>Lets start simulating to see that for ourselves</p>
</section>
<section id="showing-that-surrogate-index-works-with-simulated-data" class="level1">
<h1>Showing that Surrogate Index works with Simulated Data</h1>
<section id="step-1-simulating-the-data" class="level2">
<h2 class="anchored" data-anchor-id="step-1-simulating-the-data">Step 1: Simulating the data</h2>
<p>We’ll start by simulating two datasets: A historical dataset and an experiment dataset. The advantage to simulating data is that we know the exact effects, so when we try and estimate them we can confirm our methods are recovering the true effect.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> seaborn <span class="im" style="color: #00769E;">as</span> sns</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> statsmodels.api <span class="im" style="color: #00769E;">as</span> sm</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">from</span> simple_simulation <span class="im" style="color: #00769E;">import</span> set_true_parameters, transmitter</span>
<span id="cb1-7">SEED <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">99</span></span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;"># step 1: simulate data</span></span>
<span id="cb1-10">rng <span class="op" style="color: #5E5E5E;">=</span> np.random.default_rng(seed<span class="op" style="color: #5E5E5E;">=</span>SEED)</span>
<span id="cb1-11">logit_link<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span></span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="co" style="color: #5E5E5E;"># True parameters</span></span>
<span id="cb1-14">Zdims <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">20</span> <span class="co" style="color: #5E5E5E;"># customer latent dims</span></span>
<span id="cb1-15">Xdims <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">5</span> <span class="co" style="color: #5E5E5E;"># pre treatment covariates</span></span>
<span id="cb1-16">Sdims <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">8</span> <span class="co" style="color: #5E5E5E;"># intermediate outcomes (the surrogates)</span></span>
<span id="cb1-17">n_users <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">50000</span></span>
<span id="cb1-18"></span>
<span id="cb1-19">GROUND_TRUTH <span class="op" style="color: #5E5E5E;">=</span> set_true_parameters(Zdims, Xdims, Sdims, logit_link<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, rng<span class="op" style="color: #5E5E5E;">=</span>rng)</span>
<span id="cb1-20"></span>
<span id="cb1-21"><span class="co" style="color: #5E5E5E;"># Simulate data </span></span>
<span id="cb1-22">historical_data <span class="op" style="color: #5E5E5E;">=</span> transmitter(GROUND_TRUTH, add_treatment<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>, n_users<span class="op" style="color: #5E5E5E;">=</span>n_users,logit_link<span class="op" style="color: #5E5E5E;">=</span>logit_link, rng<span class="op" style="color: #5E5E5E;">=</span>rng) </span>
<span id="cb1-23">experiment_data <span class="op" style="color: #5E5E5E;">=</span> transmitter(GROUND_TRUTH, add_treatment<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, n_users<span class="op" style="color: #5E5E5E;">=</span>n_users, logit_link<span class="op" style="color: #5E5E5E;">=</span>logit_link, rng<span class="op" style="color: #5E5E5E;">=</span>rng)</span>
<span id="cb1-24"></span>
<span id="cb1-25"><span class="co" style="color: #5E5E5E;"># Censor the experiment dataset so that we dont know the long term outcome yet</span></span>
<span id="cb1-26">Y_TRUE <span class="op" style="color: #5E5E5E;">=</span> experiment_data.Y.values</span>
<span id="cb1-27">experiment_data <span class="op" style="color: #5E5E5E;">=</span> experiment_data.assign(Y<span class="op" style="color: #5E5E5E;">=</span>np.NaN)</span>
<span id="cb1-28"></span>
<span id="cb1-29"><span class="co" style="color: #5E5E5E;"># Show the historical dataset </span></span>
<span id="cb1-30">display(historical_data.head(<span class="dv" style="color: #AD0000;">5</span>))</span></code></pre></div>
<div class="cell-output cell-output-display">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>X0</th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>T</th>
      <th>S0</th>
      <th>S1</th>
      <th>S2</th>
      <th>S3</th>
      <th>S4</th>
      <th>S5</th>
      <th>S6</th>
      <th>S7</th>
      <th>Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-0.122906</td>
      <td>0.870259</td>
      <td>-1.054623</td>
      <td>-0.139527</td>
      <td>-1.433731</td>
      <td>0.0</td>
      <td>1.136292</td>
      <td>0.470017</td>
      <td>-0.263080</td>
      <td>0.486101</td>
      <td>0.723525</td>
      <td>0.129917</td>
      <td>-0.493243</td>
      <td>0.679735</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.736599</td>
      <td>-0.706638</td>
      <td>1.337368</td>
      <td>-0.111941</td>
      <td>-0.838790</td>
      <td>0.0</td>
      <td>0.151892</td>
      <td>-0.107404</td>
      <td>0.140590</td>
      <td>-0.815408</td>
      <td>0.274605</td>
      <td>-0.446996</td>
      <td>0.354266</td>
      <td>-1.318440</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.110126</td>
      <td>-1.617668</td>
      <td>1.262500</td>
      <td>1.049915</td>
      <td>-0.592917</td>
      <td>0.0</td>
      <td>-0.166384</td>
      <td>-0.147854</td>
      <td>0.565484</td>
      <td>-1.401817</td>
      <td>-0.086840</td>
      <td>-0.453305</td>
      <td>0.529608</td>
      <td>-1.086965</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.475479</td>
      <td>-0.507716</td>
      <td>0.324226</td>
      <td>1.259292</td>
      <td>-0.366888</td>
      <td>0.0</td>
      <td>0.154545</td>
      <td>0.161311</td>
      <td>0.087151</td>
      <td>-0.750579</td>
      <td>0.103096</td>
      <td>-0.098244</td>
      <td>0.131146</td>
      <td>0.032963</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.290787</td>
      <td>-0.575874</td>
      <td>0.867617</td>
      <td>0.844031</td>
      <td>-0.098109</td>
      <td>0.0</td>
      <td>-0.089913</td>
      <td>0.078953</td>
      <td>0.067596</td>
      <td>-0.773764</td>
      <td>0.041729</td>
      <td>-0.170939</td>
      <td>0.318613</td>
      <td>-0.506544</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>The underlying simulation code is below if you’re interested</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;">from</span> typing <span class="im" style="color: #00769E;">import</span> Dict</span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="kw" style="color: #003B4F;">def</span> transmitter(</span>
<span id="cb2-4">    params: Dict,</span>
<span id="cb2-5">    add_treatment: <span class="bu" style="color: null;">bool</span> <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span>,</span>
<span id="cb2-6">    n_users: <span class="bu" style="color: null;">int</span> <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span>,</span>
<span id="cb2-7">    logit_link: <span class="bu" style="color: null;">bool</span> <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">False</span>,</span>
<span id="cb2-8">    rng <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span></span>
<span id="cb2-9">) <span class="op" style="color: #5E5E5E;">-&gt;</span> pd.DataFrame:</span>
<span id="cb2-10">    <span class="co" style="color: #5E5E5E;">'''Simulates outcomes based on some ground truth parameters. </span></span>
<span id="cb2-11"></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;">    Parameters</span></span>
<span id="cb2-13"><span class="co" style="color: #5E5E5E;">    -----------</span></span>
<span id="cb2-14"><span class="co" style="color: #5E5E5E;">        params: The ground truth parameters (effects and biases) to simulate based off of</span></span>
<span id="cb2-15"><span class="co" style="color: #5E5E5E;">        add_treatment: adds a randomly allocated treatment when true, with effect `bTS`</span></span>
<span id="cb2-16"><span class="co" style="color: #5E5E5E;">        n_users: The number of users to simulate</span></span>
<span id="cb2-17"><span class="co" style="color: #5E5E5E;">        logit_link: whether the data generating process is a bernoulli outcome or not</span></span>
<span id="cb2-18"><span class="co" style="color: #5E5E5E;">        rng: A numpy random generator </span></span>
<span id="cb2-19"></span>
<span id="cb2-20"><span class="co" style="color: #5E5E5E;">    Returns</span></span>
<span id="cb2-21"><span class="co" style="color: #5E5E5E;">    --------</span></span>
<span id="cb2-22"><span class="co" style="color: #5E5E5E;">        A pandas dataframe with simulated data, including pre-treatment covariates,</span></span>
<span id="cb2-23"><span class="co" style="color: #5E5E5E;">         surrogate outcomes, a treatment indicator, and a long term outcome, Y</span></span>
<span id="cb2-24"><span class="co" style="color: #5E5E5E;">    '''</span></span>
<span id="cb2-25">    <span class="cf" style="color: #003B4F;">if</span> rng <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb2-26">        seed <span class="op" style="color: #5E5E5E;">=</span> np.random.choice(<span class="bu" style="color: null;">range</span>(<span class="dv" style="color: #AD0000;">1000</span>))</span>
<span id="cb2-27">        rng <span class="op" style="color: #5E5E5E;">=</span> np.random.default_rng(seed<span class="op" style="color: #5E5E5E;">=</span>seed)</span>
<span id="cb2-28"></span>
<span id="cb2-29">    <span class="co" style="color: #5E5E5E;"># unpack params</span></span>
<span id="cb2-30">    Zdims, Xdims, Sdims <span class="op" style="color: #5E5E5E;">=</span>  params[<span class="st" style="color: #20794D;">'bZX'</span>].shape[<span class="dv" style="color: #AD0000;">1</span>],  params[<span class="st" style="color: #20794D;">'bZX'</span>].shape[<span class="dv" style="color: #AD0000;">0</span>],  params[<span class="st" style="color: #20794D;">'bXS'</span>].shape[<span class="dv" style="color: #AD0000;">0</span>]</span>
<span id="cb2-31">    alphaX,alphaS,alphaY  <span class="op" style="color: #5E5E5E;">=</span> params[<span class="st" style="color: #20794D;">'alphaX'</span>], params[<span class="st" style="color: #20794D;">'alphaS'</span>], params[<span class="st" style="color: #20794D;">'alphaY'</span>] <span class="co" style="color: #5E5E5E;"># bias terms</span></span>
<span id="cb2-32">    bZX,bXS,bSY <span class="op" style="color: #5E5E5E;">=</span> params[<span class="st" style="color: #20794D;">'bZX'</span>], params[<span class="st" style="color: #20794D;">'bXS'</span>],params[<span class="st" style="color: #20794D;">'bSY'</span>] <span class="co" style="color: #5E5E5E;"># causal relationships</span></span>
<span id="cb2-33">    bTS,bXTS <span class="op" style="color: #5E5E5E;">=</span> params[<span class="st" style="color: #20794D;">'bTS'</span>], params[<span class="st" style="color: #20794D;">'bXTS'</span>] <span class="co" style="color: #5E5E5E;"># tx effects</span></span>
<span id="cb2-34"></span>
<span id="cb2-35">    <span class="co" style="color: #5E5E5E;"># unobserved variable Z representing latent customer traits</span></span>
<span id="cb2-36">    Z <span class="op" style="color: #5E5E5E;">=</span> rng.normal(<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">1</span>, size<span class="op" style="color: #5E5E5E;">=</span>(Zdims, n_users))</span>
<span id="cb2-37"></span>
<span id="cb2-38">    <span class="co" style="color: #5E5E5E;"># Some observed pre-TX measures</span></span>
<span id="cb2-39">    X <span class="op" style="color: #5E5E5E;">=</span> alphaX[:,<span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">+</span> (bZX <span class="op" style="color: #5E5E5E;">@</span> Z)</span>
<span id="cb2-40"></span>
<span id="cb2-41">    <span class="co" style="color: #5E5E5E;"># Intermediate outcomes</span></span>
<span id="cb2-42">    S <span class="op" style="color: #5E5E5E;">=</span> alphaS[:,<span class="va" style="color: #111111;">None</span>] <span class="op" style="color: #5E5E5E;">+</span> (bXS <span class="op" style="color: #5E5E5E;">@</span> X) </span>
<span id="cb2-43"></span>
<span id="cb2-44">    <span class="co" style="color: #5E5E5E;"># Add in treatment effect if applicable</span></span>
<span id="cb2-45">    T <span class="op" style="color: #5E5E5E;">=</span> rng.binomial(<span class="dv" style="color: #AD0000;">1</span>,<span class="fl" style="color: #AD0000;">0.5</span>,size<span class="op" style="color: #5E5E5E;">=</span>n_users) <span class="cf" style="color: #003B4F;">if</span> add_treatment <span class="cf" style="color: #003B4F;">else</span> np.zeros(n_users)        </span>
<span id="cb2-46">    avg_tx_term <span class="op" style="color: #5E5E5E;">=</span> (bTS <span class="op" style="color: #5E5E5E;">*</span> T[:,<span class="va" style="color: #111111;">None</span>])        </span>
<span id="cb2-47">    hetergeneous_tx_term <span class="op" style="color: #5E5E5E;">=</span> (bXTS <span class="op" style="color: #5E5E5E;">@</span> (X<span class="op" style="color: #5E5E5E;">*</span>T))</span>
<span id="cb2-48">    S <span class="op" style="color: #5E5E5E;">+=</span> avg_tx_term.T <span class="op" style="color: #5E5E5E;">+</span> hetergeneous_tx_term</span>
<span id="cb2-49"></span>
<span id="cb2-50">    <span class="co" style="color: #5E5E5E;"># expectation of long term outcome</span></span>
<span id="cb2-51">    eta <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">0</span> <span class="op" style="color: #5E5E5E;">+</span> (bSY <span class="op" style="color: #5E5E5E;">@</span> S)</span>
<span id="cb2-52"></span>
<span id="cb2-53">    <span class="co" style="color: #5E5E5E;"># Long term outcome</span></span>
<span id="cb2-54">    <span class="cf" style="color: #003B4F;">if</span> logit_link:</span>
<span id="cb2-55">        Y <span class="op" style="color: #5E5E5E;">=</span> rng.binomial(<span class="dv" style="color: #AD0000;">1</span>, sp.expit(eta) )</span>
<span id="cb2-56">    <span class="cf" style="color: #003B4F;">else</span>:</span>
<span id="cb2-57">        Y <span class="op" style="color: #5E5E5E;">=</span> rng.normal(eta, <span class="fl" style="color: #AD0000;">0.025</span>)</span>
<span id="cb2-58"></span>
<span id="cb2-59">    <span class="co" style="color: #5E5E5E;"># Output as dataframe</span></span>
<span id="cb2-60">    Xdf <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame(X.T, columns<span class="op" style="color: #5E5E5E;">=</span>[<span class="ss" style="color: #20794D;">f'X</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span> <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(Xdims)]).assign(T<span class="op" style="color: #5E5E5E;">=</span>T)</span>
<span id="cb2-61">    Sdf <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame(S.T, columns<span class="op" style="color: #5E5E5E;">=</span>[<span class="ss" style="color: #20794D;">f'S</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span> <span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(Sdims)])</span>
<span id="cb2-62">    Ydf <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame(Y.ravel(), columns<span class="op" style="color: #5E5E5E;">=</span>[<span class="st" style="color: #20794D;">'Y'</span>])</span>
<span id="cb2-63">    <span class="cf" style="color: #003B4F;">return</span> pd.concat((Xdf, Sdf, Ydf),axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span></code></pre></div>
</details>
</div>
</section>
<section id="step-2-fitting-a-surrogate-model" class="level2">
<h2 class="anchored" data-anchor-id="step-2-fitting-a-surrogate-model">Step 2: Fitting a surrogate model</h2>
<p>We’ll use the historical dataset to fit the surrogate index model, mapping <img src="https://latex.codecogs.com/png.latex?S%20%5Crightarrow%20Y"></p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">S_vars <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">" + "</span>.join( historical_data.<span class="bu" style="color: null;">filter</span>(like<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"S"</span>).columns )</span>
<span id="cb3-2">X_vars <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">" + "</span>.join( historical_data.<span class="bu" style="color: null;">filter</span>(like<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"X"</span>).columns )</span>
<span id="cb3-3"></span>
<span id="cb3-4"><span class="co" style="color: #5E5E5E;"># Step 2: fit a surrogate index model on complete historical data</span></span>
<span id="cb3-5">surrogate_model <span class="op" style="color: #5E5E5E;">=</span> sm.OLS.from_formula(<span class="ss" style="color: #20794D;">f"Y ~ </span><span class="sc" style="color: #5E5E5E;">{</span>S_vars<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, data<span class="op" style="color: #5E5E5E;">=</span>historical_data).fit()</span>
<span id="cb3-6"></span>
<span id="cb3-7"><span class="co" style="color: #5E5E5E;"># Estimate the variance in the estimator, \hat{sigma^2}. This is used for bias corrections later</span></span>
<span id="cb3-8">predicted_sigma2 <span class="op" style="color: #5E5E5E;">=</span> np.var( surrogate_model.fittedvalues <span class="op" style="color: #5E5E5E;">-</span> historical_data.Y,  ddof<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span> )</span>
<span id="cb3-9"></span>
<span id="cb3-10"><span class="co" style="color: #5E5E5E;"># Show the model summary</span></span>
<span id="cb3-11">surrogate_model.summary()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">

<table class="simpletable">
<caption>OLS Regression Results</caption>
<tbody><tr>
  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.109</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.109</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1227.</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Tue, 26 Sep 2023</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  
</tr>
<tr>
  <th>Time:</th>                 <td>20:23:12</td>     <th>  Log-Likelihood:    </th> <td> -33395.</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td> 50000</td>      <th>  AIC:               </th> <td>6.680e+04</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td> 49994</td>      <th>  BIC:               </th> <td>6.686e+04</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    0.4987</td> <td>    0.002</td> <td>  236.271</td> <td> 0.000</td> <td>    0.495</td> <td>    0.503</td>
</tr>
<tr>
  <th>S0</th>        <td>    0.0361</td> <td>    0.004</td> <td>   10.244</td> <td> 0.000</td> <td>    0.029</td> <td>    0.043</td>
</tr>
<tr>
  <th>S1</th>        <td>    0.1035</td> <td>    0.005</td> <td>   21.661</td> <td> 0.000</td> <td>    0.094</td> <td>    0.113</td>
</tr>
<tr>
  <th>S2</th>        <td>   -0.0399</td> <td>    0.005</td> <td>   -8.396</td> <td> 0.000</td> <td>   -0.049</td> <td>   -0.031</td>
</tr>
<tr>
  <th>S3</th>        <td>    0.1833</td> <td>    0.004</td> <td>   49.916</td> <td> 0.000</td> <td>    0.176</td> <td>    0.190</td>
</tr>
<tr>
  <th>S4</th>        <td>    0.0482</td> <td>    0.002</td> <td>   29.074</td> <td> 0.000</td> <td>    0.045</td> <td>    0.051</td>
</tr>
<tr>
  <th>S5</th>        <td>    0.0674</td> <td>    0.002</td> <td>   29.208</td> <td> 0.000</td> <td>    0.063</td> <td>    0.072</td>
</tr>
<tr>
  <th>S6</th>        <td>   -0.0057</td> <td>    0.002</td> <td>   -2.350</td> <td> 0.019</td> <td>   -0.010</td> <td>   -0.001</td>
</tr>
<tr>
  <th>S7</th>        <td>    0.0054</td> <td>    0.003</td> <td>    1.970</td> <td> 0.049</td> <td> 2.64e-05</td> <td>    0.011</td>
</tr>
</tbody></table>
<table class="simpletable">
<tbody><tr>
  <th>Omnibus:</th>       <td>250873.640</td> <th>  Durbin-Watson:     </th> <td>   1.993</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>5244.738</td>
</tr>
<tr>
  <th>Skew:</th>            <td> 0.004</td>   <th>  Prob(JB):          </th> <td>    0.00</td>
</tr>
<tr>
  <th>Kurtosis:</th>        <td> 1.413</td>   <th>  Cond. No.          </th> <td>1.96e+16</td>
</tr>
</tbody></table><br><br>Notes:<br>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br>[2] The smallest eigenvalue is 2.41e-28. This might indicate that there are<br>strong multicollinearity problems or that the design matrix is singular.
</div>
</div>
<p>There are 3 important things to note here:</p>
<ol type="1">
<li>Note that we’re purposely not including the pre-treatment covariates, <img src="https://latex.codecogs.com/png.latex?X"> in this model. Remember the DAG - all of the effect of <img src="https://latex.codecogs.com/png.latex?X"> on <img src="https://latex.codecogs.com/png.latex?Y"> is entirely mediated by <img src="https://latex.codecogs.com/png.latex?S">, so adding <img src="https://latex.codecogs.com/png.latex?X"> into the model adds no additional information.</li>
<li>We’re using Ordinary Least Squares for bernoulli outcome data. Thats not a mistake. OLS has great properties to be effective on bernoulli outcome data, and it makes this approach very simple. Other models can also be swapped in, like Random Forest or XGBoost.</li>
<li>I’m not doing alot of model validation, just because this is simulated data. In practice, don’t just throw things into a model. Part 2 in this series will discuss how to validate surrogate indexes.</li>
</ol>
</section>
<section id="step-3-estimate-long-term-treatment-effect" class="level2">
<h2 class="anchored" data-anchor-id="step-3-estimate-long-term-treatment-effect">Step 3: Estimate Long Term Treatment Effect</h2>
<p>We’ll now use the surrogate index to estimate a long term treatment effect</p>
<p>Let’s take our experiment dataset and estimate <img src="https://latex.codecogs.com/png.latex?E%5B%5Cdelta_%7B%5Ctext%7BLTO%7D%7D%5D">, the average treatment effect on the long term outcome. Notice, the long term outcome, <img src="https://latex.codecogs.com/png.latex?Y">, hasn’t been observed yet.</p>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">display(experiment_data.head())</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>X0</th>
      <th>X1</th>
      <th>X2</th>
      <th>X3</th>
      <th>X4</th>
      <th>T</th>
      <th>S0</th>
      <th>S1</th>
      <th>S2</th>
      <th>S3</th>
      <th>S4</th>
      <th>S5</th>
      <th>S6</th>
      <th>S7</th>
      <th>Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.524763</td>
      <td>2.462224</td>
      <td>-0.550430</td>
      <td>0.771123</td>
      <td>0.435625</td>
      <td>0</td>
      <td>0.699780</td>
      <td>0.013300</td>
      <td>-1.550533</td>
      <td>0.516532</td>
      <td>0.555615</td>
      <td>0.259520</td>
      <td>-0.912439</td>
      <td>1.968729</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-0.852718</td>
      <td>2.363775</td>
      <td>-1.233271</td>
      <td>-0.064883</td>
      <td>0.007073</td>
      <td>1</td>
      <td>0.401477</td>
      <td>0.150007</td>
      <td>-1.056908</td>
      <td>1.090094</td>
      <td>0.319569</td>
      <td>1.315168</td>
      <td>-1.060364</td>
      <td>1.639560</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.845904</td>
      <td>-0.143859</td>
      <td>1.205996</td>
      <td>-2.574407</td>
      <td>-0.338278</td>
      <td>1</td>
      <td>-0.617663</td>
      <td>-0.031722</td>
      <td>0.353283</td>
      <td>0.503690</td>
      <td>-0.077284</td>
      <td>0.706088</td>
      <td>0.401262</td>
      <td>-2.388860</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.860914</td>
      <td>-1.382552</td>
      <td>0.295809</td>
      <td>-2.023966</td>
      <td>-0.018137</td>
      <td>0</td>
      <td>-0.691752</td>
      <td>-0.197120</td>
      <td>1.080598</td>
      <td>0.329710</td>
      <td>-0.489959</td>
      <td>-0.151432</td>
      <td>0.610699</td>
      <td>-1.754289</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.257026</td>
      <td>0.005047</td>
      <td>-0.333462</td>
      <td>-0.386979</td>
      <td>-0.126490</td>
      <td>1</td>
      <td>-0.391908</td>
      <td>-0.302902</td>
      <td>0.220642</td>
      <td>0.201999</td>
      <td>-0.343136</td>
      <td>0.883784</td>
      <td>-0.312573</td>
      <td>-0.012875</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>First, we’ll do some visulation of the experiment data.</p>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">fig, axes <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;">2</span>,<span class="bu" style="color: null;">int</span>(Xdims<span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">2</span>),figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">5</span>),sharey<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb5-2"></span>
<span id="cb5-3"><span class="cf" style="color: #003B4F;">for</span> i, ax <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">zip</span>(<span class="bu" style="color: null;">range</span>(Xdims), axes.ravel()):</span>
<span id="cb5-4">    sns.histplot( experiment_data.loc[<span class="kw" style="color: #003B4F;">lambda</span> d: d[<span class="st" style="color: #20794D;">'T'</span>]<span class="op" style="color: #5E5E5E;">==</span><span class="dv" style="color: #AD0000;">0</span>][<span class="ss" style="color: #20794D;">f"X</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>],ax<span class="op" style="color: #5E5E5E;">=</span>ax, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Control'</span> )</span>
<span id="cb5-5">    sns.histplot( experiment_data.loc[<span class="kw" style="color: #003B4F;">lambda</span> d: d[<span class="st" style="color: #20794D;">'T'</span>]<span class="op" style="color: #5E5E5E;">==</span><span class="dv" style="color: #AD0000;">1</span>][<span class="ss" style="color: #20794D;">f"X</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>],ax<span class="op" style="color: #5E5E5E;">=</span>ax, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Treatment'</span> )</span>
<span id="cb5-6"></span>
<span id="cb5-7">plt.suptitle(<span class="st" style="color: #20794D;">"Histogram of Pre-Treatment Covariates</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">for the Treatment and Control groups"</span>)</span>
<span id="cb5-8">plt.tight_layout()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/posts/surrogates/2023-07-09-surrogate_index_intro_files/figure-html/cell-6-output-1.png" width="758" height="475"></p>
</div>
</div>
<p>As we can see above, the pre-treatment variables are the exact same between the experiment groups. Thats because users are randomly allocated into treatment and control groups, and their pre-treatment varibles by definition are things not imapcted by the experiment.</p>
<p>Conversely, if we look at the surrogate outcomes below, we’ll see some differences in surrogate outcomes between the treatment and control groups.</p>
<div class="cell" data-execution_count="6">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">fig, axes <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;">2</span>,<span class="bu" style="color: null;">int</span>(Sdims<span class="op" style="color: #5E5E5E;">/</span><span class="dv" style="color: #AD0000;">2</span>),figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">5</span>), sharey<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb6-2"></span>
<span id="cb6-3"><span class="cf" style="color: #003B4F;">for</span> i, ax <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">zip</span>(<span class="bu" style="color: null;">range</span>(Sdims), axes.ravel()):</span>
<span id="cb6-4">    sns.histplot( experiment_data.loc[<span class="kw" style="color: #003B4F;">lambda</span> d: d[<span class="st" style="color: #20794D;">'T'</span>]<span class="op" style="color: #5E5E5E;">==</span><span class="dv" style="color: #AD0000;">0</span>][<span class="ss" style="color: #20794D;">f"S</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>],ax<span class="op" style="color: #5E5E5E;">=</span>ax, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Control'</span> )</span>
<span id="cb6-5">    sns.histplot( experiment_data.loc[<span class="kw" style="color: #003B4F;">lambda</span> d: d[<span class="st" style="color: #20794D;">'T'</span>]<span class="op" style="color: #5E5E5E;">==</span><span class="dv" style="color: #AD0000;">1</span>][<span class="ss" style="color: #20794D;">f"S</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>],ax<span class="op" style="color: #5E5E5E;">=</span>ax, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Treatment'</span> )</span>
<span id="cb6-6"></span>
<span id="cb6-7">plt.suptitle(<span class="st" style="color: #20794D;">"Histogram of Surrogate Outcomes</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">for the Treatment and Control groups"</span>)</span>
<span id="cb6-8">plt.tight_layout()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/posts/surrogates/2023-07-09-surrogate_index_intro_files/figure-html/cell-7-output-1.png" width="758" height="475"></p>
</div>
</div>
<p>If our surrogate index estimator is correct, these observed surrogate outcomes should directly map to the Long Term Outcome deterministically, via <img src="https://latex.codecogs.com/png.latex?%5Chat%7BY%7D%20=%20f(S)">, where <img src="https://latex.codecogs.com/png.latex?f()"> is the surrogate index model.</p>
<p>We can show that the surrogate index estimator recovers the true average treatment effect on the long term outcome</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;">def</span> estimate_delta_LTO(experiment_data, surrogate_model, predicted_sigma2):</span>
<span id="cb7-2">    <span class="co" style="color: #5E5E5E;">'''Accepts experiment data with a binary treatment, a surrogate model, and the predicted sigma^2 of the surrogate model.</span></span>
<span id="cb7-3"><span class="co" style="color: #5E5E5E;">    Returns the ATE estimate and its uncertainty</span></span>
<span id="cb7-4"><span class="co" style="color: #5E5E5E;">    </span></span>
<span id="cb7-5"><span class="co" style="color: #5E5E5E;">    '''</span></span>
<span id="cb7-6">    Y_T1 <span class="op" style="color: #5E5E5E;">=</span> surrogate_model.predict(experiment_data.loc[<span class="kw" style="color: #003B4F;">lambda</span> d: d[<span class="st" style="color: #20794D;">'T'</span>]<span class="op" style="color: #5E5E5E;">==</span><span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb7-7">    Y_T0 <span class="op" style="color: #5E5E5E;">=</span> surrogate_model.predict(experiment_data.loc[<span class="kw" style="color: #003B4F;">lambda</span> d: d[<span class="st" style="color: #20794D;">'T'</span>]<span class="op" style="color: #5E5E5E;">==</span><span class="dv" style="color: #AD0000;">0</span>])</span>
<span id="cb7-8">    </span>
<span id="cb7-9">    <span class="co" style="color: #5E5E5E;"># Calculate the ATE</span></span>
<span id="cb7-10">    ATE <span class="op" style="color: #5E5E5E;">=</span>  Y_T1.mean() <span class="op" style="color: #5E5E5E;">-</span> Y_T0.mean()</span>
<span id="cb7-11">    <span class="co" style="color: #5E5E5E;"># calculate the variance </span></span>
<span id="cb7-12">    var_surrogate <span class="op" style="color: #5E5E5E;">=</span> np.var(Y_T1,ddof<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>) <span class="op" style="color: #5E5E5E;">/</span> <span class="bu" style="color: null;">len</span>(Y_T1) <span class="op" style="color: #5E5E5E;">+</span> np.var(Y_T0,ddof<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>) <span class="op" style="color: #5E5E5E;">/</span> <span class="bu" style="color: null;">len</span>(Y_T0)</span>
<span id="cb7-13">    <span class="co" style="color: #5E5E5E;"># Adjust the variance by the surrogate model error</span></span>
<span id="cb7-14">    var_surrogate_adj <span class="op" style="color: #5E5E5E;">=</span> var_surrogate <span class="op" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">2</span><span class="op" style="color: #5E5E5E;">*</span>predicted_sigma2<span class="op" style="color: #5E5E5E;">/</span><span class="bu" style="color: null;">len</span>(Y_T1)</span>
<span id="cb7-15">    ATE_sd <span class="op" style="color: #5E5E5E;">=</span> np.sqrt(var_surrogate_adj)</span>
<span id="cb7-16">    </span>
<span id="cb7-17">    <span class="cf" style="color: #003B4F;">return</span> ATE, ATE_sd</span>
<span id="cb7-18"></span>
<span id="cb7-19">ATE, ATE_sd <span class="op" style="color: #5E5E5E;">=</span> estimate_delta_LTO(experiment_data, surrogate_model, predicted_sigma2)</span>
<span id="cb7-20">sns.histplot(np.random.normal(ATE, ATE_sd,size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10000</span>), stat<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'probability'</span>)</span>
<span id="cb7-21">plt.axvline( GROUND_TRUTH[<span class="st" style="color: #20794D;">'ATE'</span>], color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'r'</span>, ls<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'--'</span>, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'True ATE'</span>)</span>
<span id="cb7-22">plt.legend()</span>
<span id="cb7-23">plt.xlabel(<span class="st" style="color: #20794D;">"ATE"</span>)</span>
<span id="cb7-24">plt.title(<span class="st" style="color: #20794D;">"Estimated Treatment Effect vs. True Treatment Effect"</span>)</span>
<span id="cb7-25">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/posts/surrogates/2023-07-09-surrogate_index_intro_files/figure-html/cell-8-output-1.png" width="618" height="442"></p>
</div>
</div>
<p>There we are. The surrogate estimator recovers the true average treatment effect! We didn’t even have to wait and observe the true long term outcome.</p>
<p>If you’re interested, try simulating this repeatedly to confirm it regularly recovers the true ATE with different random seeds. Even better, try setting the treatment effect to zero and see how often there are false positives.</p>
</section>
</section>
<section id="whats-next" class="level1">
<h1>What’s next?</h1>
<p>Hopefully this post convinced you that the surrogate index approach can help assess long term outcomes in experiments faster.</p>
<p>While its easier to show this approach works, it’s harder to pull it off in practice. The next post will focus on how to validate a surrogate index estimator on more realistic data that you might see in industry.</p>


</section>

 ]]></description>
  <category>experimentation</category>
  <category>Causal Inference</category>
  <guid>https://github.com/kylejcaron/kylejcaron.github.io/posts/surrogates/2023-07-09-surrogate_index_intro.html</guid>
  <pubDate>Sun, 09 Jul 2023 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Desiging an Experimentation Strategy</title>
  <link>https://github.com/kylejcaron/kylejcaron.github.io/posts/experiment_strategy/2023-06-09-experiment-strategy.html</link>
  <description><![CDATA[ 




<p>Experiments have alot more use cases than many give them credit for. At their simplest, they’re a tool for mitigating risk when making product decisions. But at their best, they’re a tool that can help <a href="https://eng.lyft.com/causal-forecasting-at-lyft-part-1-14cca6ff3d6d">optimize an entire business</a>.</p>
<p>Every business has its own unique problems and goals, and this post is a case study where strategy was made across experiments to fit the needs of the business.</p>
<section id="tldr" class="level1">
<h1>TLDR</h1>
<ul>
<li>Building Trust First</li>
<li>More interesting questions come natually as the process improves</li>
<li>How do we make sure our decisions help our long term outcome? –&gt; Surrogate index</li>
</ul>
<p>At the end of the day, the real strategy is building trust with stakeholders. Once that trust is built up, thats when you get the chance to start having a bigger influence on the business.</p>
</section>
<section id="part-1-identifying-the-business-problems-and-needs" class="level1">
<h1>Part 1: Identifying the business problems and needs</h1>
<p>Policygenius is an insurance marketplace that aims to help customers find insurance policies. Selling insurance isn’t quite the same as e-commerce; it’s a major life decision, and major life decisions take some time to decide on. In fact, customers typically took 3-6 months to purchase a life insurance policy (our true-north metric). Thats a long time to monetize a lead. Attempting to <a href="https://arxiv.org/pdf/2106.01421.pdf">improve a long-term outcome</a> like that can be difficult, but that wasn’t a problem that the business fully understood the implications of when I first started. The business needs changed over time and so did our strategy to addres them, but that one problem eventually became the focal point of our strategy.</p>
<section id="early-stage-needs---starting-simple-building-trust" class="level2">
<h2 class="anchored" data-anchor-id="early-stage-needs---starting-simple-building-trust">Early stage needs - Starting Simple, Building trust</h2>
<p>When I joined the company, I was just the third data science hire, and there really wasn’t any experimentation practice in place beyond stakeholders watching an optimizely dashboard. Listening to stakeholders, there was a desire to build more trust in decision making and make sure their products decisions were actually improving things for the customer.</p>
<p>We started simple - a google doc template where stakeholders could explain the product feature they wanted to implement and their hypothesis on what outcome the product feature might improve. From there we worked with them to design a measurement strategy to answer their question, which wasn’t always an experiment. At the end of the day, experimentation is just one of many tools for causal inference. Having this process and flexibility helped us earn buy-in - we weren’t just there to tell them what we could and couldn’t do. We were there to educate so that we weren’t just recommending solutions, but so that stakeholders were playing a really active role in what our measurement strategy should be.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/posts/experiment_strategy/coach_beard.jpg" class="img-fluid figure-img"></p>
</figure>
</div>
<p>We also improved the experiment output from an optimizely dashboard to an in-house report. All of this built alot more trust in the results, and helped us move on to new questions like</p>
<ul>
<li>“Can we use different outcome metrics beyond conversion rate?”</li>
<li>“Can we make experiments shorter?” (power analyses, <a href="https://www.exp-platform.com/Documents/2013-02-CUPED-ImprovingSensitivityOfControlledExperiments.pdf">variance reduction</a>)</li>
<li>“Can we launch a feature without hurting the business even if we can’t confirm it’s better?”” (<a href="https://twitter.com/seanjtaylor/status/1488343062057152516">uncertainty quantification</a>)</li>
<li>“What’s the right risk tolerance in terms of being able to detect an effect versus risking a false positive” (<a href="https://twitter.com/seanjtaylor/status/1169855647510253569">here’s a fun example</a>)</li>
<li>“Can we start experimenting like this on our other products?”</li>
<li>“Can we learn how our change in one part of the funnel may have an impact further downstream?”</li>
<li>“How can we run experiments that mitigate regret?” (<a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Bandit algorithms</a>)</li>
<li>“Can we stop an experiment early and still have confidence in the results?” (sequential testing, <a href="https://dpananos.github.io/posts/2022-07-06-gsd/">alpha spending</a>)</li>
<li>“Who is the experiment working best for?” ( <a href="https://multithreaded.stitchfix.com/blog/2015/10/15/multiple-hypothesis-testing/">Multiple Hypothesis Testing</a>, <a href="https://matheusfacure.github.io/python-causality-handbook/18-Heterogeneous-Treatment-Effects-and-Personalization.html">Heterogeneous Treatment Effects</a> )</li>
</ul>
<p>Again, we weren’t just throwing cool implementations at them we thought they needed, we were listening to what our stakeholders wanted first and then prioritizing it. As we moved up the ladder in terms of trust, I was able to get buy in to build out scalable tooling for others in the company to start usin, and we were able to scale the process to other teams.</p>
<p>There was also 1 key tenant I tried to keep in mind as our methodology became more advanced: <strong>could we directly observe the treatment effect?</strong> (<a href="https://mixtape.scunning.com/04-potential_outcomes">simple difference in outcomes</a>). No matter how advanced of a method we might consider, throwing some output from a blackbox model at a stakeholder was never the way to go. It can’t be understated how important directly observing the treatment effect is for trust.</p>
</section>
</section>
<section id="part-2---new-problems" class="level1">
<h1>Part 2 - New problems</h1>
<p>Our early stage strategy for experiments was to try and optimize mid-funnel outcomes (with intermediate guardrail metrics), since it would take too long to observe lower funnel outcomes. We wanted to be running experiments at 1-2 week cadences, we couldnt afford to wait 3-6 months for experiments. This did come with risk however, so we had built some visibility to see how users who were exposed to some experiments were baking out months later. I’m not sure why <em>baking</em> is a professional term to wait and see an outcome over time, but it is.</p>
<p>The opportunity for a long-term strategy arose as we began running into new problems.</p>
<section id="problem-1-infrastructure" class="level3">
<h3 class="anchored" data-anchor-id="problem-1-infrastructure">Problem 1: Infrastructure</h3>
<p>Some pillars of the business had less established data models (the data engineering kind of data models) - so setting up different SQL queries for different experiments was a painpoint for some product pillars.</p>
</section>
<section id="problem-2-secondary-analyses-and-personalization" class="level3">
<h3 class="anchored" data-anchor-id="problem-2-secondary-analyses-and-personalization">Problem 2: Secondary Analyses and personalization</h3>
<p>The data team was getting burnout. With each experiment came what we called “secondary analysis”. Really, what stakeholders were interested in was heterogeneous treatment effects, or “who does the treatment work best for”, because the vision was to personalize the product flow based on the customer. But for the data team, the analysis that came with it was entirely manual and would drag on when there wasn’t a clear answer (often). It was also a risk for false positives from multiple hypothesis testing.</p>
</section>
<section id="problem-3-sample-size" class="level3">
<h3 class="anchored" data-anchor-id="problem-3-sample-size">Problem 3: Sample Size</h3>
<p>There are only so many customers interested in private insurance in this country, and that limited sample size quite a bit. We were already choosing power and false positive rate parameters for our tests that would allow us to move quicker across the company, but there was a real desire from stakeholders to move faster, especially since some experiments could take up to a month.</p>
</section>
<section id="problem-4-spillover-effects" class="level3">
<h3 class="anchored" data-anchor-id="problem-4-spillover-effects">Problem 4: Spillover effects</h3>
<p>A major step of our funnel involved sales agents, which we had a limited supply. This had the potential for spillover effects, where if we sent them too many leads from a successful variant, it would impact the control. This is a classic SUTVA violation, which can bias the observed treatment effect.</p>
</section>
<section id="problem-5-were-we-optimizing-the-wrong-thing" class="level3">
<h3 class="anchored" data-anchor-id="problem-5-were-we-optimizing-the-wrong-thing">Problem 5: Were we optimizing the wrong thing?</h3>
<p>My second quarter with the life-insurance team we smashed through our OKRs that were targeted at improving mid-funnel outcomes (we were scoped to work on the top half of the funnel). The problem was that 3 months later we weren’t seeing those results trickle down to the bottom half of the funnel in the way that we thought it would.</p>
<p>In fact, in one of the most successful experiments we ran, we found that the customers who were exposed to the treatment fared worse in the long-term, despite seeming fine for the mid-funnel outcome and guardrail we were using.</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> matplotlib.ticker <span class="im" style="color: #00769E;">as</span> mtick</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> pymc <span class="im" style="color: #00769E;">as</span> pm</span>
<span id="cb1-6"></span>
<span id="cb1-7"></span>
<span id="cb1-8"><span class="co" style="color: #5E5E5E;"># Simulate out time to convert and conversion rate </span></span>
<span id="cb1-9"><span class="kw" style="color: #003B4F;">def</span> sim_conversion(k, lambd, p, N<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1000</span>):</span>
<span id="cb1-10">    ttc <span class="op" style="color: #5E5E5E;">=</span> np.ceil(pm.draw( pm.Weibull.dist(k, lambd), N))</span>
<span id="cb1-11">    convert <span class="op" style="color: #5E5E5E;">=</span> np.random.binomial(<span class="dv" style="color: #AD0000;">1</span>,p, size<span class="op" style="color: #5E5E5E;">=</span>N)</span>
<span id="cb1-12">    <span class="cf" style="color: #003B4F;">return</span> pd.DataFrame({<span class="st" style="color: #20794D;">"time"</span>:ttc, <span class="st" style="color: #20794D;">'convert'</span>:convert})</span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="kw" style="color: #003B4F;">def</span> cohort_table(df):</span>
<span id="cb1-15">    <span class="cf" style="color: #003B4F;">return</span>     (</span>
<span id="cb1-16">        df</span>
<span id="cb1-17">        .groupby(<span class="st" style="color: #20794D;">"time"</span>)</span>
<span id="cb1-18">        .convert.agg([<span class="st" style="color: #20794D;">'sum'</span>,<span class="st" style="color: #20794D;">'count'</span>])</span>
<span id="cb1-19">        .assign(conversions<span class="op" style="color: #5E5E5E;">=</span><span class="kw" style="color: #003B4F;">lambda</span> d: d[<span class="st" style="color: #20794D;">'sum'</span>].cumsum())</span>
<span id="cb1-20">        .assign(N<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">len</span>(df))</span>
<span id="cb1-21">        .assign(cvr<span class="op" style="color: #5E5E5E;">=</span><span class="kw" style="color: #003B4F;">lambda</span> d: d.conversions<span class="op" style="color: #5E5E5E;">/</span>d.N)</span>
<span id="cb1-22">    )</span>
<span id="cb1-23"></span>
<span id="cb1-24"><span class="kw" style="color: #003B4F;">def</span> censor(df, time):</span>
<span id="cb1-25">    <span class="cf" style="color: #003B4F;">return</span> df.loc[<span class="kw" style="color: #003B4F;">lambda</span> d: d.time<span class="op" style="color: #5E5E5E;">&lt;</span>time]</span>
<span id="cb1-26"></span>
<span id="cb1-27"><span class="kw" style="color: #003B4F;">def</span> simple_cohort_plot(df, ax<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">None</span>, <span class="op" style="color: #5E5E5E;">**</span>plot_kwargs):</span>
<span id="cb1-28">    </span>
<span id="cb1-29">    <span class="cf" style="color: #003B4F;">if</span> ax <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span>:</span>
<span id="cb1-30">        fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">1</span>,figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">7</span>,<span class="dv" style="color: #AD0000;">4</span>))</span>
<span id="cb1-31">    </span>
<span id="cb1-32">    (df.pipe(censor, time<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">200</span>)</span>
<span id="cb1-33">        .pipe(cohort_table)</span>
<span id="cb1-34">        [<span class="st" style="color: #20794D;">'cvr'</span>]</span>
<span id="cb1-35">        .plot(ax<span class="op" style="color: #5E5E5E;">=</span>ax, <span class="op" style="color: #5E5E5E;">**</span>plot_kwargs))</span>
<span id="cb1-36"></span>
<span id="cb1-37">    ax.<span class="bu" style="color: null;">set</span>(</span>
<span id="cb1-38">        title<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Cumulative Conversion to Sale'</span>, </span>
<span id="cb1-39">        xlabel<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Days Since Experiment Start'</span>, </span>
<span id="cb1-40">        ylabel<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Conversion Rate'</span>)</span>
<span id="cb1-41">    </span>
<span id="cb1-42">  </span>
<span id="cb1-43">fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">1</span>,figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">7</span>,<span class="dv" style="color: #AD0000;">4</span>))</span>
<span id="cb1-44">N <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">100_000</span></span>
<span id="cb1-45">sim_conversion(<span class="fl" style="color: #AD0000;">1.5</span>, <span class="dv" style="color: #AD0000;">60</span>, <span class="fl" style="color: #AD0000;">0.2</span>, N).pipe(simple_cohort_plot,ax<span class="op" style="color: #5E5E5E;">=</span>ax, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Control'</span>)</span>
<span id="cb1-46">sim_conversion(<span class="fl" style="color: #AD0000;">1.5</span>, <span class="dv" style="color: #AD0000;">55</span>, <span class="fl" style="color: #AD0000;">0.18</span>, N).pipe(simple_cohort_plot,ax<span class="op" style="color: #5E5E5E;">=</span>ax, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Variant'</span>)</span>
<span id="cb1-47">ax.yaxis.set_major_formatter(mtick.PercentFormatter(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">1</span>,))</span>
<span id="cb1-48">ax.legend()</span>
<span id="cb1-49">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/posts/experiment_strategy/2023-06-09-experiment-strategy_files/figure-html/cell-2-output-1.png" width="610" height="370"></p>
</div>
</div>
<p>It turns out we had gamed our metric. We could find great ways to boost our target metric and crush our OKRs, but what good did it do for the company?</p>
<p>This was by far the biggest problem, and luckily thanks to all of the trust that we had built up and the co-ownership model we had adopted with our stakeholders this problem didn’t end up dissolving any trust we had. In fact, everyone was grateful it was caught. Thinking counterfactually, the business would have never know had we not adopted a rigorous experimentation process. The importance of this issue gave me the justification to come up with a plan and start addressing these problems we were running into.</p>
</section>
</section>
<section id="part-3---designing-the-long-term-strategy" class="level1">
<h1>Part 3 - Designing the long term strategy</h1>
<section id="whats-a-surrogate-index" class="level2">
<h2 class="anchored" data-anchor-id="whats-a-surrogate-index">What’s a surrogate index?</h2>
<p>A surrogate index was a new piece of research from Susan Athey, basically a way to predict what a long term treatment effect would be given intermediate outcomes that could be observed sooner. It also neatly addressed the biggest problem we were facing.</p>
<p>The basic idea is illustrated in the DAG below.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-1">flowchart LR
  B(Treatment) --&gt; c(Outcome 1)
  B(Treatment) --&gt; d(Outcome 2)
  B(Treatment) --&gt; e(Outcome 3)
  c(Outcome 1) --&gt; f(Long Term\nOutcome)
  d(Outcome 2) --&gt; f(Long Term\nOutcome)
  e(Outcome 3) --&gt; f(Long Term\nOutcome)
</pre>
<div id="mermaid-tooltip-1" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<p>Let’s say the long term outcome can be entirely explained by 3 intermediate outcomes, such as mid-funnel metrics that can be observed sooner. A model can be fit to that relationship on historical data like so:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-2">flowchart LR
  c(Outcome 1) --&gt; f(Long Term\nOutcome)
  d(Outcome 2) --&gt; f(Long Term\nOutcome)
  e(Outcome 3) --&gt; f(Long Term\nOutcome)
</pre>
<div id="mermaid-tooltip-2" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<p>The set of intermediate outcomes is known as a surrogate index; they’re a surrogate for the long term outcome. If you have a correct model for the DAG above, than all you need to do is observe outcomes 1-3. You could then just run an experiment as you normally would, but instead of using some game-able mid-funnel metric as the primary outcome, you could measure outcomes 1-3 for both the treatment and control group, and predict what the long-term outcome would be for each group. The difference in the prediction for the treatment group and the control group ends up being identical to the true long-term treatment effect (assuming that the model and dag are specified correctly).</p>
<p>As always, it’s easier said than done. You need to make sure that the entire intermediate effect between the treatment and the long-term outcome is captured by the DAG and the model. Or in english, you need to understand the exact effect that the intermediate outcomes have on the long term outcome, and you need to be right about it; you can’t be missing anything.</p>
<p>But there are ways to validate you’re on the right track. First, knowing something about DAGs and causal inference, you can call on the <strong>local markov property</strong>; the treatment should be conditionally independent of the long term outcome after conditioning on the surrogate index. That’s easy to test. One can alse make predictions on the long term outcome with their surrogate index and see if it ended up being correct when the long-term outcome gets observed (hopefully for repeated experiments). Also do-able. Even better, if you have many historical experiments, you could do this validation on that dataset across all of the experiments.</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># for simplicity, not actually simulating a true data generating process</span></span>
<span id="cb2-2">np.random.seed(<span class="dv" style="color: #AD0000;">99</span>)</span>
<span id="cb2-3">x <span class="op" style="color: #5E5E5E;">=</span> np.random.normal(<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">3</span>,size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">25</span>)</span>
<span id="cb2-4">true_north_metric <span class="op" style="color: #5E5E5E;">=</span> x<span class="op" style="color: #5E5E5E;">*</span><span class="fl" style="color: #AD0000;">1.4</span> <span class="op" style="color: #5E5E5E;">+</span> np.random.normal(<span class="dv" style="color: #AD0000;">0</span>, <span class="fl" style="color: #AD0000;">0.5</span>, size<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">len</span>(x))</span>
<span id="cb2-5">predicted_true_north <span class="op" style="color: #5E5E5E;">=</span> np.random.normal(true_north_metric, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb2-6"></span>
<span id="cb2-7">fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">7</span>,<span class="dv" style="color: #AD0000;">5</span>))</span>
<span id="cb2-8">ax.scatter(predicted_true_north, true_north_metric)</span>
<span id="cb2-9">ax.plot([<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">7</span>], [<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">7</span>], ls<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'--'</span>)</span>
<span id="cb2-10"></span>
<span id="cb2-11">ax.set_xticks([])</span>
<span id="cb2-12">ax.set_yticks([])</span>
<span id="cb2-13">ax.<span class="bu" style="color: null;">set</span>(xlabel<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Predicted True North'</span>, ylabel<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'True North Metric'</span>, title<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'Surrogate Index vs. Long Term Outcome over many experiments'</span>)</span>
<span id="cb2-14">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/posts/experiment_strategy/2023-06-09-experiment-strategy_files/figure-html/cell-3-output-1.png" width="558" height="420"></p>
</div>
</div>
<p>Unfortunately, we didn’t have a large dataset of historical experiments. For the experiments we did have, they didn’t have enough power to detect reasonably sized changes on our true-north bottom funnel metric. Those experiment had all been designed with mid-funnel metrics in mind, and therefore had smaller sample sizes.</p>
</section>
<section id="building-a-plan" class="level2">
<h2 class="anchored" data-anchor-id="building-a-plan">Building a plan</h2>
<p>In total there were 5 big problems to address, each with a different solution. There also weren’t alot of resources to devote to them. But if we could free up time for others running experiments, they could use some of that time to contribute to this roadmap.</p>
<p>In the end, the biggest priority was to implement surrogate indices, because that was having the biggest painpoint on our business - we couldnt keep working with game-able metrics that weren’t improving the business.</p>
<p>With that in mind, switchback experimentation was in direct conflict with that goal. Switchback experiments don’t allow you to observe long term outcomes because users arent the ones who are randomized, time periods are what is randomized. We could atleast monitor and set up guardrails to make sure there wasnt alot of spillover.</p>
<p>This also meant that bandit algorithms shouldn’t be part of our toolkit any time soon, even though there had been alot of interest in them. Bandit algorithms wouldn’t be ideal for learning the impact on long term outcomes, and using them to learn a surrogate index would be really difficult since the treatment propensity would be constantly changing over time.</p>
<p>I’ll summarize some of the easy and hard solutions I came up with:</p>
<ol type="1">
<li><strong>Infrastructure</strong>
<ul>
<li><strong>Solution</strong>: templated SQL for scalable experiment queries</li>
</ul></li>
<li><strong>“Who did the experiment work best for?”</strong>
<ul>
<li><strong>Easy solution(s):</strong> Scalable code for Multiple hypothesis testing with corrections</li>
<li><strong>Hard solution:</strong> Heterogeneuous Treatment Effect models</li>
</ul></li>
<li><strong>Sample Size problems</strong>
<ul>
<li><strong>Easy solution(s):</strong> Quickly implement Informative priors. Since we had revenue as part of our overall evaluation criteria for some experiments, this provided a massive speedup</li>
<li><strong>Hard solution(s):</strong> <a href="https://www.exp-platform.com/Documents/2013-02-CUPED-ImprovingSensitivityOfControlledExperiments.pdf">CUPED</a>, <a href="https://github.com/kylejcaron/case_studies/blob/main/Time%20to%20Conversion%20Matters.ipynb">Cohort Models</a></li>
</ul></li>
<li><strong>Spillover Effects</strong>
<ul>
<li><strong>Easy Solution(s):</strong> Monitoring, guardrails</li>
<li><strong>Hard Solution(s):</strong> Switchback Experimentation Engine</li>
</ul></li>
<li>Optimizing for Long-term Outcomes
<ul>
<li><strong>Easy Solution(s):</strong> Cohort monitoring, Longer experiments, long term hold-out groups</li>
<li><strong>Hard solution(s):</strong> Surrogate Index approach</li>
</ul></li>
</ol>
<p>The final proposed plan ended up being the following:</p>
<ol type="1">
<li>Partner with the data team for each product pillar to build templated SQL for their experiments to save them time.</li>
<li>Automate the secondary analysis of experiments so that stakeholders could understand who the experiments worked best for. We actually chose the easy solution for this, multiple hypothesis testing with corrections. It was easy to implement it and it aligned with our principle of making sure the treatment effect is observable. Plus, if we ever got the point of heterogenous treatment effect modeling, it’d be alot more believeable for stakeholders if they could also look at the multiple hypothesis test reporting. This was a low lift way to free up the teams time and help our stakeholders answer what they wanted. Importantly, we lumped in metric observability with this so that we could understand which experiments were impacting which metrics.</li>
<li>Reduce experiment duration with informative priors and CUPED. Many experiments had an overall evaluation criteria that incorporated customer revenue, Customer revenue was wide-tailed (near lognormally distributed). Using priors was an incredibly easy and insanely effective way to reduce variance for experiments, speeding them up significantly. CUPED would be a way to take that even further. We planned for a data scientist to implement this with their newly freed up time after automating secondary analyses.</li>
<li>Set up monitoring for spillover effects, but don’t implement switchback experiments.</li>
<li>Center the life-insurance product’s experimentation strategy around a surrogate index. This meant running longer experiments so that there was enough power to detect effects on the true north metric. Hopefully after 6 months, we’d have enough information to build a correct surrogate index to start using.</li>
</ol>
<p>There was still a big red flag. We’d have to run longer experiments, and we’d have to wait atleast 6 months to even start using this. That was met with alot of hesitation. Deviating from 1-2 week experiment cadences admittedly sounds a bit nuts. Companies need to grow, and to do that they need to change and try new things. But at the same time we had a problem we couldn’t avoid - the simple fact of the matter was that if we wanted to have conviction in our product changes, we’d have to wait 3-6 months to actually observe its down funnel impact.</p>
<p>We decided to compromise rigor for speed. We planned to immediately implement a surrogate index based on the small amount of data we had, begin running experiments with enough power to detect an effect on our true north metric (3-4 weeks), and use the surrogate index, a guardrail, and our usual mid-funnel outcome as joint primary outcome metrics for upcoming experiments. While not ideal, it’d allow us to start using these ideas immediately, and we’d also be able to build up a better dataset of experiments so that even if the first iteration of the surrogate index didn’t work, we could eventually learn the correct one. That, and we’d have enough power to observe treatment effects on the long term outcome (after waiting a long time).</p>
<p>Really, our <strong>overall strategy was a shift to improving observability</strong>. We created better observability on how experiments were affecting different outcomes and different customers and we created better observability on how our experiments were impacting our true north metric. The funny part is, early in my career I thought this was a big red flag - the more you observe the more likely you could be to identify a false positive. But thats impractical advice. You really have to be looking at the whole picture, that way you can start to understand the business and learn more. Just do so responsibly.</p>
</section>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<p>There’s alot that goes into experimentation beyond just a cool approach like a surrogate index, or CUPED, or HTE modeling. To even get to the point where people will believe in those things, trust needs to built up. The interesting problems we ran into at Policygenius were a huge motivation for me to learn more about recent research in experimentation and causal inference, but looking back I wouldn’t have gotten a chance to do any of that if we hadn’t already built strong foundations. That opened up the door to start influencing the long term strategy for how the business made product decisions.</p>


</section>

 ]]></description>
  <category>experimentation</category>
  <guid>https://github.com/kylejcaron/kylejcaron.github.io/posts/experiment_strategy/2023-06-09-experiment-strategy.html</guid>
  <pubDate>Mon, 12 Jun 2023 04:00:00 GMT</pubDate>
  <media:content url="https://github.com/kylejcaron/kylejcaron.github.io/posts/experiment_strategy/coach_beard.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Useful Tools for Weibull Survival Analysis</title>
  <link>https://github.com/kylejcaron/kylejcaron.github.io/posts/weibull_survival_analysis/weibull_survival_tools.html</link>
  <description><![CDATA[ 




<section id="weibull-survival-analysis" class="level1">
<h1>Weibull Survival Analysis</h1>
<p>The Weibull distirbution is an excellent choice for many survival analysis problems - it has an interpretable parameterization that is highly flexible to a large number of phenomenon. The main advantage is that it can model how the risk of failure accelerates over time. This post will focus on the <img src="https://latex.codecogs.com/png.latex?%5Ctext%7BWeibull%7D(k,%20%5Clambda)"> parameterization, although I hope to cover the Gumbel reparameterization in the future.</p>
<p>This post requires some base understanding of survival analysis. I’ll try to have another post in the future that discusses survival analysis at a more introductory level</p>
<section id="a-quick-recap-on-survival-curves" class="level2">
<h2 class="anchored" data-anchor-id="a-quick-recap-on-survival-curves">A (quick) Recap on Survival Curves</h2>
<p>Survival Curves model time to some event (such as a failure) - they can tell you the probability of a binary event occurring at each future time point in somethings lifetime. An example survival curve is shown below:</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">from</span> typing <span class="im" style="color: #00769E;">import</span> <span class="op" style="color: #5E5E5E;">*</span></span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> pymc <span class="im" style="color: #00769E;">as</span> pm</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> matplotlib.ticker <span class="im" style="color: #00769E;">as</span> mtick</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> seaborn <span class="im" style="color: #00769E;">as</span> sns</span>
<span id="cb1-7"><span class="im" style="color: #00769E;">from</span> weibull <span class="im" style="color: #00769E;">import</span> Weibull</span>
<span id="cb1-8"><span class="im" style="color: #00769E;">import</span> scipy</span>
<span id="cb1-9">plt.style.use(<span class="st" style="color: #20794D;">"seaborn"</span>)</span>
<span id="cb1-10"></span>
<span id="cb1-11">k <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1.5</span></span>
<span id="cb1-12">lambd <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">30</span></span>
<span id="cb1-13"></span>
<span id="cb1-14">dist <span class="op" style="color: #5E5E5E;">=</span> Weibull(k, lambd)</span>
<span id="cb1-15">t <span class="op" style="color: #5E5E5E;">=</span> np.arange(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">101</span>)</span>
<span id="cb1-16">St <span class="op" style="color: #5E5E5E;">=</span>  dist.survival(t)</span>
<span id="cb1-17"></span>
<span id="cb1-18">fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">5</span>))</span>
<span id="cb1-19">ax.plot(t,St, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Survival Curve"</span>)</span>
<span id="cb1-20">ax.yaxis.set_major_formatter(mtick.PercentFormatter(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">0</span>))</span>
<span id="cb1-21">ax.set_xlabel(<span class="st" style="color: #20794D;">"Time"</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb1-22">ax.set_ylabel(<span class="st" style="color: #20794D;">"Survival probability"</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb1-23">ax.set_title(<span class="st" style="color: #20794D;">"How to Read a Survival Curve"</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb1-24">ax.legend(fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb1-25"></span>
<span id="cb1-26"><span class="co" style="color: #5E5E5E;"># Annotations</span></span>
<span id="cb1-27">xlim <span class="op" style="color: #5E5E5E;">=</span> ax.get_xlim()</span>
<span id="cb1-28">ylim <span class="op" style="color: #5E5E5E;">=</span> ax.get_ylim()</span>
<span id="cb1-29">x <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">20</span></span>
<span id="cb1-30">ax.vlines(x, <span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">0.05</span>, St[x<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>], color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"k"</span>, ls<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"--"</span>, alpha<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.75</span>, lw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1.5</span>)</span>
<span id="cb1-31">ax.hlines(St[x<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>], <span class="dv" style="color: #AD0000;">0</span>, x, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"k"</span>, ls<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"--"</span>, alpha<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.75</span>, lw<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">1.5</span>)</span>
<span id="cb1-32">ax.tick_params(axis<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'both'</span>, which<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'major'</span>, labelsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">14</span>)</span>
<span id="cb1-33"></span>
<span id="cb1-34">ax.annotate(<span class="ss" style="color: #20794D;">f'"There</span><span class="ch" style="color: #20794D;">\'</span><span class="ss" style="color: #20794D;">s a ~60% probability of an event </span><span class="ch" style="color: #20794D;">\n</span><span class="ss" style="color: #20794D;">still not occurring by time t=20"'</span>, </span>
<span id="cb1-35">        xy<span class="op" style="color: #5E5E5E;">=</span>(x,St[x<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>]),</span>
<span id="cb1-36">        xycoords<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"data"</span>, </span>
<span id="cb1-37">        xytext<span class="op" style="color: #5E5E5E;">=</span>(<span class="fl" style="color: #AD0000;">0.4</span>, <span class="fl" style="color: #AD0000;">0.8</span>),</span>
<span id="cb1-38">        textcoords<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'axes fraction'</span>,</span>
<span id="cb1-39">        arrowprops<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">dict</span>(facecolor<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'black'</span>, shrink<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.05</span>),</span>
<span id="cb1-40">        horizontalalignment<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'left'</span>,</span>
<span id="cb1-41">        verticalalignment<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">'top'</span>,</span>
<span id="cb1-42">        fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">12</span>,</span>
<span id="cb1-43">        bbox<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">dict</span>(boxstyle<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Round,pad=0.5"</span>, fc<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"white"</span>, ec<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"gray"</span>, lw<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb1-44">)</span>
<span id="cb1-45">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/posts/weibull_survival_analysis/weibull_survival_tools_files/figure-html/cell-2-output-1.png" width="697" height="457"></p>
</div>
</div>
<p>They basically tell you the probability of a unit not observing an event up until some time point.</p>
</section>
<section id="a-quick-recap-on-hazard-curves" class="level2">
<h2 class="anchored" data-anchor-id="a-quick-recap-on-hazard-curves">A (quick) Recap on Hazard Curves</h2>
<p>Hazard Curves are another way to think about survival analysis problems. A hazard curve tells you the instantaneous risk of an event occurring at each time point.</p>
<p>Hazard Curves tend to be very informative as they allow you to see how risk changes over time - sometimes it might decelerate, or sometimes it might even accelerate exponentially. Here’s an example of a hazard curve below.</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">k <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1.5</span></span>
<span id="cb2-2">lambd <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">30</span></span>
<span id="cb2-3"></span>
<span id="cb2-4">dist <span class="op" style="color: #5E5E5E;">=</span> Weibull(k, lambd)</span>
<span id="cb2-5">t <span class="op" style="color: #5E5E5E;">=</span> np.arange(<span class="dv" style="color: #AD0000;">1</span>, <span class="dv" style="color: #AD0000;">101</span>)</span>
<span id="cb2-6">ht <span class="op" style="color: #5E5E5E;">=</span>  dist.hazard(t)</span>
<span id="cb2-7"></span>
<span id="cb2-8">fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">5</span>))</span>
<span id="cb2-9">ax.plot(t,ht, label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Hazard Curve"</span>)</span>
<span id="cb2-10">ax.set_xlabel(<span class="st" style="color: #20794D;">"Time"</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb2-11">ax.set_ylabel(<span class="st" style="color: #20794D;">"Hazard Rate"</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb2-12">ax.set_title(<span class="st" style="color: #20794D;">"An Example Hazard Curve"</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb2-13">ax.legend(fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb2-14"></span>
<span id="cb2-15">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/posts/weibull_survival_analysis/weibull_survival_tools_files/figure-html/cell-3-output-1.png" width="675" height="452"></p>
</div>
</div>
</section>
</section>
<section id="textweibullk-lambda-parameter-interpretation" class="level1">
<h1><img src="https://latex.codecogs.com/png.latex?%5Ctext%7BWeibull%7D(k,%20%5Clambda)"> Parameter Interpretation</h1>
<p>Let’s quickly cover how to interpret the parameters - we’ll do this via simulation.</p>
<section id="the-k-parameter" class="level2">
<h2 class="anchored" data-anchor-id="the-k-parameter">The <img src="https://latex.codecogs.com/png.latex?k"> Parameter</h2>
<p>Sometimes also called <img src="https://latex.codecogs.com/png.latex?%5Crho">, this parameter controls the degree of acceleration of the hazard curve.</p>
<div class="cell" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">ks <span class="op" style="color: #5E5E5E;">=</span> [<span class="fl" style="color: #AD0000;">0.5</span>, <span class="dv" style="color: #AD0000;">1</span>, <span class="fl" style="color: #AD0000;">1.5</span>, <span class="dv" style="color: #AD0000;">2</span>, <span class="fl" style="color: #AD0000;">2.5</span>]</span>
<span id="cb3-2">lambd <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">30</span></span>
<span id="cb3-3">t <span class="op" style="color: #5E5E5E;">=</span> np.arange(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">51</span>)</span>
<span id="cb3-4"></span>
<span id="cb3-5">fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">5</span>))</span>
<span id="cb3-6"></span>
<span id="cb3-7"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="bu" style="color: null;">len</span>(ks)):</span>
<span id="cb3-8">    dist <span class="op" style="color: #5E5E5E;">=</span> Weibull(ks[i], lambd)</span>
<span id="cb3-9">    ht <span class="op" style="color: #5E5E5E;">=</span> dist.hazard(t)</span>
<span id="cb3-10">    ax.plot(t, ht, label<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"k=</span><span class="sc" style="color: #5E5E5E;">{</span>ks[i]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, lw<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb3-11"></span>
<span id="cb3-12">ax.set_xlabel(<span class="st" style="color: #20794D;">"Time"</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb3-13">ax.set_ylabel(<span class="st" style="color: #20794D;">"Hazard Rate"</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb3-14">ax.set_title(<span class="st" style="color: #20794D;">"Hazard Curves with Varying k Parameters"</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb3-15">ax.legend(fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb3-16">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/posts/weibull_survival_analysis/weibull_survival_tools_files/figure-html/cell-4-output-1.png" width="682" height="452"></p>
</div>
</div>
<p>As shown above, here’s how different parameter values impact acceleration:</p>
<ul>
<li><strong>When k &lt; 1:</strong> Hazard decelerates</li>
<li><strong>When k = 1:</strong> Hazard is constant. This is equivalent to an exponential distributions hazard function.</li>
<li><strong>When k &gt; 1:</strong> Hazard increases logarithmically</li>
<li><strong>When k = 2:</strong> Hazard increases with constant acceleration</li>
<li><strong>When k &gt; 2:</strong> Hazard increases exponentially</li>
</ul>
<p>Clothing is a great example of something where the hazard increases over time - the risk of a clothing item getting damaged obviously increases over time as the item is worn, washed, gets loose stitching, etc.</p>
</section>
<section id="the-lambda-parameter" class="level2">
<h2 class="anchored" data-anchor-id="the-lambda-parameter">The <img src="https://latex.codecogs.com/png.latex?%5Clambda"> Parameter</h2>
<p>Sometimes also referred to as a <em>scale parameter</em>, this parameter represents the time point where there’s a 63.2% probability of an event having occurred. Weird, I know, its just an arbitrary thing quality</p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">k <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1.5</span></span>
<span id="cb4-2">lambd <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">30</span></span>
<span id="cb4-3">dist <span class="op" style="color: #5E5E5E;">=</span> Weibull(k, lambd)</span>
<span id="cb4-4">t <span class="op" style="color: #5E5E5E;">=</span> np.linspace(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">100</span>, <span class="dv" style="color: #AD0000;">10000</span>)</span>
<span id="cb4-5">St <span class="op" style="color: #5E5E5E;">=</span> dist.survival(t)</span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="co" style="color: #5E5E5E;"># choose the point in the survival curve where the time is t=30</span></span>
<span id="cb4-8"><span class="co" style="color: #5E5E5E;"># take the inverse of it so that its the probability of an event having occurred by that time.</span></span>
<span id="cb4-9">(<span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">-</span>St[t<span class="op" style="color: #5E5E5E;">&gt;=</span>lambd][<span class="dv" style="color: #AD0000;">0</span>]).<span class="bu" style="color: null;">round</span>(<span class="dv" style="color: #AD0000;">4</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>0.6321</code></pre>
</div>
</div>
<p>Let’s see this visually as well - if you look at the plot below, each survival curve indicates that there’s a 63.2% probability of an event having occurred at the exact time that <img src="https://latex.codecogs.com/png.latex?t=%5Clambda"></p>
<div class="cell" data-execution_count="5">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1">ks <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1.5</span></span>
<span id="cb6-2">lambds <span class="op" style="color: #5E5E5E;">=</span> [<span class="dv" style="color: #AD0000;">15</span>, <span class="dv" style="color: #AD0000;">30</span>, <span class="dv" style="color: #AD0000;">60</span>, <span class="dv" style="color: #AD0000;">120</span>]</span>
<span id="cb6-3">t <span class="op" style="color: #5E5E5E;">=</span> np.arange(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">151</span>)</span>
<span id="cb6-4"></span>
<span id="cb6-5">fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">10</span>,<span class="dv" style="color: #AD0000;">5</span>))</span>
<span id="cb6-6"></span>
<span id="cb6-7"><span class="cf" style="color: #003B4F;">for</span> i <span class="kw" style="color: #003B4F;">in</span> <span class="bu" style="color: null;">range</span>(<span class="bu" style="color: null;">len</span>(lambds)):</span>
<span id="cb6-8">    dist <span class="op" style="color: #5E5E5E;">=</span> Weibull(k, lambds[i])</span>
<span id="cb6-9">    St <span class="op" style="color: #5E5E5E;">=</span> dist.survival(t)</span>
<span id="cb6-10">    ax.plot(t, St, label<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f"lambd=</span><span class="sc" style="color: #5E5E5E;">{</span>lambds[i]<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>, lw<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>)</span>
<span id="cb6-11">    ax.axvline(lambds[i],ls<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"--"</span>, alpha<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.5</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="ss" style="color: #20794D;">f'C</span><span class="sc" style="color: #5E5E5E;">{</span>i<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">'</span>)</span>
<span id="cb6-12"></span>
<span id="cb6-13">ax.axhline(<span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">0.632</span>, color<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"k"</span>, ls<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"--"</span>, alpha<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.75</span>,</span>
<span id="cb6-14">    label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Point where there's a 63.2% probability</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">of the event having occurred</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">by that time"</span>)</span>
<span id="cb6-15"></span>
<span id="cb6-16">ax.set_xlabel(<span class="st" style="color: #20794D;">"Time"</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb6-17">ax.set_ylabel(<span class="st" style="color: #20794D;">"Hazard Rate"</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb6-18">ax.set_title(<span class="st" style="color: #20794D;">"Hazard Curves with Varying k Parameters"</span>, fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">16</span>)</span>
<span id="cb6-19">ax.legend(fontsize<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">12</span>, loc<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"upper right"</span>)</span>
<span id="cb6-20">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/posts/weibull_survival_analysis/weibull_survival_tools_files/figure-html/cell-6-output-1.png" width="816" height="452"></p>
</div>
</div>
</section>
</section>
<section id="using-learned-parameters-for-applied-statistics" class="level1">
<h1>Using learned parameters for Applied Statistics</h1>
<p>Ok so lets say you have some estimator that learns the parameters of the weibull distribution - the goal here is to show different ways you can work with these parameters to make predictions</p>
<section id="easier-predictions-lifetime-survival-curves-and-hazard-curves" class="level2">
<h2 class="anchored" data-anchor-id="easier-predictions-lifetime-survival-curves-and-hazard-curves">Easier Predictions: Lifetime, Survival Curves, and Hazard Curves</h2>
<p>Average lifetime, Survival Curves, and Hazard Curves are the basic types of predictions for working with survival analysis. Most distributions have formulas that make these things easier to calculate. Below is the underlying code for these functions.</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="kw" style="color: #003B4F;">class</span> Weibull:</span>
<span id="cb7-2"></span>
<span id="cb7-3">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, k, lambd):</span>
<span id="cb7-4">        <span class="va" style="color: #111111;">self</span>.k <span class="op" style="color: #5E5E5E;">=</span> k</span>
<span id="cb7-5">        <span class="va" style="color: #111111;">self</span>.lambd <span class="op" style="color: #5E5E5E;">=</span> lambd</span>
<span id="cb7-6"></span>
<span id="cb7-7">    ...</span>
<span id="cb7-8"></span>
<span id="cb7-9">    <span class="kw" style="color: #003B4F;">def</span> expectation(<span class="va" style="color: #111111;">self</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> np.array:</span>
<span id="cb7-10">        <span class="co" style="color: #5E5E5E;">'''Calculates the expectation of the weibull distribution</span></span>
<span id="cb7-11"><span class="co" style="color: #5E5E5E;">        '''</span></span>
<span id="cb7-12">        <span class="cf" style="color: #003B4F;">return</span> <span class="va" style="color: #111111;">self</span>.lambd <span class="op" style="color: #5E5E5E;">*</span> sp.gamma(<span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">/</span><span class="va" style="color: #111111;">self</span>.k)</span>
<span id="cb7-13"></span>
<span id="cb7-14">    <span class="kw" style="color: #003B4F;">def</span> survival(<span class="va" style="color: #111111;">self</span>, t: np.array) <span class="op" style="color: #5E5E5E;">-&gt;</span> np.array:</span>
<span id="cb7-15">        <span class="co" style="color: #5E5E5E;">'''Outputs the survival probability at each time point T. This is done with the survival function, </span></span>
<span id="cb7-16"><span class="co" style="color: #5E5E5E;">        the complement of the Weibull Distribution's PDF.</span></span>
<span id="cb7-17"></span>
<span id="cb7-18"><span class="co" style="color: #5E5E5E;">        Parameters</span></span>
<span id="cb7-19"><span class="co" style="color: #5E5E5E;">        -----------</span></span>
<span id="cb7-20"><span class="co" style="color: #5E5E5E;">            t: A numpy array with time points to calculate the survival curve,      </span></span>
<span id="cb7-21"><span class="co" style="color: #5E5E5E;">                utilizing the distributions parameters</span></span>
<span id="cb7-22"><span class="co" style="color: #5E5E5E;">        </span></span>
<span id="cb7-23"><span class="co" style="color: #5E5E5E;">        Returns</span></span>
<span id="cb7-24"><span class="co" style="color: #5E5E5E;">        -------</span></span>
<span id="cb7-25"><span class="co" style="color: #5E5E5E;">            St: A survival curve calculated over the inputted time period</span></span>
<span id="cb7-26"><span class="co" style="color: #5E5E5E;">        '''</span></span>
<span id="cb7-27">        CDF <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">-</span> <span class="va" style="color: #111111;">self</span>.cdf(t)</span>
<span id="cb7-28">        St <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">-</span> CDF</span>
<span id="cb7-29">        <span class="cf" style="color: #003B4F;">return</span> St</span>
<span id="cb7-30"></span>
<span id="cb7-31">    <span class="kw" style="color: #003B4F;">def</span> hazard(<span class="va" style="color: #111111;">self</span>, t: np.array) <span class="op" style="color: #5E5E5E;">-&gt;</span> np.array:</span>
<span id="cb7-32">        <span class="co" style="color: #5E5E5E;">'''Outputs the hazard rate at each time point T.</span></span>
<span id="cb7-33"></span>
<span id="cb7-34"><span class="co" style="color: #5E5E5E;">        Parameters</span></span>
<span id="cb7-35"><span class="co" style="color: #5E5E5E;">        -----------</span></span>
<span id="cb7-36"><span class="co" style="color: #5E5E5E;">            t: A numpy array with time points to calculate the survival curve,      </span></span>
<span id="cb7-37"><span class="co" style="color: #5E5E5E;">                utilizing the distributions parameters</span></span>
<span id="cb7-38"><span class="co" style="color: #5E5E5E;">        </span></span>
<span id="cb7-39"><span class="co" style="color: #5E5E5E;">        Returns</span></span>
<span id="cb7-40"><span class="co" style="color: #5E5E5E;">        -------</span></span>
<span id="cb7-41"><span class="co" style="color: #5E5E5E;">            St: A survival curve calculated over the inputted time period</span></span>
<span id="cb7-42"><span class="co" style="color: #5E5E5E;">        '''</span></span>
<span id="cb7-43">        ht <span class="op" style="color: #5E5E5E;">=</span> (<span class="va" style="color: #111111;">self</span>.k<span class="op" style="color: #5E5E5E;">/</span><span class="va" style="color: #111111;">self</span>.lambd)<span class="op" style="color: #5E5E5E;">*</span>(t<span class="op" style="color: #5E5E5E;">/</span><span class="va" style="color: #111111;">self</span>.lambd)<span class="op" style="color: #5E5E5E;">**</span>(<span class="va" style="color: #111111;">self</span>.k<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb7-44">        <span class="cf" style="color: #003B4F;">return</span> ht</span>
<span id="cb7-45">    </span>
<span id="cb7-46">    ...</span></code></pre></div>
<p>We already looked into hazard and survival curves - let’s take a look at estimating the average lifetime.</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">k <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1.5</span></span>
<span id="cb8-2">lambd <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">30</span></span>
<span id="cb8-3"></span>
<span id="cb8-4">dist <span class="op" style="color: #5E5E5E;">=</span> Weibull(k, lambd)</span>
<span id="cb8-5">Et <span class="op" style="color: #5E5E5E;">=</span> dist.expectation()    </span>
<span id="cb8-6"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Expected Average Lifetime = </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">round</span>(Et,<span class="dv" style="color: #AD0000;">1</span>)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Expected Average Lifetime = 27.1</code></pre>
</div>
</div>
<p>Does this align with reality? Lets simulate event times from the weibull distribution to find out</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">event_times <span class="op" style="color: #5E5E5E;">=</span> dist.sample(n<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1000000</span>)</span>
<span id="cb10-2"><span class="bu" style="color: null;">print</span>(<span class="ss" style="color: #20794D;">f"Simulated Average Lifetime = </span><span class="sc" style="color: #5E5E5E;">{</span><span class="bu" style="color: null;">round</span>(event_times.mean(),<span class="dv" style="color: #AD0000;">1</span>)<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Simulated Average Lifetime = 27.1</code></pre>
</div>
</div>
</section>
<section id="predicting-residual-remaining-life" class="level2">
<h2 class="anchored" data-anchor-id="predicting-residual-remaining-life">Predicting Residual Remaining Life</h2>
<p>Another common and useful prediction you may want to present is the remaining life. There are a few different ways to calculate this:</p>
<pre><code>1. Use the formula</code></pre>
<p><img src="https://latex.codecogs.com/png.latex?%0AMRL(t)%20=%20%5Cfrac%7B%5Clambda%20%5C:%20%5CGamma(1%20+%201/k,%20(%5Cfrac%7Bt%7D%7B%5Clambda%7D)%5Ek)%7D%7BS(t)%7D%20-%20t%0A"></p>
<p>And we can see it implemented in python below:</p>
<div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="kw" style="color: #003B4F;">class</span> Weibull:</span>
<span id="cb13-2"></span>
<span id="cb13-3">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, k, lambd):</span>
<span id="cb13-4">        <span class="va" style="color: #111111;">self</span>.k <span class="op" style="color: #5E5E5E;">=</span> k</span>
<span id="cb13-5">        <span class="va" style="color: #111111;">self</span>.lambd <span class="op" style="color: #5E5E5E;">=</span> lambd</span>
<span id="cb13-6"></span>
<span id="cb13-7">    ...</span>
<span id="cb13-8"></span>
<span id="cb13-9">    <span class="kw" style="color: #003B4F;">def</span> mean_residual_life(<span class="va" style="color: #111111;">self</span>, t: np.array) <span class="op" style="color: #5E5E5E;">-&gt;</span> np.array:</span>
<span id="cb13-10">        t <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>._normalize_to_array(t)</span>
<span id="cb13-11">        St <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>.survival(t)</span>
<span id="cb13-12">        numerator <span class="op" style="color: #5E5E5E;">=</span> (</span>
<span id="cb13-13">            <span class="va" style="color: #111111;">self</span>.lambd </span>
<span id="cb13-14">            <span class="op" style="color: #5E5E5E;">*</span> sp.gammaincc(<span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">/</span><span class="va" style="color: #111111;">self</span>.k, (t<span class="op" style="color: #5E5E5E;">/</span><span class="va" style="color: #111111;">self</span>.lambd)<span class="op" style="color: #5E5E5E;">**</span><span class="va" style="color: #111111;">self</span>.k)</span>
<span id="cb13-15">            <span class="op" style="color: #5E5E5E;">*</span> sp.gamma(<span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">/</span><span class="va" style="color: #111111;">self</span>.k))</span>
<span id="cb13-16"></span>
<span id="cb13-17">        result <span class="op" style="color: #5E5E5E;">=</span> np.divide(</span>
<span id="cb13-18">            numerator,</span>
<span id="cb13-19">            St,</span>
<span id="cb13-20">            out<span class="op" style="color: #5E5E5E;">=</span>np.zeros_like(numerator),</span>
<span id="cb13-21">            where<span class="op" style="color: #5E5E5E;">=</span>St<span class="op" style="color: #5E5E5E;">!=</span><span class="dv" style="color: #AD0000;">0</span></span>
<span id="cb13-22">        ) <span class="op" style="color: #5E5E5E;">-</span> t[:,<span class="va" style="color: #111111;">None</span>]</span>
<span id="cb13-23">        </span>
<span id="cb13-24">        <span class="co" style="color: #5E5E5E;"># The code above returns negative values when St=0. This clipping corrects those cases</span></span>
<span id="cb13-25">        <span class="cf" style="color: #003B4F;">return</span> np.clip(result, <span class="dv" style="color: #AD0000;">0</span>, np.inf)</span></code></pre></div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">curr_time <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">40</span></span>
<span id="cb14-2">k, lambd <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1.5</span>, <span class="dv" style="color: #AD0000;">30</span></span>
<span id="cb14-3">dist <span class="op" style="color: #5E5E5E;">=</span> Weibull(k,lambd)</span>
<span id="cb14-4">remaining_life <span class="op" style="color: #5E5E5E;">=</span> dist.mean_residual_life(curr_time)</span></code></pre></div>
</div>
<pre><code>2. Simulate</code></pre>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb16" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1">T <span class="op" style="color: #5E5E5E;">=</span> dist.sample(n<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10000000</span>)</span>
<span id="cb16-2">units_reached_curr_time <span class="op" style="color: #5E5E5E;">=</span> T[T<span class="op" style="color: #5E5E5E;">&gt;</span>curr_time] <span class="op" style="color: #5E5E5E;">-</span> curr_time</span>
<span id="cb16-3">remaining_life_simulated <span class="op" style="color: #5E5E5E;">=</span> units_reached_curr_time.mean()</span></code></pre></div>
</div>
<p>With truncated sampling, this can also be more efficient</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb17" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1">T_cond <span class="op" style="color: #5E5E5E;">=</span> dist.sample(n<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">10000000</span>,left_trunc<span class="op" style="color: #5E5E5E;">=</span>curr_time) <span class="op" style="color: #5E5E5E;">-</span> curr_time</span>
<span id="cb17-2">remaining_life_simulated2 <span class="op" style="color: #5E5E5E;">=</span> T_cond.mean()</span></code></pre></div>
</div>
<pre><code>3. Transform the hazard curve</code></pre>
<p>There’s a convenient relationship between the hazard curves, survival curves, and expectations. It turns out that</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS(t)%20=%20%5Ctext%7Bexp%7D(-Ht)%0A"></p>
<p>where <img src="https://latex.codecogs.com/png.latex?Ht"> is the cumulative hazard function. Additionally, the expectation is just the integral of the survival function</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AE%5BT%5D%20=%20%5Cint_%7Bt=0%7D%5E%5Cinfty%20S(t)%20%5C,%20dt%0A"></p>
<p>Using these relationships, we can 1. take the hazard curve from time 40 onwards 2. turn it into the cumulative hazard 3. transform that into a survival curve 4. integrate the survival curve into an expectation</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb19" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1">ht <span class="op" style="color: #5E5E5E;">=</span> dist.hazard(np.arange(curr_time, curr_time<span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1000</span>))</span>
<span id="cb19-2">Ht <span class="op" style="color: #5E5E5E;">=</span> ht.cumsum()</span>
<span id="cb19-3">St <span class="op" style="color: #5E5E5E;">=</span> np.exp(<span class="op" style="color: #5E5E5E;">-</span>Ht)</span>
<span id="cb19-4">remaining_life_from_hazard <span class="op" style="color: #5E5E5E;">=</span> scipy.integrate.simps(St)</span></code></pre></div>
</div>
<p>Comparing all of these methods we end up with the following:</p>
<div class="cell" data-execution_count="12">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb20" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><span class="bu" style="color: null;">print</span>(</span>
<span id="cb20-2">    <span class="st" style="color: #20794D;">"Remaining Life (from formula) = </span><span class="sc" style="color: #5E5E5E;">{:.4}</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(remaining_life.ravel()[<span class="dv" style="color: #AD0000;">0</span>]),</span>
<span id="cb20-3">    <span class="st" style="color: #20794D;">"Remaining Life (from simulation) = </span><span class="sc" style="color: #5E5E5E;">{:.4}</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(remaining_life_simulated),</span>
<span id="cb20-4">    <span class="st" style="color: #20794D;">"Remaining Life (from truncated simulation) = </span><span class="sc" style="color: #5E5E5E;">{:.4}</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(remaining_life_simulated2),</span>
<span id="cb20-5">    <span class="st" style="color: #20794D;">"Remaining Life (manually calculated from hazard) = </span><span class="sc" style="color: #5E5E5E;">{:.4}</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">"</span>.<span class="bu" style="color: null;">format</span>(remaining_life_from_hazard)</span>
<span id="cb20-6">)</span></code></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Remaining Life (from formula) = 15.05
 Remaining Life (from simulation) = 15.04
 Remaining Life (from truncated simulation) = 15.05
 Remaining Life (manually calculated from hazard) = 14.14
</code></pre>
</div>
</div>
<p>They’re all very close, but it looks like theres some slight error when manually calculating (and its more complicated).</p>
</section>
<section id="calculating-conditional-survival-curves" class="level2">
<h2 class="anchored" data-anchor-id="calculating-conditional-survival-curves">Calculating Conditional Survival Curves</h2>
<p>The last type of prediction we’ll show here is conditional survival. This is basically saying “what’s the survival curve if we’ve made it up to time=t?”</p>
<p>It turns out, all you have to do is calculate the survival curve and normalize it by the eligible area of the distirbution. This basically means calculating a survival curve past the current time, and then dividing it by the survival function at the current time of interest.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0AS(t%7C%5Ctext%7Bcurr%20time%7D=40)%20=%20S(t)/S(40)%0A"></p>
<p>It was pretty easy to add that to the <code>Weibull.survival()</code> function from earlier:</p>
<div class="sourceCode" id="cb22" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><span class="kw" style="color: #003B4F;">class</span> Weibull:</span>
<span id="cb22-2"></span>
<span id="cb22-3">    <span class="kw" style="color: #003B4F;">def</span> <span class="fu" style="color: #4758AB;">__init__</span>(<span class="va" style="color: #111111;">self</span>, k, lambd):</span>
<span id="cb22-4">        <span class="va" style="color: #111111;">self</span>.k <span class="op" style="color: #5E5E5E;">=</span> k</span>
<span id="cb22-5">        <span class="va" style="color: #111111;">self</span>.lambd <span class="op" style="color: #5E5E5E;">=</span> lambd</span>
<span id="cb22-6">    </span>
<span id="cb22-7">    ...</span>
<span id="cb22-8"></span>
<span id="cb22-9">    <span class="kw" style="color: #003B4F;">def</span> survival(<span class="va" style="color: #111111;">self</span>, t: np.array, curr_time: Optional[<span class="bu" style="color: null;">int</span>] <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">None</span>) <span class="op" style="color: #5E5E5E;">-&gt;</span> np.array:</span>
<span id="cb22-10">        <span class="co" style="color: #5E5E5E;">'''Outputs the survival probability at each time point T. This is done with the survival function, </span></span>
<span id="cb22-11"><span class="co" style="color: #5E5E5E;">        the complement of the Weibull Distribution's PDF.</span></span>
<span id="cb22-12"></span>
<span id="cb22-13"><span class="co" style="color: #5E5E5E;">        Can also be used to calculate conditional survival with the `curr_time` argument.</span></span>
<span id="cb22-14"></span>
<span id="cb22-15"><span class="co" style="color: #5E5E5E;">        Parameters</span></span>
<span id="cb22-16"><span class="co" style="color: #5E5E5E;">        -----------</span></span>
<span id="cb22-17"><span class="co" style="color: #5E5E5E;">            t: A numpy array with time points to calculate the survival curve,      </span></span>
<span id="cb22-18"><span class="co" style="color: #5E5E5E;">                utilizing the distributions parameters</span></span>
<span id="cb22-19"><span class="co" style="color: #5E5E5E;">            curr_time: Used to calculate the survival curve given already reaching </span></span>
<span id="cb22-20"><span class="co" style="color: #5E5E5E;">                some point in time, `curr_time`.</span></span>
<span id="cb22-21"><span class="co" style="color: #5E5E5E;">        </span></span>
<span id="cb22-22"><span class="co" style="color: #5E5E5E;">        Returns</span></span>
<span id="cb22-23"><span class="co" style="color: #5E5E5E;">        -------</span></span>
<span id="cb22-24"><span class="co" style="color: #5E5E5E;">            St: A survival curve calculated over the inputted time period</span></span>
<span id="cb22-25"><span class="co" style="color: #5E5E5E;">        '''</span></span>
<span id="cb22-26">        <span class="co" style="color: #5E5E5E;"># Normalizing constant used for conditional survival</span></span>
<span id="cb22-27">        norm <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">1</span> <span class="cf" style="color: #003B4F;">if</span> curr_time <span class="kw" style="color: #003B4F;">is</span> <span class="va" style="color: #111111;">None</span> <span class="cf" style="color: #003B4F;">else</span> <span class="va" style="color: #111111;">self</span>.survival(curr_time)</span>
<span id="cb22-28">        </span>
<span id="cb22-29">        <span class="co" style="color: #5E5E5E;"># check inputs</span></span>
<span id="cb22-30">        t <span class="op" style="color: #5E5E5E;">=</span> <span class="va" style="color: #111111;">self</span>._normalize_to_array(t)</span>
<span id="cb22-31">        <span class="cf" style="color: #003B4F;">if</span> curr_time <span class="kw" style="color: #003B4F;">is</span> <span class="kw" style="color: #003B4F;">not</span> <span class="va" style="color: #111111;">None</span> <span class="kw" style="color: #003B4F;">and</span> (t <span class="op" style="color: #5E5E5E;">&lt;</span> curr_time).<span class="bu" style="color: null;">sum</span>() <span class="op" style="color: #5E5E5E;">&gt;</span> <span class="dv" style="color: #AD0000;">1</span>:</span>
<span id="cb22-32">            <span class="cf" style="color: #003B4F;">raise</span> <span class="pp" style="color: #AD0000;">ValueError</span>(<span class="st" style="color: #20794D;">'t&lt;curr_time. t must be greater than or equal to curr_time'</span>)</span>
<span id="cb22-33">        </span>
<span id="cb22-34">        St <span class="op" style="color: #5E5E5E;">=</span> (<span class="dv" style="color: #AD0000;">1</span> <span class="op" style="color: #5E5E5E;">-</span> <span class="va" style="color: #111111;">self</span>.cdf(t))<span class="op" style="color: #5E5E5E;">/</span>norm</span>
<span id="cb22-35">        <span class="cf" style="color: #003B4F;">return</span> St</span></code></pre></div>
<p>And as we can see below, it lines up perfectly with an empirically calculated kaplan meier curve</p>
<div class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb23" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><span class="im" style="color: #00769E;">from</span> lifelines <span class="im" style="color: #00769E;">import</span> KaplanMeierFitter</span>
<span id="cb23-2"></span>
<span id="cb23-3">curr_time <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">40</span></span>
<span id="cb23-4">T_cond <span class="op" style="color: #5E5E5E;">=</span> dist.sample(<span class="dv" style="color: #AD0000;">1000000</span>, left_trunc<span class="op" style="color: #5E5E5E;">=</span>curr_time) <span class="op" style="color: #5E5E5E;">-</span> curr_time</span>
<span id="cb23-5">kmf <span class="op" style="color: #5E5E5E;">=</span> KaplanMeierFitter()</span>
<span id="cb23-6">kmf.fit(T_cond)</span>
<span id="cb23-7">kmf.plot_survival_function(lw<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">5</span>, ls<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"--"</span>)</span>
<span id="cb23-8"></span>
<span id="cb23-9">plt.plot(dist.survival(t<span class="op" style="color: #5E5E5E;">=</span>np.arange(<span class="dv" style="color: #AD0000;">40</span>, <span class="dv" style="color: #AD0000;">200</span><span class="op" style="color: #5E5E5E;">+</span><span class="dv" style="color: #AD0000;">1</span>), curr_time<span class="op" style="color: #5E5E5E;">=</span>curr_time), label<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"Conditional Survival Curve"</span>)</span>
<span id="cb23-10">plt.legend()</span>
<span id="cb23-11">plt.ylabel(<span class="st" style="color: #20794D;">"Conditional Survival Rate"</span>)</span>
<span id="cb23-12">plt.title(<span class="ss" style="color: #20794D;">f"Conditional Survival Given a Unit Reached Time=</span><span class="sc" style="color: #5E5E5E;">{</span>curr_time<span class="sc" style="color: #5E5E5E;">}</span><span class="ss" style="color: #20794D;">"</span>)</span>
<span id="cb23-13">plt.show()</span></code></pre></div>
<div class="cell-output cell-output-display">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/posts/weibull_survival_analysis/weibull_survival_tools_files/figure-html/cell-14-output-1.png" width="662" height="478"></p>
</div>
</div>
<p>A convenient feature about survival curves is that if we want to know the probability of an event occurring in the next 1 time period, or 2 time periods, all we have to do is take the complement of the survival probability. So that means we can also use this method to calculate <em>“probability of an event occurring in the next 1 time period”</em></p>
</section>
</section>
<section id="conclusion" class="level1">
<h1>Conclusion</h1>
<p>That’s it for this post on working with Weibull Survival Analysis. There are also other re-parameterizations such as the Gumbel parameterization that I’d like to explore more later, but I found this collection of functionality really helpful in my work building out custom bayesian survival models.</p>


</section>

 ]]></description>
  <category>survival analysis</category>
  <guid>https://github.com/kylejcaron/kylejcaron.github.io/posts/weibull_survival_analysis/weibull_survival_tools.html</guid>
  <pubDate>Mon, 31 Oct 2022 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Why do we need A/B tests? The Potential Outcomes Model</title>
  <link>https://github.com/kylejcaron/kylejcaron.github.io/posts/experiment_design.html</link>
  <description><![CDATA[ 




<section id="overview" class="level1">
<h1>Overview</h1>
<p>This blog post introduces the Potential Outcomes Model and introduces why experiments are often necessary to measure what we want. This topic is already covered extensively in other more rigorous resources. This post provides just another example.</p>
</section>
<section id="the-potential-outcomes-model" class="level1">
<h1>The Potential Outcomes Model</h1>
<p>Let’s say we want to know the effect of of a customer support product on a customer outcome such as customer lifetime value LTV. Customers who might seem particularly upset when on the phone with customer support will be more likely to receive a promo code from the customer support staff, which we label as <img src="https://latex.codecogs.com/png.latex?T=1"> (or treatment = True). We represent the outcome, their customer lifetime value (assuming we can observe their full LTV), as <img src="https://latex.codecogs.com/png.latex?Y(1)">, which really just means <em>“what is the outcome Y for customers who had the treatment”</em>.</p>
<section id="a-hypothetical-world" class="level2">
<h2 class="anchored" data-anchor-id="a-hypothetical-world">A Hypothetical world</h2>
<p>What if we envision some hypothetical world we can observe the outcome for each customer who reached out to customer support, with and without having the treatment of receiving a promo?</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">import</span> pandas <span class="im" style="color: #00769E;">as</span> pd</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">import</span> numpy <span class="im" style="color: #00769E;">as</span> np</span>
<span id="cb1-3"><span class="im" style="color: #00769E;">import</span> scipy.special <span class="im" style="color: #00769E;">as</span> sp</span>
<span id="cb1-4"><span class="im" style="color: #00769E;">import</span> matplotlib.pyplot <span class="im" style="color: #00769E;">as</span> plt</span>
<span id="cb1-5"><span class="im" style="color: #00769E;">import</span> seaborn <span class="im" style="color: #00769E;">as</span> sns</span>
<span id="cb1-6"><span class="im" style="color: #00769E;">import</span> statsmodels.api <span class="im" style="color: #00769E;">as</span> sm</span>
<span id="cb1-7"></span>
<span id="cb1-8">rng <span class="op" style="color: #5E5E5E;">=</span> np.random.default_rng(<span class="dv" style="color: #AD0000;">100</span>)</span>
<span id="cb1-9"></span>
<span id="cb1-10">N<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">100_000</span></span>
<span id="cb1-11">upset <span class="op" style="color: #5E5E5E;">=</span> rng.normal(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>, N)</span>
<span id="cb1-12"></span>
<span id="cb1-13"><span class="kw" style="color: #003B4F;">def</span> sim_treatment(upset, rng, return_prob<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">False</span>):</span>
<span id="cb1-14">    beta <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">1.5</span></span>
<span id="cb1-15">    p_treatment <span class="op" style="color: #5E5E5E;">=</span> sp.expit( <span class="op" style="color: #5E5E5E;">-</span><span class="fl" style="color: #AD0000;">2.5</span> <span class="op" style="color: #5E5E5E;">+</span> upset <span class="op" style="color: #5E5E5E;">*</span> beta)</span>
<span id="cb1-16">    <span class="cf" style="color: #003B4F;">if</span> return_prob:</span>
<span id="cb1-17">        <span class="cf" style="color: #003B4F;">return</span> p_treatment</span>
<span id="cb1-18">    <span class="cf" style="color: #003B4F;">return</span> rng.binomial(<span class="dv" style="color: #AD0000;">1</span>, p_treatment)</span>
<span id="cb1-19"></span>
<span id="cb1-20"><span class="kw" style="color: #003B4F;">def</span> sim_outcome(upset, treatment, rng):</span>
<span id="cb1-21">    eps <span class="op" style="color: #5E5E5E;">=</span> rng.normal(<span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">150</span>, size<span class="op" style="color: #5E5E5E;">=</span><span class="bu" style="color: null;">len</span>(upset))</span>
<span id="cb1-22">    ltv <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">2500</span> <span class="op" style="color: #5E5E5E;">+</span> <span class="dv" style="color: #AD0000;">500</span><span class="op" style="color: #5E5E5E;">*</span>treatment <span class="op" style="color: #5E5E5E;">+</span> <span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">500</span><span class="op" style="color: #5E5E5E;">*</span>upset <span class="op" style="color: #5E5E5E;">+</span> eps </span>
<span id="cb1-23">    <span class="cf" style="color: #003B4F;">return</span> ltv.<span class="bu" style="color: null;">round</span>(<span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb1-24"></span>
<span id="cb1-25">data <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame({</span>
<span id="cb1-26">    <span class="st" style="color: #20794D;">"Person"</span>: np.arange(N),</span>
<span id="cb1-27">    <span class="st" style="color: #20794D;">"upset"</span>: upset,</span>
<span id="cb1-28">    <span class="st" style="color: #20794D;">"T"</span>: sim_treatment(upset, rng),</span>
<span id="cb1-29">    <span class="st" style="color: #20794D;">"Y(0)"</span>: sim_outcome(upset, np.zeros(N), rng),</span>
<span id="cb1-30">    <span class="st" style="color: #20794D;">"Y(1)"</span>: sim_outcome(upset, np.ones(N), rng)</span>
<span id="cb1-31">}).set_index(<span class="st" style="color: #20794D;">"Person"</span>)<span class="op" style="color: #5E5E5E;">\</span></span>
<span id="cb1-32">  .assign(ITE <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> d: d[<span class="st" style="color: #20794D;">"Y(1)"</span>] <span class="op" style="color: #5E5E5E;">-</span> d[<span class="st" style="color: #20794D;">"Y(0)"</span>])<span class="op" style="color: #5E5E5E;">\</span></span>
<span id="cb1-33">  .assign(Y <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> d: np.where(d[<span class="st" style="color: #20794D;">"T"</span>] <span class="op" style="color: #5E5E5E;">==</span> <span class="dv" style="color: #AD0000;">1</span>, d[<span class="st" style="color: #20794D;">"Y(1)"</span>], d[<span class="st" style="color: #20794D;">"Y(0)"</span>]) )</span>
<span id="cb1-34"></span>
<span id="cb1-35">data.head()[[<span class="st" style="color: #20794D;">"T"</span>, <span class="st" style="color: #20794D;">"Y(0)"</span>, <span class="st" style="color: #20794D;">"Y(1)"</span>, <span class="st" style="color: #20794D;">"ITE"</span>]]</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="1">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>T</th>
      <th>Y(0)</th>
      <th>Y(1)</th>
      <th>ITE</th>
    </tr>
    <tr>
      <th>Person</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3108.62</td>
      <td>3583.87</td>
      <td>475.25</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>2347.01</td>
      <td>2878.23</td>
      <td>531.22</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>2176.28</td>
      <td>2379.30</td>
      <td>203.02</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>2146.09</td>
      <td>2559.96</td>
      <td>413.87</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>2806.50</td>
      <td>3623.16</td>
      <td>816.66</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>As shown above, in this hypothetical world we can see the exact <strong>individual treatment effect (ITE)</strong> for every customer.</p>
<pre><code>- Person 0 would have spent $475.25 more over their lifetime  if they received the promo
- Person 2 would have spend $203.02 more over their lifetime if they received the promo</code></pre>
<p>If we want to know the <strong>Average Treatment Effect (ATE, often denoted <img src="https://latex.codecogs.com/png.latex?%5Ctau">)</strong>, all we have to do is take the mean of all of the individual treatment effects. As we can see, the ATE is about $500</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctau%20=%20%5Cfrac%7B1%7D%7BN%7D%20%5Csum%5E%7BN%7D_%7Bi=0%7D%20Y_i(1)%20-%20Y_i(0)%0A"></p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">data.ITE.mean()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>500.09949529999994</code></pre>
</div>
</div>
<p>We can also represent this in hypothetical terms that will be useful later - the <strong>average treatment effect of the treated (ATT)</strong>, and the <strong>average treatment effect of the untreated (ATU)</strong>. The true ATE ends up being the weighted average of these terms, weighted by the proportion of individuals seeing the treatment, <img src="https://latex.codecogs.com/png.latex?%5Cpi"></p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0A%5Ctau%20&amp;%20=%20%5Cpi%20%5Ccdot%20E%5B%5Ctau%20%7C%20T=1%5D%20+%20(1-%5Cpi)%20%5Ccdot%20E%5B%5Ctau%20%7C%20T=%200%5D%20%5C%5C%0A%20%20%20%20%20&amp;%20=%20%5Cpi%20%5Ccdot%20%5Ctext%7BATT%7D%20+%20(1-%5Cpi)%20%5Ccdot%20%5Ctext%7BATU%7D%0A%5Cend%7Balign%7D%0A"></p>
<p>We can confirm that this is equivalent to the ATE from above with code</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">pi <span class="op" style="color: #5E5E5E;">=</span> data[<span class="st" style="color: #20794D;">"T"</span>].value_counts(normalize<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb5-2">(pi <span class="op" style="color: #5E5E5E;">*</span> data.groupby(<span class="st" style="color: #20794D;">"T"</span>).mean()[<span class="st" style="color: #20794D;">"ITE"</span>]).<span class="bu" style="color: null;">sum</span>()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>500.0994953</code></pre>
</div>
</div>
</section>
<section id="getting-hit-with-the-real-world" class="level2">
<h2 class="anchored" data-anchor-id="getting-hit-with-the-real-world">Getting hit with the real world</h2>
<p>So how can we create a scenario where we can observe each person with and without having received the promo? Sadly, we can’t. But is there a way to make use of data we already have? Here’s the actual data we might have access to. Notice that now the hypothetical potential outcomes are no longer visible (just like in the real world).</p>
<div class="cell" data-execution_count="4">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="co" style="color: #5E5E5E;"># Real world data</span></span>
<span id="cb7-2">df <span class="op" style="color: #5E5E5E;">=</span> (</span>
<span id="cb7-3">    data[[<span class="st" style="color: #20794D;">"upset"</span>, <span class="st" style="color: #20794D;">"T"</span>, <span class="st" style="color: #20794D;">"Y(0)"</span>, <span class="st" style="color: #20794D;">"Y(1)"</span>, <span class="st" style="color: #20794D;">"ITE"</span>, <span class="st" style="color: #20794D;">"Y"</span>]]</span>
<span id="cb7-4">    .assign(<span class="op" style="color: #5E5E5E;">**</span>{</span>
<span id="cb7-5">        <span class="st" style="color: #20794D;">"Y(0)"</span>:<span class="kw" style="color: #003B4F;">lambda</span> d: np.where(d[<span class="st" style="color: #20794D;">"T"</span>]<span class="op" style="color: #5E5E5E;">==</span><span class="dv" style="color: #AD0000;">1</span>, np.NaN, d[<span class="st" style="color: #20794D;">"Y(0)"</span>]),</span>
<span id="cb7-6">        <span class="st" style="color: #20794D;">"Y(1)"</span>:<span class="kw" style="color: #003B4F;">lambda</span> d: np.where(d[<span class="st" style="color: #20794D;">"T"</span>]<span class="op" style="color: #5E5E5E;">==</span><span class="dv" style="color: #AD0000;">0</span>, np.NaN, d[<span class="st" style="color: #20794D;">"Y(1)"</span>]),</span>
<span id="cb7-7">        <span class="st" style="color: #20794D;">"ITE"</span>: np.NAN</span>
<span id="cb7-8">        })</span>
<span id="cb7-9">)</span>
<span id="cb7-10"></span>
<span id="cb7-11">df.iloc[:,<span class="dv" style="color: #AD0000;">1</span>:].head()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="4">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>T</th>
      <th>Y(0)</th>
      <th>Y(1)</th>
      <th>ITE</th>
      <th>Y</th>
    </tr>
    <tr>
      <th>Person</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3108.62</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3108.62</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>2347.01</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2347.01</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>NaN</td>
      <td>2379.3</td>
      <td>NaN</td>
      <td>2379.30</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>2146.09</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2146.09</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>2806.50</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2806.50</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>One (unfortunately incorrect) idea might be take the average of Y(1) and subtract the average of Y(0), also known as the <strong>simple difference in outcomes (SDO)</strong>.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BSDO%7D%20=%20E%5B%20Y(1)%20%7C%20T%20=%201%20%5D%20-%20E%5B%20Y(0)%20%7C%20T%20=%200%20%5D%0A"></p>
<blockquote class="blockquote">
<p>Notice that I use the terms <img src="https://latex.codecogs.com/png.latex?E%5B%20Y(0)%20%7C%20T%20=%200%20%5D"> and <img src="https://latex.codecogs.com/png.latex?E%5B%20Y(1)%20%7C%20T%20=%201%20%5D">. Reading these as plain english “the expected value (aka mean) of Y(0) given no treatment” and “the expected value (aka mean) of Y(1) given a treatment”</p>
</blockquote>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">(</span>
<span id="cb8-2">    df.groupby(<span class="st" style="color: #20794D;">"T"</span>)</span>
<span id="cb8-3">    .mean()[[<span class="st" style="color: #20794D;">"Y"</span>]].T</span>
<span id="cb8-4">    .assign(tau <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> d: d[<span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">-</span> d[<span class="dv" style="color: #AD0000;">0</span>])</span>
<span id="cb8-5">    .rename(columns<span class="op" style="color: #5E5E5E;">=</span>{<span class="dv" style="color: #AD0000;">0</span>:<span class="st" style="color: #20794D;">"E[ Y(0) | T = 0 ]"</span>, <span class="dv" style="color: #AD0000;">1</span>:<span class="st" style="color: #20794D;">"E[ Y(1) | T = 1 ]"</span>})</span>
<span id="cb8-6">    .rename_axis(<span class="va" style="color: #111111;">None</span>, axis<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb8-7">    .<span class="bu" style="color: null;">round</span>(<span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb8-8">    .reset_index(drop<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb8-9">)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>E[ Y(0) | T = 0 ]</th>
      <th>E[ Y(1) | T = 1 ]</th>
      <th>tau</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2579.46</td>
      <td>2491.48</td>
      <td>-87.98</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p><strong>Under the SDO it looks like the treatment has a negative effect</strong> - this is saying that giving customers a promo makes their LTV $88 worse? That seems seriously wrong, and is a huge problem. It should be $500 like we saw in our hypothetical world. So what went wrong?</p>
</section>
<section id="selection-bias" class="level2">
<h2 class="anchored" data-anchor-id="selection-bias">Selection Bias</h2>
<p>We can illustrate the problem by bringing another variable into the mix - customer unhappiness (we’re pretending we can measure it directly for examples sake).</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1">fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">2</span>, figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">8</span>,<span class="dv" style="color: #AD0000;">3</span>))</span>
<span id="cb9-2">ax[<span class="dv" style="color: #AD0000;">0</span>].set_title(<span class="st" style="color: #20794D;">"Histogram of</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">Customer unhappiness"</span>)</span>
<span id="cb9-3">df.upset.hist(ax<span class="op" style="color: #5E5E5E;">=</span>ax[<span class="dv" style="color: #AD0000;">0</span>])</span>
<span id="cb9-4"></span>
<span id="cb9-5">ax[<span class="dv" style="color: #AD0000;">1</span>].set_title(<span class="st" style="color: #20794D;">"More upset customers are</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">more likely to receive a promo"</span>)</span>
<span id="cb9-6">ax[<span class="dv" style="color: #AD0000;">1</span>].set_ylabel(<span class="st" style="color: #20794D;">"Proportion Receiving Promo"</span>)</span>
<span id="cb9-7">df.groupby(df.upset<span class="op" style="color: #5E5E5E;">//</span><span class="fl" style="color: #AD0000;">0.25</span><span class="op" style="color: #5E5E5E;">*</span><span class="fl" style="color: #AD0000;">0.25</span>).mean()[<span class="st" style="color: #20794D;">"T"</span>].plot(ax<span class="op" style="color: #5E5E5E;">=</span>ax[<span class="dv" style="color: #AD0000;">1</span>])</span>
<span id="cb9-8">plt.tight_layout()</span>
<span id="cb9-9"></span>
<span id="cb9-10">df.head()</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>upset</th>
      <th>T</th>
      <th>Y(0)</th>
      <th>Y(1)</th>
      <th>ITE</th>
      <th>Y</th>
    </tr>
    <tr>
      <th>Person</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.157550</td>
      <td>0</td>
      <td>3108.62</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3108.62</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.289756</td>
      <td>0</td>
      <td>2347.01</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2347.01</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.780854</td>
      <td>1</td>
      <td>NaN</td>
      <td>2379.3</td>
      <td>NaN</td>
      <td>2379.30</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.543974</td>
      <td>0</td>
      <td>2146.09</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2146.09</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.961383</td>
      <td>0</td>
      <td>2806.50</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2806.50</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<div class="cell-output cell-output-display">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/posts/experiment_design_files/figure-html/cell-7-output-2.png" width="758" height="279"></p>
</div>
</div>
<p>It looks like the most unhappy customers are the most likely to receive a treatment as shown in the DAG below.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<p>
<svg width="672" height="480" viewbox="0.00 0.00 220.71 188.00" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 184)">
<title>
G
</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-184 216.71,-184 216.71,4 -4,4"></polygon> <!-- a --> <g id="node1" class="node">
<title>
a
</title>
<ellipse fill="none" stroke="black" cx="122.22" cy="-162" rx="90.47" ry="18"></ellipse> <text text-anchor="middle" x="122.22" y="-157.8" font-family="Arial" font-size="14.00">unhappy customer</text> </g> <!-- b --> <g id="node2" class="node">
<title>
b
</title>
<ellipse fill="none" stroke="black" cx="72.22" cy="-90" rx="72.45" ry="18"></ellipse> <text text-anchor="middle" x="72.22" y="-85.8" font-family="Arial" font-size="14.00">receive promo</text> </g> <!-- a&#45;&gt;b --> <g id="edge1" class="edge">
<title>
a-&gt;b
</title>
<path fill="none" stroke="black" d="M110.12,-144.05C104.1,-135.63 96.71,-125.28 90.06,-115.97"></path> <polygon fill="black" stroke="black" points="92.87,-113.89 84.21,-107.79 87.18,-117.96 92.87,-113.89"></polygon> </g> <!-- c --> <g id="node3" class="node">
<title>
c
</title>
<ellipse fill="none" stroke="black" cx="122.22" cy="-18" rx="67.29" ry="18"></ellipse> <text text-anchor="middle" x="122.22" y="-13.8" font-family="Arial" font-size="14.00">lifetime value</text> </g> <!-- a&#45;&gt;c --> <g id="edge2" class="edge">
<title>
a-&gt;c
</title>
<path fill="none" stroke="black" d="M135.37,-143.91C142.14,-134.01 149.71,-120.96 153.22,-108 157.41,-92.56 157.41,-87.44 153.22,-72 150.64,-62.48 145.88,-52.92 140.84,-44.59"></path> <polygon fill="black" stroke="black" points="143.73,-42.6 135.37,-36.09 137.84,-46.39 143.73,-42.6"></polygon> </g> <!-- b&#45;&gt;c --> <g id="edge3" class="edge">
<title>
b-&gt;c
</title>
<path fill="none" stroke="black" d="M84.33,-72.05C90.34,-63.63 97.74,-53.28 104.39,-43.97"></path> <polygon fill="black" stroke="black" points="107.27,-45.96 110.23,-35.79 101.57,-41.89 107.27,-45.96"></polygon> </g> </g>
</svg>
</p>
</div>
</div>
</div>
<p>This is an example of <strong>selection bias</strong> (more specifically, its <strong>collider bias</strong>, a common confound). When comparing customers who had the treatment vs. didnt have the treatment, we accidentally also end up comparing unhappy customers vs.&nbsp;happier customers, and obviously unhappier customers tend to have worse lifetime value. <strong>We need to find a way to compare the impact of the treatment while controlling for the happiness of customers so that we are making a more fair comparison.</strong> For example, if we had 2 equally unhappy customers and 1 received the treatment while the other didnt, we’d get a more reasonable comparison for evaluating the treatment effect.</p>
</section>
<section id="identification-under-selection-bias" class="level2">
<h2 class="anchored" data-anchor-id="identification-under-selection-bias">Identification Under Selection bias</h2>
<p>How can we represent the scenario above with math? This is where the Potential Outcomes model starts coming into play. <em>Note I’m borrowing this directly from Scott Cunningham. For the full proof, see his book, <a href="https://mixtape.scunning.com/">Causal Inference the Mixtape</a></em>.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0A%5Ctext%7BSimple%20Difference%20in%20Outcomes%7D%0A&amp;=%20%5Cunderbrace%7BE%5BY(1)%5D%20-%20E%5BY(0)%5D%7D_%7B%20%5Ctext%7BAverage%20Treatment%20Effect%7D%7D%5C%5C%0A&amp;+%20%5Cunderbrace%7BE%5Cbig%5BY(0)%5Cmid%20T=1%5Cbig%5D%20-%20E%5Cbig%5BY(0)%5Cmid%20T=0%5Cbig%5D%7D_%7B%20%5Ctext%7BSelection%20bias%7D%7D%5C%5C%0A&amp;%20+%20%5Cunderbrace%7B(1-%5Cpi)(ATT%20-%20ATU)%7D_%7B%20%5Ctext%7BHeterogeneous%20treatment%20effect%20bias%7D%7D%0A%5Cend%7Balign%7D%0A"></p>
<p>This equation for the Potential Outcomes model basically says that anytime you make a comparison on observational data, it ends up being the sum of the true average treatment effect, selection bias, and Heterogeneous Treatment effect (HTE) bias. HTEs are just a fancy way of saying the personalized effect, aka promos might be more impactful for some users than others.</p>
<p>So how does this relate to what we did before? Well when we tried to compare users who saw the treatment vs.&nbsp;those that didnt</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Ctext%7BSDO%7D%20=%20E%5B%20Y(1)%20%7C%20T%20=%201%20%5D%20-%20E%5B%20Y(0)%20%7C%20T%20=%200%20%5D%0A"></p>
<p>we didnt take into account the fact that users who saw the treatment tend to be different than those who didn’t. Users who saw the treatment tend to be more unhappy by design.</p>
<p>So if we subtract out the <strong>selection bias</strong> from the SDO (I got this via simple algebra), aka we control for the unhappiness between customers, we can get closer to identifying the true ATE.</p>
<p>Note that selection bias was <img src="https://latex.codecogs.com/png.latex?%0AE%5Cbig%5BY(0)%5Cmid%20T=1%5Cbig%5D%20-%20E%5Cbig%5BY(0)%5Cmid%20T=0%5Cbig%5D%0A"></p>
<p>This is just saying selection bias is the fundamental difference between users who get picked for treatment vs.&nbsp;those who dont.</p>
<p>In our case, the fundamental difference between whether users are selected for treatment is based upon their unhappiness. So if we can subtract out the effect of unhappiness, we can subtract out the selection bias</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1">df.groupby(<span class="st" style="color: #20794D;">"T"</span>).mean()[[<span class="st" style="color: #20794D;">"upset"</span>]].T</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>T</th>
      <th>0</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>upset</th>
      <td>-0.159046</td>
      <td>1.018004</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>We can do this with OLS. The most obvious way is to fit a model relating unhappiness to LTV, and then subtract out that effect.</p>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1">model1 <span class="op" style="color: #5E5E5E;">=</span> sm.OLS.from_formula(<span class="st" style="color: #20794D;">"Y ~ upset"</span>, data<span class="op" style="color: #5E5E5E;">=</span>df.loc[<span class="kw" style="color: #003B4F;">lambda</span> d: d[<span class="st" style="color: #20794D;">"T"</span>]<span class="op" style="color: #5E5E5E;">==</span><span class="dv" style="color: #AD0000;">0</span>]).fit()</span>
<span id="cb11-2">Y0_hat <span class="op" style="color: #5E5E5E;">=</span> model1.predict(df)</span>
<span id="cb11-3"></span>
<span id="cb11-4">selection_bias <span class="op" style="color: #5E5E5E;">=</span> (</span>
<span id="cb11-5">    df.assign(selection_bias <span class="op" style="color: #5E5E5E;">=</span> Y0_hat)</span>
<span id="cb11-6">    .groupby(<span class="st" style="color: #20794D;">"T"</span>).mean()</span>
<span id="cb11-7">    [[<span class="st" style="color: #20794D;">"selection_bias"</span>]]</span>
<span id="cb11-8">)</span>
<span id="cb11-9">selection_bias.T.<span class="bu" style="color: null;">round</span>(<span class="dv" style="color: #AD0000;">2</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th>T</th>
      <th>0</th>
      <th>1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>selection_bias</th>
      <td>2579.46</td>
      <td>1990.96</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>And finally we can subtract out the effect, ending up with an estimate very close to the true ATE of 500</p>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1">(</span>
<span id="cb12-2">    df.assign(selection_bias <span class="op" style="color: #5E5E5E;">=</span> Y0_hat)</span>
<span id="cb12-3">    .groupby(<span class="st" style="color: #20794D;">"T"</span>).mean()[[<span class="st" style="color: #20794D;">"Y"</span>, <span class="st" style="color: #20794D;">"selection_bias"</span>]].T</span>
<span id="cb12-4">    .assign(difference <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> d: d[<span class="dv" style="color: #AD0000;">1</span>] <span class="op" style="color: #5E5E5E;">-</span> d[<span class="dv" style="color: #AD0000;">0</span>])</span>
<span id="cb12-5">    [[<span class="st" style="color: #20794D;">"difference"</span>]].T</span>
<span id="cb12-6">    .reset_index(drop<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>)</span>
<span id="cb12-7">    .rename(columns<span class="op" style="color: #5E5E5E;">=</span>{<span class="st" style="color: #20794D;">"Y"</span>:<span class="st" style="color: #20794D;">"SDO"</span>})</span>
<span id="cb12-8">    .assign(tau <span class="op" style="color: #5E5E5E;">=</span> <span class="kw" style="color: #003B4F;">lambda</span> d: d.SDO <span class="op" style="color: #5E5E5E;">-</span> d.selection_bias)</span>
<span id="cb12-9">    .<span class="bu" style="color: null;">round</span>(<span class="dv" style="color: #AD0000;">2</span>)</span>
<span id="cb12-10">)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>SDO</th>
      <th>selection_bias</th>
      <th>tau</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-87.98</td>
      <td>-588.5</td>
      <td>500.52</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>There’s actually an even more simple way to control for selection bias - it can just be included as a term in an OLS regression model.</p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="kw" style="color: #003B4F;">def</span> statsmodels_to_df(model):</span>
<span id="cb13-2">    table <span class="op" style="color: #5E5E5E;">=</span> np.array(model.summary().tables[<span class="dv" style="color: #AD0000;">1</span>].data)</span>
<span id="cb13-3">    <span class="cf" style="color: #003B4F;">return</span> pd.DataFrame(table[<span class="dv" style="color: #AD0000;">1</span>:, <span class="dv" style="color: #AD0000;">1</span>:], columns<span class="op" style="color: #5E5E5E;">=</span>table[<span class="dv" style="color: #AD0000;">0</span>,<span class="dv" style="color: #AD0000;">1</span>:], index<span class="op" style="color: #5E5E5E;">=</span>table[<span class="dv" style="color: #AD0000;">1</span>:,<span class="dv" style="color: #AD0000;">0</span>])</span>
<span id="cb13-4"></span>
<span id="cb13-5">model2 <span class="op" style="color: #5E5E5E;">=</span> sm.OLS.from_formula(<span class="st" style="color: #20794D;">" Y ~ T + upset"</span>, data<span class="op" style="color: #5E5E5E;">=</span>df).fit()</span>
<span id="cb13-6">statsmodels_to_df(model2)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">

<div>

<table class="dataframe table table-sm table-striped">
  <thead>
    <tr>
      <th></th>
      <th>coef</th>
      <th>std err</th>
      <th>t</th>
      <th>P&gt;|t|</th>
      <th>[0.025</th>
      <th>0.975]</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Intercept</th>
      <td>2499.9363</td>
      <td>0.516</td>
      <td>4847.317</td>
      <td>0.000</td>
      <td>2498.925</td>
      <td>2500.947</td>
    </tr>
    <tr>
      <th>T</th>
      <td>500.5529</td>
      <td>1.502</td>
      <td>333.191</td>
      <td>0.000</td>
      <td>497.608</td>
      <td>503.497</td>
    </tr>
    <tr>
      <th>upset</th>
      <td>-500.0068</td>
      <td>0.518</td>
      <td>-965.940</td>
      <td>0.000</td>
      <td>-501.021</td>
      <td>-498.992</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<p>As we can see above the estimate of the treatment effect is the beta coefficient for <code>T</code> and it closely matches our manual estimate above.</p>
</section>
<section id="a-quick-note-on-heterogeneous-treatment-effects" class="level2">
<h2 class="anchored" data-anchor-id="a-quick-note-on-heterogeneous-treatment-effects">A quick note on Heterogeneous Treatment Effects</h2>
<p>We’ve controlled for selection bias, what about Heterogeneous Treatment Effect bias? We actually don’t need to control for these once we’ve controlled for selection bias. These average treatment effect ends up being the average of all of the HTEs of individuals, which is fine because as long as we’ve accounted for selection bias, the HTEs tend to cancel out. They’re essentially captured by the error term, <img src="https://latex.codecogs.com/png.latex?%5Cepsilon"> in OLS <img src="https://latex.codecogs.com/png.latex?%0Ay%20=%20%5Calpha%20+%20%5Cbeta%20X%20+%20%5Cepsilon%0A"></p>
<p>We can also see that in our code, where the distribution of true HTE bias from our hypothetical dataset is centered at zero. Any time we’ve accounted for all selection bias, the HTE should be zero centered and cancel itself out as N increases.</p>
<div class="cell" data-execution_count="11">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1">ATE <span class="op" style="color: #5E5E5E;">=</span> data[<span class="st" style="color: #20794D;">"ITE"</span>].mean()</span>
<span id="cb14-2">HTE <span class="op" style="color: #5E5E5E;">=</span> data.ITE.values <span class="op" style="color: #5E5E5E;">-</span> ATE</span>
<span id="cb14-3">sns.histplot(HTE)</span>
<span id="cb14-4">plt.xlabel(<span class="st" style="color: #20794D;">"HTE"</span>)</span>
<span id="cb14-5">plt.title(<span class="st" style="color: #20794D;">"Distribution of HTEs (each customers difference from the ATE)"</span>)</span>
<span id="cb14-6">plt.show()</span></code></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/posts/experiment_design_files/figure-html/cell-12-output-1.png" width="601" height="442"></p>
</div>
</div>
<p>The bias of HTEs for each person is just the distance their treatment effect is from the average treatment effect. Again, this follows the same property as the error term in OLS regression, which is why it can be such a powerful tool for causal inference <em>when used correctly</em>.</p>
</section>
</section>
<section id="why-are-ab-tests-needed" class="level1">
<h1>Why are A/B tests needed?</h1>
<p>We saw that when taking a simple difference in outcomes that we can end up with biased inference. Controlling for selection bias can help fix this, but we may not always be able to do so.</p>
<p>For instance, consider if we didn’t have data on customer unhappiness (which is more likely true than not in the real world) - how would we control for it?</p>
<p>In many cases we can’t, or even if we can (such as with Instrumental Variable Analysis), it’s very difficult. This is where randomization and A/B testing come into play.</p>
<p>Remember that the whole reason we had issues with measuring the ATE was because users treated ended up being fundamentally different from those that weren’t. But what if we made it so that its purely random who receives the treatment and who doesn’t? Then we’d expect the same level of unhappiness in each group, cancelling out any selection bias. HTEs would cancel out as well like before, and <strong>by randomizing, we find that the simple difference in outcomes equals the true average treatment effect</strong>.</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cbegin%7Balign%7D%0A%5Ctext%7BSimple%20Difference%20in%20Outcomes%7D%0A&amp;=%20%5Cunderbrace%7BE%5BY(1)%5D%20-%20E%5BY(0)%5D%7D_%7B%20%5Ctext%7BAverage%20Treatment%20Effect%7D%7D%5C%5C%0A&amp;+%20%5Cunderbrace%7B%20%5Ccancel%7BE%5Cbig%5BY(0)%5Cmid%20T=1%5Cbig%5D%20-%20E%5Cbig%5BY(0)%5Cmid%20T=0%5Cbig%5D%7D%7D_%7B%20%5Ctext%7BSelection%20bias%7D%7D%5C%5C%0A&amp;%20+%20%5Cunderbrace%7B%5Ccancel%7B(1-%5Cpi)(ATT%20-%20ATU)%7D%7D_%7B%20%5Ctext%7BHeterogeneous%20treatment%20effect%20bias%7D%7D%0A%5Cend%7Balign%7D%0A"></p>
<p>This is why randomization is so powerful, and why many people say A/B tests are the gold standard.</p>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<p>In this post we walked through the Potential Outcomes Model, showed how it applies to a fake data scenario, and then used it to tie back to why randomization works for A/B testing.</p>
</section>
<section id="additional-reading" class="level1">
<h1>Additional Reading</h1>
<p>This is just one example of many that exist out there. Here are some other examples I’ve come across:</p>
<ul>
<li>Scott Cunningham’s <a href="https://mixtape.scunning.com/04-potential_outcomes">“The Perfect Doctor” example</a> from <a href="https://mixtape.scunning.com/">Causal Inference: the Mixtape</a></li>
<li>Matheus Facure’s <a href="https://matheusfacure.github.io/python-causality-handbook/landing-page.html">Causal Inference for the Brave and True</a></li>
</ul>


</section>

 ]]></description>
  <category>experimentation</category>
  <guid>https://github.com/kylejcaron/kylejcaron.github.io/posts/experiment_design.html</guid>
  <pubDate>Sat, 17 Sep 2022 04:00:00 GMT</pubDate>
</item>
<item>
  <title>Making out of sample predictions with PyMC</title>
  <link>https://github.com/kylejcaron/kylejcaron.github.io/posts/2022-04-17-out-of-sample-pymc.html</link>
  <description><![CDATA[ 




<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>A cool thing about hierarchical models is that its easy to predict out of sample - i.e.&nbsp;if you want to make a prediction on a new zipcode, just sample from the state’s distribution (composed of the state average and variance across zip codes in that state).</p>
<p>In pymc3, it’s somewhat easy to accomplish this, but not as straightforward as we’d hope. This blog post will show a trick that lets you easily predict out of sample, and will reduce some of the overhead that comes from writing alot of custom prediction functions</p>
</section>
<section id="simulating-data" class="level1">
<h1>Simulating data</h1>
<p>I simulated a 2 level hierarchical model - for interpretability, I set it up as a state &gt; zipcode model. You can following along with the notebook <a href="https://github.com/kylejcaron/case_studies/blob/main/PyMC%20out%20of%20sample%20predictions.ipynb">here</a>. The data is as follows</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/out_of_sample/fig1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="using-categorical-variables" class="level1">
<h1>Using categorical variables</h1>
<p>Categorical variables are a somewhat new feature of pandas - they can store categories that aren’t in the observed data, and are an easy replacement for <code>pd.factorize()</code> (a common tool for those familiar with the bayesian workflow).</p>
<p>We can use these to trick pymc into thinking there’s a category with no observed data, and pymc ends up assigning the global distribution to that unobserved category, which we can simply reference in the future for any time we want to make a prediction on out of sample data.</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="co" style="color: #5E5E5E;"># Convert to categorical and add an `out_of_sample` category</span></span>
<span id="cb1-2">df <span class="op" style="color: #5E5E5E;">=</span> df.assign(state <span class="op" style="color: #5E5E5E;">=</span> pd.Categorical(df.state).add_categories(<span class="st" style="color: #20794D;">"out_of_sample"</span>))<span class="op" style="color: #5E5E5E;">\</span></span>
<span id="cb1-3">    .assign(zipcode <span class="op" style="color: #5E5E5E;">=</span> pd.Categorical(df.zipcode).add_categories(<span class="st" style="color: #20794D;">"out_of_sample"</span>))</span></code></pre></div>
</section>
<section id="fitting-the-model" class="level1">
<h1>Fitting the model</h1>
<p>We’ll use the codes from the categorical columns to index our model coefficients, and we’ll use the categories as coordinates for the model to map names to.</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1">coords<span class="op" style="color: #5E5E5E;">=</span>{</span>
<span id="cb2-2">    <span class="st" style="color: #20794D;">"state"</span>:df.state.cat.categories,</span>
<span id="cb2-3">    <span class="st" style="color: #20794D;">"zipcode"</span>:df.zipcode.cat.categories</span>
<span id="cb2-4">}</span>
<span id="cb2-5"></span>
<span id="cb2-6"><span class="kw" style="color: #003B4F;">def</span> hierarchical_normal(name, μ, dims):</span>
<span id="cb2-7">    <span class="co" style="color: #5E5E5E;">'''Adapted from Austin Rochford'''</span></span>
<span id="cb2-8">    Δ <span class="op" style="color: #5E5E5E;">=</span> pm.Normal(<span class="st" style="color: #20794D;">'Δ_</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(name), <span class="fl" style="color: #AD0000;">0.</span>, <span class="fl" style="color: #AD0000;">1.</span>, dims<span class="op" style="color: #5E5E5E;">=</span>dims)</span>
<span id="cb2-9">    σ <span class="op" style="color: #5E5E5E;">=</span> pm.Exponential(<span class="st" style="color: #20794D;">'σ_</span><span class="sc" style="color: #5E5E5E;">{}</span><span class="st" style="color: #20794D;">'</span>.<span class="bu" style="color: null;">format</span>(name), <span class="fl" style="color: #AD0000;">2.5</span>)</span>
<span id="cb2-10">    <span class="cf" style="color: #003B4F;">return</span> pm.Deterministic(name, μ <span class="op" style="color: #5E5E5E;">+</span> Δ <span class="op" style="color: #5E5E5E;">*</span> σ, dims<span class="op" style="color: #5E5E5E;">=</span>dims)</span>
<span id="cb2-11"></span>
<span id="cb2-12"></span>
<span id="cb2-13"><span class="cf" style="color: #003B4F;">with</span> pm.Model(coords<span class="op" style="color: #5E5E5E;">=</span>coords) <span class="im" style="color: #00769E;">as</span> model_nc:</span>
<span id="cb2-14">    </span>
<span id="cb2-15">    <span class="co" style="color: #5E5E5E;"># Observed Data tracking</span></span>
<span id="cb2-16">    state_ <span class="op" style="color: #5E5E5E;">=</span> pm.Data(<span class="st" style="color: #20794D;">"state_"</span>, df.state.cat.codes)</span>
<span id="cb2-17">    zip_ <span class="op" style="color: #5E5E5E;">=</span> pm.Data(<span class="st" style="color: #20794D;">"zip_"</span>, df.zipcode.cat.codes)</span>
<span id="cb2-18">    obs <span class="op" style="color: #5E5E5E;">=</span> pm.Data(<span class="st" style="color: #20794D;">"obs"</span>, df.y)</span>
<span id="cb2-19"></span>
<span id="cb2-20">    <span class="co" style="color: #5E5E5E;"># Hyperprior</span></span>
<span id="cb2-21">    mu_country <span class="op" style="color: #5E5E5E;">=</span> pm.Normal(<span class="st" style="color: #20794D;">"mu_country"</span>, <span class="dv" style="color: #AD0000;">0</span>, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb2-22">    </span>
<span id="cb2-23">    <span class="co" style="color: #5E5E5E;"># Prior</span></span>
<span id="cb2-24">    sig <span class="op" style="color: #5E5E5E;">=</span> pm.Exponential(<span class="st" style="color: #20794D;">"sig"</span>, <span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb2-25">    </span>
<span id="cb2-26">    <span class="co" style="color: #5E5E5E;"># Hierarchical coefficients</span></span>
<span id="cb2-27">    mu_state <span class="op" style="color: #5E5E5E;">=</span> hierarchical_normal(<span class="st" style="color: #20794D;">"mu_state"</span>, μ<span class="op" style="color: #5E5E5E;">=</span>mu_country, dims<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"state"</span>)</span>
<span id="cb2-28">    mu_zipcode <span class="op" style="color: #5E5E5E;">=</span> hierarchical_normal(<span class="st" style="color: #20794D;">"mu_zipcode"</span>, μ<span class="op" style="color: #5E5E5E;">=</span>mu_state, dims<span class="op" style="color: #5E5E5E;">=</span>(<span class="st" style="color: #20794D;">"zipcode"</span>, <span class="st" style="color: #20794D;">"state"</span>) )</span>
<span id="cb2-29">    </span>
<span id="cb2-30">    <span class="co" style="color: #5E5E5E;"># Observational model</span></span>
<span id="cb2-31">    y <span class="op" style="color: #5E5E5E;">=</span> pm.Normal(<span class="st" style="color: #20794D;">"y"</span>, mu_zipcode[zip_, state_], sig, observed<span class="op" style="color: #5E5E5E;">=</span>obs)</span>
<span id="cb2-32">    </span>
<span id="cb2-33">    <span class="co" style="color: #5E5E5E;"># Fit </span></span>
<span id="cb2-34">    trace_nc <span class="op" style="color: #5E5E5E;">=</span> pm.sample(target_accept<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.9</span>, return_inferencedata<span class="op" style="color: #5E5E5E;">=</span><span class="va" style="color: #111111;">True</span>, random_seed<span class="op" style="color: #5E5E5E;">=</span>SEED)</span></code></pre></div>
<p>There are a few key point that make out of sample prediction possible * Having the <code>out_of_sample</code> category for each indexed variable with no observed data * Passing the <code>coords</code> in the model statement * Using dims to reference which model coefficients have which coordinate labels * Having all of our input data wrapped in a <code>pm.Data()</code> statement</p>
<p>That last point is particularly important. For PyMC, if you want to make predictions on new data, you have to replace the data that the model references and the only way to do that (that I know of atleast) is to using a Theano shared variable. <code>pm.Data()</code> handles all of that fo you.</p>
<p>So we fit our model, lets take a quick look at the state level coefficients</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1">pm.plot_forest(trace_nc, var_names<span class="op" style="color: #5E5E5E;">=</span>[<span class="st" style="color: #20794D;">"mu_state"</span>])</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/out_of_sample/fig2.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Great, that out of sample variable seems to represent the <code>global</code> distribution across states - i.e.&nbsp;if we were to make a prediction for a new state we’d potentially use that distribtion (we’ll confirm further down).</p>
<p>We’ll check the zip code level below as well, looking at Maine specifically</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/out_of_sample/fig3.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>As we can see, the <code>out_of_sample</code> variable has a sampled value despite there being no observed data for it. Now the question is, does this align with how we’d predict new data?</p>
<p>Let’s try calculating coefficients out of sample by hand and see if it aligns with the out_of_sample values</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">post <span class="op" style="color: #5E5E5E;">=</span> trace_nc.posterior</span>
<span id="cb4-2"></span>
<span id="cb4-3"><span class="co" style="color: #5E5E5E;"># Pull the true data from our simulation</span></span>
<span id="cb4-4">state_true <span class="op" style="color: #5E5E5E;">=</span> mu_state_true.random(size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4000</span>)</span>
<span id="cb4-5"></span>
<span id="cb4-6"></span>
<span id="cb4-7"><span class="co" style="color: #5E5E5E;"># Calculate out of sample state means by drawing from global distribution</span></span>
<span id="cb4-8">mu_country <span class="op" style="color: #5E5E5E;">=</span> post[<span class="st" style="color: #20794D;">"mu_country"</span>].values.reshape(<span class="dv" style="color: #AD0000;">4000</span>,<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb4-9">σ_state <span class="op" style="color: #5E5E5E;">=</span> post[<span class="st" style="color: #20794D;">"σ_mu_state"</span>].values.reshape(<span class="dv" style="color: #AD0000;">4000</span>,<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb4-10">mu_state <span class="op" style="color: #5E5E5E;">=</span> np.random.normal(mu_country, σ_state)</span>
<span id="cb4-11"></span>
<span id="cb4-12"><span class="co" style="color: #5E5E5E;"># Using the indexing trick</span></span>
<span id="cb4-13">state_idx_trick <span class="op" style="color: #5E5E5E;">=</span> post[<span class="st" style="color: #20794D;">"mu_state"</span>].sel({<span class="st" style="color: #20794D;">"state"</span>:[<span class="st" style="color: #20794D;">"out_of_sample"</span>]}).values.ravel()</span>
<span id="cb4-14"></span>
<span id="cb4-15"><span class="co" style="color: #5E5E5E;"># Pull the true data from simulation</span></span>
<span id="cb4-16">zip_true <span class="op" style="color: #5E5E5E;">=</span> pm.Normal.dist(mu_state_true.random(size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4000</span>), sig_zip_true).random(size<span class="op" style="color: #5E5E5E;">=</span><span class="dv" style="color: #AD0000;">4000</span>)</span>
<span id="cb4-17"></span>
<span id="cb4-18"><span class="co" style="color: #5E5E5E;"># calculate out of sample mu by hand by drawing from out of sample state prediction above</span></span>
<span id="cb4-19">σ_zipcode <span class="op" style="color: #5E5E5E;">=</span> post[<span class="st" style="color: #20794D;">"σ_mu_zipcode"</span>].values.reshape(<span class="dv" style="color: #AD0000;">4000</span>,<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>)</span>
<span id="cb4-20">mu_zipcode <span class="op" style="color: #5E5E5E;">=</span> np.random.normal(mu_state, σ_zipcode)</span>
<span id="cb4-21"></span>
<span id="cb4-22"><span class="co" style="color: #5E5E5E;"># Use the indexing trick</span></span>
<span id="cb4-23">zip_idx_trick <span class="op" style="color: #5E5E5E;">=</span> (post[<span class="st" style="color: #20794D;">"mu_zipcode"</span>]</span>
<span id="cb4-24">                .sel({<span class="st" style="color: #20794D;">"state"</span>:[<span class="st" style="color: #20794D;">"out_of_sample"</span>], <span class="st" style="color: #20794D;">"zipcode"</span>:[<span class="st" style="color: #20794D;">"out_of_sample"</span>]})</span>
<span id="cb4-25">                .values.ravel())</span></code></pre></div>
<p>We can compare these results by plotting their distributions below</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/out_of_sample/fig4.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Notice that the manual prediction and the indexing trick are basically identical. There’s a slight difference from the ground truth, but thats to be expected since we’re fitting a model on limited data (and anyway, it’s still quite close).</p>
</section>
<section id="predicting-out-of-sample" class="level1">
<h1>Predicting out of sample</h1>
<p>Let’s go ahead and actually make prediction now - we’ll make predictions for the following data below</p>
<ul>
<li>The first example is in sample</li>
<li>The second example is in sample for state, out of sample for zipcode</li>
<li>The third example is out of sample entirely</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/out_of_sample/fig5.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>And finally we’ll use the model to make predictions on this new data. Notice the <code>pm.set_data()</code> function - remember our <code>pm.Data()</code> calls from before? This tells PyMC to override that with new data, so when we sample from the posterior predictive it makes predictions on the new data instead of the data used to fit the model.</p>
<details>
<summary>
Click here for helper function code
</summary>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="co" style="color: #5E5E5E;"># We're making some quick convenience functions to map this new data </span></span>
<span id="cb5-2"><span class="co" style="color: #5E5E5E;"># to the proper indexes from the fitted model</span></span>
<span id="cb5-3">zip_lookup <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">dict</span>(<span class="bu" style="color: null;">zip</span>(df.zipcode.cat.categories, <span class="bu" style="color: null;">range</span>(<span class="bu" style="color: null;">len</span>(df.zipcode.cat.categories))))</span>
<span id="cb5-4">state_lookup <span class="op" style="color: #5E5E5E;">=</span> <span class="bu" style="color: null;">dict</span>(<span class="bu" style="color: null;">zip</span>(df.state.cat.categories, <span class="bu" style="color: null;">range</span>(<span class="bu" style="color: null;">len</span>(df.state.cat.categories))))</span>
<span id="cb5-5"></span>
<span id="cb5-6"><span class="kw" style="color: #003B4F;">def</span> labels_to_index(series, lookup):</span>
<span id="cb5-7">    <span class="co" style="color: #5E5E5E;">'''Converts categories to their proper codes'''</span></span>
<span id="cb5-8">    series <span class="op" style="color: #5E5E5E;">=</span> series.copy()</span>
<span id="cb5-9">    in_sample <span class="op" style="color: #5E5E5E;">=</span> series.isin(lookup.keys())</span>
<span id="cb5-10">    series.loc[<span class="op" style="color: #5E5E5E;">~</span>in_sample] <span class="op" style="color: #5E5E5E;">=</span> <span class="st" style="color: #20794D;">"out_of_sample"</span></span>
<span id="cb5-11">    <span class="cf" style="color: #003B4F;">return</span> series.<span class="bu" style="color: null;">map</span>(lookup).values.astype(<span class="st" style="color: #20794D;">"int8"</span>)</span></code></pre></div>
</details>
<p><br></p>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="cf" style="color: #003B4F;">with</span> model_nc:</span>
<span id="cb6-2">    <span class="co" style="color: #5E5E5E;"># Set new data for the model to make predictions on</span></span>
<span id="cb6-3">    pm.set_data({</span>
<span id="cb6-4">        <span class="st" style="color: #20794D;">"state_"</span>: X.state.pipe(labels_to_index, state_lookup),</span>
<span id="cb6-5">        <span class="st" style="color: #20794D;">"zip_"</span>: X.zipcode.pipe(labels_to_index, zip_lookup)</span>
<span id="cb6-6">    })</span>
<span id="cb6-7">    </span>
<span id="cb6-8">    <span class="co" style="color: #5E5E5E;"># make predictions</span></span>
<span id="cb6-9">    preds <span class="op" style="color: #5E5E5E;">=</span> pm.sample_posterior_predictive(trace_nc)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/out_of_sample/fig6.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>This is exactly what we were looking for - and prediction is easy, just map any out of sample states or zipcodes to the <code>out_of_sample</code> category. Notice how in sample predictions have smaller uncertainty intervals and out of sample data is more uncertain - this is exactly what we’d expect. This trick makes it much easier to make predictions compared to having to write out a custom prediction function that follows the same logic as the model.</p>
<p>If you have any other easy tricks for out of sample prediction let me know!</p>


</section>

 ]]></description>
  <guid>https://github.com/kylejcaron/kylejcaron.github.io/posts/2022-04-17-out-of-sample-pymc.html</guid>
  <pubDate>Sun, 17 Apr 2022 04:00:00 GMT</pubDate>
  <media:content url="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/out_of_sample/fig1.png" medium="image" type="image/png" height="118" width="144"/>
</item>
<item>
  <title>How long should you run an A/B test for?</title>
  <link>https://github.com/kylejcaron/kylejcaron.github.io/posts/2022-04-05-ab-test-duration.html</link>
  <description><![CDATA[ 




<p>For some people in industry new to A/B testing, they might wonder “Why cant we just run an A/B test for 2 days and be done with it?”. Even those familiar with it might wonder why their team’s Data Scientist is insisting on so much. And even Data Scientists may be looking for easier ways to explain the need to them. The goal of this article is to cover just that, from a naive and explainable point of view.</p>
<p>So, <strong>How long should you run an A/B test for?</strong> Well let’s say you step into a casino with $5000 and you walk away with $6000. You just made a 20% return. Is it fair to say that a night out in the casino leads to a 20% return? Is it fair to say that our A/B test we ran for 2 days leads to a 20% lift in conversion? How do we know for sure?</p>
<p><strong>We should run an A/B test for as long as it takes to rule out random chance.</strong></p>
<p>While vague, and technically not the full picture, your friendly neightborhood data scientist should be able to answer this for you. The code for this blogpost can be found <a href="https://github.com/kylejcaron/case_studies/blob/master/How%20long%20should%20you%20run%20an%20AB%20Test%20for%3F.ipynb">here</a>.</p>
<p><br></p>
<section id="simulating-a-fake-scenario" class="level3">
<h3 class="anchored" data-anchor-id="simulating-a-fake-scenario">Simulating a fake scenario</h3>
<p>Let’s play out the casino example from above. I’m going to simulate out an entirely fake, but entirely possible scenario.</p>
<p>You go to the casino one night with $5000 and decide roulette is your game of choice. You get a little into it and play 500 rounds (in one night?? for examples sake, yes). Little do you know the real probability of winning is 48.5%</p>
<p>The plot below shows the total money you had at the start of each round of roulette</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/how_long_ab_test/fig1.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>This is great - after 500 rounds of this you’ve made 122% return on your initial investment of $5000 and you’re winning 51% of the time.</p>
<p>Playing roulette must lead to a 20% return right? Commited to your strategy you decide to come back over the next few weeks and play another 3000 rounds, shown below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/how_long_ab_test/fig2.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Alright you’ve played 3500 rounds now and you have $5400 total. You’ve definitely had some runs of bad luck, but you’re still seeing a win percentage above 50% (50.1% in fact) and right now you’re heating up. You stay determined and play until you reach 15000 rounds.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/how_long_ab_test/fig3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="what-happened" class="level1">
<h1>What happened?</h1>
<p>We started off on a hot streak winning 51% of our rounds, but as we played more and more rounds, it became more obvious we were losing money. This is a demonstration of the law of large numbers - as we play more and more rounds, the truth comes out</p>
<p>We can visualize this process via the beta distribution below. These plots visualize all of the possible values that the true win percentage could be (the x axis), and their relative plausibilities (the y axis). The first plot can be read as follows:</p>
<blockquote class="blockquote">
<p>The win percentage is likely to be somewhere between 42.5% and 60%, with the most likely value being around 51%</p>
</blockquote>
<p>As we move from left to right, our estimated distribution converges closer and closer to the true probability of winning a round</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/how_long_ab_test/fig4.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>We can also visualize this as a time series, which really makes it clear how the uncertainty becomes smaller over time and the estimated value converges to the true value.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/how_long_ab_test/fig5.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><br></p>
<section id="how-does-this-tie-back-to-ab-testing" class="level3">
<h3 class="anchored" data-anchor-id="how-does-this-tie-back-to-ab-testing">How does this tie back to A/B testing?</h3>
<p>If we don’t choose our sample size for an experiment properly, we can end up making the wrong decisions!<sup>1</sup> The larger the sample size we choose, the more likely we’ll make the right choice.</p>
<p>We can use <strong>power analyses</strong> (sometimes referred to as simulation studies) to estimate what sample size is needed for an experiment given the desired outcome.</p>
<hr>


</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Unless you’re using bayesian inference, which can really mitigate this risk.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <guid>https://github.com/kylejcaron/kylejcaron.github.io/posts/2022-04-05-ab-test-duration.html</guid>
  <pubDate>Fri, 15 Apr 2022 04:00:00 GMT</pubDate>
  <media:content url="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/how_long_ab_test/fig1.png" medium="image" type="image/png" height="80" width="144"/>
</item>
<item>
  <title>Uncertainty Intervals or p-values?</title>
  <link>https://github.com/kylejcaron/kylejcaron.github.io/posts/2022-04-11-uncertainty_intervals_over_pvals.html</link>
  <description><![CDATA[ 




<p>Uncertainty Intervals are better than p-values. Sure, its better to use both, but p-values are just a point estimate and they bring no concept of uncertainty in our estimate - this can lead to situations where we expose ourselves to high downside risk.</p>
<p>Take the following example for instance. Let’s say we’re running a “Do no harm” A/B test where we want to roll out an experiment as long as it doesnt harm conversion rate.</p>
<p>If you want to follow along with the code, <a href="https://github.com/kylejcaron/case_studies/blob/main/Uncertainty%20intervals%20over%20p%20values.ipynb">see here</a>.</p>
<section id="the-experiment-design" class="level2">
<h2 class="anchored" data-anchor-id="the-experiment-design">The experiment design</h2>
<p>Given the stakeholders want to rule out a drop in conversion, and ruling out small differences requires large sample sizes, we decide to design an experiment with good power to detect the presence of a 1/2% absolute drop (if one were to truly exist)</p>
<p>We ran a power analysis and found that in order to have a 90% probability of detecting (power=0.9) a 1/2% absolute drop in conversion rate with 80 percent confidence ( 𝛼=0.2 ), we need N=32500 per group</p>
<blockquote class="blockquote">
<p>Statisticians might not love this interpretation of a power analysis, but its a useful and interpretable translation and tends to coincide with what we’re aiming for anyway. In reality, frequentist power analyses assume that the null hypothesis is correct, which isn’t quite what we want, not to mention, frequentist power analyses use backwards probabilities which are just plain confusing - <a href="https://www.fharrell.com/post/pvalprobs/">see here to for more</a></p>
</blockquote>
<p>Note that we’re prioritizing power here for a reason. If 𝛼 is false positive rate, and power is probability of detection, then don’t we want to prioritize our probability of detecting a drop if one truly exists? A false negative here would be more expensive then a false positive</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1">pA <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.1</span> <span class="co" style="color: #5E5E5E;"># historical conversion rate</span></span>
<span id="cb1-2">abs_delta <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.005</span> <span class="co" style="color: #5E5E5E;"># minimum detectable effect to test for</span></span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;"># Statsmodels requires an effect size </span></span>
<span id="cb1-5"><span class="co" style="color: #5E5E5E;"># (aka an effect normalized by its standard deviation)</span></span>
<span id="cb1-6">stdev <span class="op" style="color: #5E5E5E;">=</span> np.sqrt( pA<span class="op" style="color: #5E5E5E;">*</span>(<span class="dv" style="color: #AD0000;">1</span><span class="op" style="color: #5E5E5E;">-</span>pA) ) <span class="co" style="color: #5E5E5E;"># bernoulli stdev, sigma = sqrt(p(1-p))</span></span>
<span id="cb1-7">ES <span class="op" style="color: #5E5E5E;">=</span> abs_delta <span class="op" style="color: #5E5E5E;">/</span> stdev </span>
<span id="cb1-8"></span>
<span id="cb1-9"><span class="co" style="color: #5E5E5E;"># estimate required sample size</span></span>
<span id="cb1-10">sm.stats.tt_ind_solve_power(</span>
<span id="cb1-11">    <span class="op" style="color: #5E5E5E;">-</span>ES, </span>
<span id="cb1-12">    alpha<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.2</span>,</span>
<span id="cb1-13">    power<span class="op" style="color: #5E5E5E;">=</span><span class="fl" style="color: #AD0000;">0.9</span>,</span>
<span id="cb1-14">    alternative<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"smaller"</span></span>
<span id="cb1-15">)</span></code></pre></div>
<p>Running the code above leads us to conclude are sample size should be roughly 32,500 users per group.</p>
<section id="the-experiment" class="level3">
<h3 class="anchored" data-anchor-id="the-experiment">The experiment</h3>
<p>I’m going to simulate fake data for this experiment where * The <strong>control</strong> has a <strong><em>true</em></strong> conversion rate of 10% * the <strong>variant</strong> has a <strong><em>true</em></strong> conversion rate of 9.25%</p>
<p>For examples sake we’ll pretend we don’t know that the variant is worse</p>
<details>
<summary>
Click here for code
</summary>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># Settings</span></span>
<span id="cb2-2">np.random.seed(<span class="dv" style="color: #AD0000;">1325</span>)</span>
<span id="cb2-3">N <span class="op" style="color: #5E5E5E;">=</span> <span class="dv" style="color: #AD0000;">32500</span></span>
<span id="cb2-4">pA <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.1</span></span>
<span id="cb2-5">pB <span class="op" style="color: #5E5E5E;">=</span> <span class="fl" style="color: #AD0000;">0.0925</span></span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;"># Simulation</span></span>
<span id="cb2-8"><span class="kw" style="color: #003B4F;">def</span> simulate_experiment(pA, pB, N_per_group):</span>
<span id="cb2-9">    </span>
<span id="cb2-10">    df <span class="op" style="color: #5E5E5E;">=</span> pd.DataFrame({</span>
<span id="cb2-11">        <span class="st" style="color: #20794D;">"group"</span>:[<span class="st" style="color: #20794D;">"A"</span>]<span class="op" style="color: #5E5E5E;">*</span>N <span class="op" style="color: #5E5E5E;">+</span> [<span class="st" style="color: #20794D;">"B"</span>]<span class="op" style="color: #5E5E5E;">*</span>N,</span>
<span id="cb2-12">        <span class="st" style="color: #20794D;">"convert"</span>:np.r_[</span>
<span id="cb2-13">             np.random.binomial(<span class="dv" style="color: #AD0000;">1</span>, p<span class="op" style="color: #5E5E5E;">=</span>pA, size<span class="op" style="color: #5E5E5E;">=</span>N),</span>
<span id="cb2-14">             np.random.binomial(<span class="dv" style="color: #AD0000;">1</span>, p<span class="op" style="color: #5E5E5E;">=</span>pB, size<span class="op" style="color: #5E5E5E;">=</span>N)</span>
<span id="cb2-15">        ]</span>
<span id="cb2-16">    })</span>
<span id="cb2-17">    </span>
<span id="cb2-18">    <span class="cf" style="color: #003B4F;">return</span> df</span>
<span id="cb2-19"></span>
<span id="cb2-20">df <span class="op" style="color: #5E5E5E;">=</span> simulate_experiment(pA, pB, N)</span></code></pre></div>
</details>
<p><br></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/uncertainty_fig1.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Looking at the data above, we’re seeing a better conversion rate in group B. We run a two-proportions z-test and we find that there’s a non-significant p-value, meaning we found insufficient evidence of the variant having lower conversion than the control.</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="kw" style="color: #003B4F;">def</span> pval_from_summary(tab):</span>
<span id="cb3-2">    </span>
<span id="cb3-3">    _, pval <span class="op" style="color: #5E5E5E;">=</span> sm.stats.proportions_ztest(</span>
<span id="cb3-4">        count<span class="op" style="color: #5E5E5E;">=</span>tab[<span class="st" style="color: #20794D;">"converts"</span>][::<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>], </span>
<span id="cb3-5">        nobs<span class="op" style="color: #5E5E5E;">=</span>tab[<span class="st" style="color: #20794D;">"N"</span>][::<span class="op" style="color: #5E5E5E;">-</span><span class="dv" style="color: #AD0000;">1</span>],</span>
<span id="cb3-6">        alternative<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"smaller"</span></span>
<span id="cb3-7">    )</span>
<span id="cb3-8">    <span class="cf" style="color: #003B4F;">return</span> pval</span>
<span id="cb3-9"></span>
<span id="cb3-10">(df.pipe(summarize_experiment)</span>
<span id="cb3-11">   .pipe(pval_from_summary))</span></code></pre></div>
<p><img src="https://latex.codecogs.com/png.latex?%20p%20=%200.38%20"></p>
<p>We recommend to our stakeholders to roll out the variant since it “does no harm”</p>
<p><strong>There are some serious red flags here</strong></p>
<ul>
<li>First of all, p-values are all about the null hypothesis. So just because we don’t find a significant drop in conversion rate, that doesnt mean one doesnt exist. It just means we didnt find evidence for it in this test</li>
<li>There was no visualization of the uncertainty in the result</li>
</ul>
</section>
</section>
<section id="understanding-uncertainty-with-the-beta-distribution" class="level2">
<h2 class="anchored" data-anchor-id="understanding-uncertainty-with-the-beta-distribution">Understanding Uncertainty with the Beta Distribution</h2>
<p>For binary outcomes, the beta distribution is highly effective for understanding uncertainty.</p>
<p>It has 2 parameters * <strong>alpha</strong>, the number of successes * <strong>beta</strong>, the number of failures</p>
<p>It’s output is easy to interpret: Its a distribution of plausible probabilities that lead to the outcome.</p>
<p>So we can simply count our successes and failures from out observed data, plug it into a beta distribution to simulate outcomes, and visualize it as a density plot to understand uncertainty</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/uncertainty_fig2.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>It’s also easy to work with - if we want to understand the plausible differences between groups, we can just take the differences in our estimates</p>
<p><img src="https://latex.codecogs.com/png.latex?%0A%5Cdelta%20=%20%5Chat%7Bp_B%7D%20-%20%5Chat%7Bp_A%7D%0A"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/uncertainty_fig3.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>With visualization, we get a very different picture than our non-significant p-value. We see that there’s plenty of plausibility that the control could be worse.</p>
<p>We can further calculate the probability of a drop, <img src="https://latex.codecogs.com/png.latex?P(B%20%3C%20A)">, and find that theres a greater than 60% probability that the variant is worse than the control</p>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="co" style="color: #5E5E5E;"># P(B &lt; A)</span></span>
<span id="cb4-2">(pB_hat <span class="op" style="color: #5E5E5E;">&lt;</span> pA_hat).mean()</span></code></pre></div>
<p><img src="https://latex.codecogs.com/png.latex?%0AP(B%20%3C%20A)%20=%200.62%0A"></p>
<p>Remember when we designed the experiment? Considering our main goal was to do no harm, we might not feel so confident in that now, and rightly so, we know the variants worse since we simulated it.</p>
<p>Unless we feel very confident in our choice of testing for a 1/2% drop and know that we can afford anything up to that, then we we really shouldnt roll out this variant without further evaluation</p>
<p>This is particularly important with higher uncertainty As we can see in the example below, where the observed conversion rate is better in the variant, but the downside risk is as high as a 4% drop in conversion rate</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/uncertainty_fig4.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p><img src="https://latex.codecogs.com/png.latex?%0Ap%20=%200.59%0A"></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/uncertainty_fig5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="another-example-which-metric" class="level1">
<h1>Another Example: Which Metric?</h1>
<p>This is a fun problem from <a href="https://twitter.com/seanjtaylor"><span class="citation" data-cites="seanjtaylor">@seanjtaylor</span></a> &gt; “You run a product test and measure a strong positive effect on your first metric.</p>
<blockquote class="blockquote">
<p>Metric 1: +1% (p&lt;.01)</p>
</blockquote>
<blockquote class="blockquote">
<p>You also see a negative, but not significant result on equally important Metric 2. You only care about these two metrics. Which of these estimates would you prefer to ship?”</p>
</blockquote>
<blockquote class="blockquote">
<ol type="1">
<li><input type="checkbox" unchecked=""> Metric 2: -0.5% (p = 0.10)</li>
<li><input type="checkbox" unchecked=""> Metric 2: -0.5% (p=0.45)</li>
<li><input type="checkbox" unchecked=""> Neither is shippable</li>
</ol>
</blockquote>
<p><br></p>
<p><em>Try to think it through on your own first, then scroll down for the answer</em></p>
<p><br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br> <br></p>
<p>If you chose option 2, you weren’t alone. Option 1 makes it seem like there’s a more likely negative effect due to the lower p-value, so thats worse, right?</p>
<p>Not quite. Check out the uncertainties. The downside risk option 2 is much worse than option 1.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/uncertainty_fig6.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>We can take this one step further and add our effects to compare (remember we assumed the metrics are equally important), and see if it’s overall net positive</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/uncertainty_fig7.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>As shown above, the non significant p value option has a higher probability of being negative, AND it gives more plausibility to more negative possible effects</p>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<p>Always report uncertainty intervals - p-values definitely dont tell the whole story, even with well designed experiments. As we saw, ignoring uncertainty can expose ourselves to high downside, especially when our choice in experiment design has even the slightest bit of arbitrary choices involved (such as an arbitrary minimum detectable effecs)</p>
<p>Reporting uncertainty intervals or beta distributions (or even bootstrapping) can be a great way to avoid falling for this mistake</p>


</section>

 ]]></description>
  <guid>https://github.com/kylejcaron/kylejcaron.github.io/posts/2022-04-11-uncertainty_intervals_over_pvals.html</guid>
  <pubDate>Mon, 11 Apr 2022 04:00:00 GMT</pubDate>
  <media:content url="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/uncertainty_fig1.png" medium="image" type="image/png" height="60" width="144"/>
</item>
<item>
  <title>Explainable AI is not Causal Inference</title>
  <link>https://github.com/kylejcaron/kylejcaron.github.io/posts/2022-04-03-explainable-ai-is-not-causal.html</link>
  <description><![CDATA[ 




<p>Explainable AI is all the rage these days. Black box ML models come along with some fun tools such as LIME, SHAP, or Partial Depence Plots that try to give visibility into how the model is interpreting data and making predictions. It’s a common misconception that these are causal inference techniques - sadly we’ve all been mislead.</p>
<p>We’re going to walk through an example that shows these tools fall victim to the same rules of causal inference as everything else. A confound is still a confound, and if you want to measure some causal effect there’s still no way around that without careful deliberation of which variables to include in your models.</p>
<p>The code for this blogpost can be found <a href="https://github.com/kylejcaron/case_studies/blob/master/Explainable%20AI%20vs%20Causal%20Inference.ipynb">here</a></p>
<section id="starting-simple-simulating-some-fake-data" class="level1">
<h1>Starting simple: simulating some fake data</h1>
<p>Let’s start with a simple scenario. Our goal is to estimate some causal effects. We’re going to simulate out data ourself so we know the true causal effects. We can see how good some popular “explainable AI” algorithms actually are at causal inference. We’ll simulate data from the following DAG:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/explainable_ai_dag1.png" class="img-fluid figure-img"></p>
</figure>
</div>
<hr>
<p><strong>What’s a DAG?</strong> A dag is a directed acyclic graph, or fancy talk for a flowchart that goes in 1 direction. It’s really just a diagram of a true data generating process. <strong>They’re typically assumed based on domain knowledge</strong> (like all models), although ocassionally there are some validation checks you can perform.</p>
<p>Edges in the graph are assumed to be true causal effects. So for example,</p>
<ul>
<li><code>X3</code> influences <code>Y</code></li>
<li><code>X5</code> influences <code>X1</code> which influences <code>Y</code></li>
<li>Some unobserved variable <code>U</code> influences both <code>X1</code> and <code>Y</code>. By unobserved, what I mean is that its some variable we don’t have data for.</li>
</ul>
<p>For those familiar with causal inference, this DAG in particular is also riddled with confounds.</p>
<hr>
<p>Ok back on track. We’ll get out one of the more popular Explainable AI tools nowadays, <code>XGBoost</code>. I’m going to start in the most dangerous way possible - I’m going to toss everything in the model.</p>
</section>
<section id="test-1-whats-the-impact-of-x1-on-y" class="level1">
<h1>Test 1: What’s the impact of X1 on Y?</h1>
<p>We know for a fact that X1 influences Y. Let’s see how well Partial Dependence Plots and SHAP values do at identifying the true causal effect</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/explainable_ai_fig2.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>These SHAP values arent just wrong, but the effect is in the wrong direction. The reason for this: there’s a <strong>Fork Confound.</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/explainable_ai_fig3.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Some variable <code>Z</code> confounds <code>X</code>s true effect on <code>Y</code>.</p>
<blockquote class="blockquote">
<p>A very common example of a fork confound is <code>warm weather (Z)</code> on the relationship between <code>ice cream sales (X)</code> and <code>crime (Y)</code>. Ice cream sales obviously have no influence on crime, but ice cream sales are higher during warmer weather, and crime is higher during warmer weather.</p>
</blockquote>
<p>So back to our main point - Explainable AI can’t get around a fork confound. This is our first lesson on why SHAP / explainable AI is different from causal inference.</p>
<p>Luckily in this case, statistics can solve this problem.</p>
<p>Using some domain knowledge about the generating process, we notice an instrument, <code>X5</code>, that can be used to estimate the causal effect of <code>X1</code> on <code>Y</code></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/explainable_ai_fig4.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>I won’t go into the details of instrumental variable analysis since the goal of this article is to highlight that Explainable AI can’t replace causal inference. To learn more about it, see <a href="https://mixtape.scunning.com/instrumental-variables.html?panelset=python-code&amp;panelset1=python-code2">Scott Cunningham’s Causal Inference the Mixtape</a>.</p>
<p>But for now, I will show that a classic causal inference method succeeds where XGBoost and SHAP values fail</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;">from</span> linearmodels <span class="im" style="color: #00769E;">import</span> IV2SLS</span>
<span id="cb1-2"><span class="im" style="color: #00769E;">from</span> src.dagtools <span class="im" style="color: #00769E;">import</span> get_effect</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="co" style="color: #5E5E5E;"># Instrumental variable analysis</span></span>
<span id="cb1-5">iv_model <span class="op" style="color: #5E5E5E;">=</span> IV2SLS.from_formula(<span class="st" style="color: #20794D;">"Y ~ 1 + [X1 ~ X5]"</span>, data<span class="op" style="color: #5E5E5E;">=</span>df).fit()</span>
<span id="cb1-6"></span>
<span id="cb1-7"><span class="co" style="color: #5E5E5E;"># pull true effect</span></span>
<span id="cb1-8">true_effect <span class="op" style="color: #5E5E5E;">=</span> get_effect(DAG, <span class="st" style="color: #20794D;">"X1"</span>, <span class="st" style="color: #20794D;">"Y"</span>)</span>
<span id="cb1-9"></span>
<span id="cb1-10"><span class="co" style="color: #5E5E5E;"># Plot</span></span>
<span id="cb1-11">fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">1</span>,figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">6</span>,<span class="dv" style="color: #AD0000;">4</span>))</span>
<span id="cb1-12">ax.set_title(<span class="st" style="color: #20794D;">"Instrumental Variable Analysis</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">Recovers True effect"</span>)</span>
<span id="cb1-13">plot_model_estimate(iv_model, true_effect<span class="op" style="color: #5E5E5E;">=</span>true_effect, feat<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"X1"</span>, ax<span class="op" style="color: #5E5E5E;">=</span>ax)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/explainable_ai_fig5.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>As we can see, a simple statistics technique succeeds where explainable AI fails.</p>
</section>
<section id="what-about-estimating-the-effect-of-x4-on-y" class="level1">
<h1>What about estimating the effect of X4 on Y?</h1>
<p>This relationship is slightly more complicated, but certainly measurable. <code>X4</code> influences <code>X2</code> which influences <code>Y</code>. Here’s the DAG again for reference</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/explainable_ai_dag1.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>The plots below show how well explainable AI does at estimating the causal effect of this relationship.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/explainable_ai_fig6.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>Unfortunately, they don’t pick up an effect at all! And if our goal was to increase <code>Y</code> we’d end up missing a pretty good lever for it. There’s another simple explanation here for why explainable AI: there’s a <strong>Pipe Confound</strong></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/explainable_ai_fig7.png" class="img-fluid figure-img"></p>
</figure>
</div>
<p>When trying to measure the effect of <code>X -&gt; Y</code>, conditioning on <code>Z</code> (aka including it in a model as a covariate with X) ends up blocking inference.</p>
<p>For more details on how a Pipe confound works, I recommend chapters 5 and 6 of <a href="https://xcelab.net/rm/statistical-rethinking/">Richard McElreath’s Statistical Rethinking v2</a> (where I borrowed the example from as well).</p>
<p>The main things to note here are that pipes are common and Explainable AI doesn’t get around them.</p>
<p>We can recover an unbiased estimate of the true effect simply with OLS</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="co" style="color: #5E5E5E;"># Fit simple OLS model</span></span>
<span id="cb2-2">model <span class="op" style="color: #5E5E5E;">=</span> sm.OLS.from_formula(<span class="st" style="color: #20794D;">"Y ~ X4"</span>, data<span class="op" style="color: #5E5E5E;">=</span>df).fit()</span>
<span id="cb2-3"></span>
<span id="cb2-4"><span class="co" style="color: #5E5E5E;"># pull true effect</span></span>
<span id="cb2-5">true_effect <span class="op" style="color: #5E5E5E;">=</span> get_effect(DAG, <span class="st" style="color: #20794D;">"X4"</span>, <span class="st" style="color: #20794D;">"X2"</span>) <span class="op" style="color: #5E5E5E;">*</span> get_effect(DAG, <span class="st" style="color: #20794D;">"X2"</span>, <span class="st" style="color: #20794D;">"Y"</span>)</span>
<span id="cb2-6"></span>
<span id="cb2-7"><span class="co" style="color: #5E5E5E;"># Plot (see notebok for plot_model_estimate function)</span></span>
<span id="cb2-8">fig, ax <span class="op" style="color: #5E5E5E;">=</span> plt.subplots(<span class="dv" style="color: #AD0000;">1</span>,<span class="dv" style="color: #AD0000;">1</span>,figsize<span class="op" style="color: #5E5E5E;">=</span>(<span class="dv" style="color: #AD0000;">6</span>,<span class="dv" style="color: #AD0000;">4</span>))</span>
<span id="cb2-9">ax.set_title(<span class="st" style="color: #20794D;">"Instrumental Variable Analysis</span><span class="ch" style="color: #20794D;">\n</span><span class="st" style="color: #20794D;">Recovers True effect"</span>)</span>
<span id="cb2-10">plot_model_estimate(model, true_effect<span class="op" style="color: #5E5E5E;">=</span>true_effect, feat<span class="op" style="color: #5E5E5E;">=</span><span class="st" style="color: #20794D;">"X4"</span>, ax<span class="op" style="color: #5E5E5E;">=</span>ax)</span></code></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/explainable_ai_fig8.png" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="can-we-use-explainable-ai-for-causal-inference-at-all" class="level1">
<h1>Can we use Explainable AI for causal inference at all?</h1>
<p>We can! We just need to be deliberate in which variables we include in our models, and the only way to do that right is to use DAGs! The example below looks at an XGBoost model that doesnt condition on <code>X2</code> (allowing us to estimate the causal effect of <code>X4 -&gt; Y</code>).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/explainable_ai_fig9.png" class="img-fluid figure-img"></p>
</figure>
</div>
</section>
<section id="take-aways" class="level1">
<h1>Take Aways</h1>
<p>Explainable AI is not some magic tool for causal inference. What these tools are good at is explaining why complicated models make the decisions they do. Explainable AI tools suffer from the same limitations for causal inference as all other statistical estimators.</p>
<p>At the end of the day when causal inference is your goal, nothing beats using DAGs to inform deliberate variable selection.</p>
<p>If you’re new to the subject, I highly recommend the following resources that will teach you how to use causal inference properly:</p>
<ul>
<li>Chapter’s 5 and 6 of Statistical Rethinking v2, by Richard McElreath</li>
<li>Causal Inference for the Brave and True by Matheus Facure</li>
<li>Causal Inference the Mixtape, by Scott Cunningham</li>
</ul>


</section>

 ]]></description>
  <guid>https://github.com/kylejcaron/kylejcaron.github.io/posts/2022-04-03-explainable-ai-is-not-causal.html</guid>
  <pubDate>Sun, 03 Apr 2022 04:00:00 GMT</pubDate>
  <media:content url="https://github.com/kylejcaron/kylejcaron.github.io/assets/img/explainable_ai_dag1.png" medium="image" type="image/png" height="101" width="144"/>
</item>
</channel>
</rss>
