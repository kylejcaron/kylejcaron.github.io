<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.163">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-09-19">

<title>Kyle Caron - A Quick Introduction to Experiment Designs in Industry</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script src="../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">


<link rel="stylesheet" href="../theme.scss">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Kyle Caron</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../blog.html">Blog</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/kylejcaron"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">A Quick Introduction to Experiment Designs in Industry</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">experimentation</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">2022-09-19</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#designing-experiments-with-stakeholders" id="toc-designing-experiments-with-stakeholders" class="nav-link active" data-scroll-target="#designing-experiments-with-stakeholders">Designing experiments with stakeholders</a></li>
  <li><a href="#why-do-experiments-matter" id="toc-why-do-experiments-matter" class="nav-link" data-scroll-target="#why-do-experiments-matter">Why do experiments matter?</a></li>
  <li><a href="#getting-buy-in" id="toc-getting-buy-in" class="nav-link" data-scroll-target="#getting-buy-in">Getting buy in</a>
  <ul class="collapse">
  <li><a href="#convincing-other-teams-to-start-experimenting-properly" id="toc-convincing-other-teams-to-start-experimenting-properly" class="nav-link" data-scroll-target="#convincing-other-teams-to-start-experimenting-properly">Convincing other teams to start experimenting properly</a></li>
  </ul></li>
  <li><a href="#desigining-the-experiment" id="toc-desigining-the-experiment" class="nav-link" data-scroll-target="#desigining-the-experiment">Desigining the experiment</a></li>
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#fundamentals-of-good-experiment-design" id="toc-fundamentals-of-good-experiment-design" class="nav-link" data-scroll-target="#fundamentals-of-good-experiment-design">Fundamentals of good experiment design</a></li>
  <li><a href="#randomized-controlled-experiments" id="toc-randomized-controlled-experiments" class="nav-link" data-scroll-target="#randomized-controlled-experiments">Randomized Controlled Experiments</a>
  <ul class="collapse">
  <li><a href="#the-ab-test" id="toc-the-ab-test" class="nav-link" data-scroll-target="#the-ab-test">The A/B Test</a>
  <ul class="collapse">
  <li><a href="#varying-the-bucketing-allocation" id="toc-varying-the-bucketing-allocation" class="nav-link" data-scroll-target="#varying-the-bucketing-allocation">Varying the bucketing allocation</a></li>
  <li><a href="#running-multiple-experiments-concurrently" id="toc-running-multiple-experiments-concurrently" class="nav-link" data-scroll-target="#running-multiple-experiments-concurrently">Running Multiple Experiments Concurrently</a></li>
  </ul></li>
  <li><a href="#the-abn-test" id="toc-the-abn-test" class="nav-link" data-scroll-target="#the-abn-test">The A/B/n test</a></li>
  <li><a href="#the-multivariate-test" id="toc-the-multivariate-test" class="nav-link" data-scroll-target="#the-multivariate-test">The Multivariate Test</a></li>
  <li><a href="#bandit-optimization" id="toc-bandit-optimization" class="nav-link" data-scroll-target="#bandit-optimization">Bandit Optimization</a></li>
  </ul></li>
  <li><a href="#quasi-experiments" id="toc-quasi-experiments" class="nav-link" data-scroll-target="#quasi-experiments">Quasi-Experiments</a>
  <ul class="collapse">
  <li><a href="#interrupted-time-series" id="toc-interrupted-time-series" class="nav-link" data-scroll-target="#interrupted-time-series">Interrupted Time Series</a></li>
  <li><a href="#regression-discontinuity-design" id="toc-regression-discontinuity-design" class="nav-link" data-scroll-target="#regression-discontinuity-design">Regression Discontinuity Design</a></li>
  </ul></li>
  <li><a href="#overview-1" id="toc-overview-1" class="nav-link" data-scroll-target="#overview-1">Overview</a></li>
  <li><a href="#randomized-controlled-experiments-1" id="toc-randomized-controlled-experiments-1" class="nav-link" data-scroll-target="#randomized-controlled-experiments-1">Randomized Controlled Experiments</a>
  <ul class="collapse">
  <li><a href="#the-ab-test-1" id="toc-the-ab-test-1" class="nav-link" data-scroll-target="#the-ab-test-1">The A/B Test</a>
  <ul class="collapse">
  <li><a href="#varying-the-bucketing-allocation-1" id="toc-varying-the-bucketing-allocation-1" class="nav-link" data-scroll-target="#varying-the-bucketing-allocation-1">Varying the bucketing allocation</a></li>
  <li><a href="#running-multiple-experiments-concurrently-1" id="toc-running-multiple-experiments-concurrently-1" class="nav-link" data-scroll-target="#running-multiple-experiments-concurrently-1">Running Multiple Experiments Concurrently</a></li>
  </ul></li>
  <li><a href="#the-abn-test-1" id="toc-the-abn-test-1" class="nav-link" data-scroll-target="#the-abn-test-1">The A/B/n test</a></li>
  <li><a href="#the-multivariate-test-1" id="toc-the-multivariate-test-1" class="nav-link" data-scroll-target="#the-multivariate-test-1">The Multivariate Test</a></li>
  <li><a href="#bandit-optimization-1" id="toc-bandit-optimization-1" class="nav-link" data-scroll-target="#bandit-optimization-1">Bandit Optimization</a></li>
  </ul></li>
  <li><a href="#quasi-experiments-1" id="toc-quasi-experiments-1" class="nav-link" data-scroll-target="#quasi-experiments-1">Quasi-Experiments</a>
  <ul class="collapse">
  <li><a href="#interrupted-time-series-1" id="toc-interrupted-time-series-1" class="nav-link" data-scroll-target="#interrupted-time-series-1">Interrupted Time Series</a></li>
  <li><a href="#regression-discontinuity-design-1" id="toc-regression-discontinuity-design-1" class="nav-link" data-scroll-target="#regression-discontinuity-design-1">Regression Discontinuity Design</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="designing-experiments-with-stakeholders" class="level1">
<h1>Designing experiments with stakeholders</h1>
<p>Randomized controlled experiments are gold standard for inference, allowing companies to make the best decisions possible. As a data scientist, you’ll often find yourself in a position where a stakeholder wants to improve some metric and they have a new feature to get them there; your job will often be to make sure that the feature actually has a positive impact on the business.</p>
<p>The problem is there’s alway a catch - there’s always some deadline to be met or some shortage in sample size or some trade-off to be made, and in order to instill confidence in stakeholders and gain trust from the business you need to prove you’re able to adapt and recommend useful experiments.</p>
<p>It’s only once the business has started to build trust in an experimentation team (and the costs that come with it), that you can start to push the envelope and begin adding larger value to the company like optimizing experiment duration, personalizing feature roll outs, and even recommending product features and interventions to test.</p>
<p>While you can simply pick up a book to learn a T-Test, there’s no book out there that tells you how to work with stakeholders. But <em>maybe</em> hearing someone elses experience with it could help. So here it is - how do we design simple and effective experiments with stakeholders?</p>
</section>
<section id="why-do-experiments-matter" class="level1">
<h1>Why do experiments matter?</h1>
<p>Let’s start at our most basic assumption - why do experiments matter? At the end of the day, what really matters is company results, but experiments are an extremely valuable tool to make sure results are going in the right direction.</p>
<p>The best way to explain why experiments matter is with anecdotes. Let’s say you’re trying to improve conversion rate, and you have a new website feature that you think will help. What if you don’t experiment? You roll it out to production so that 100% of your customer’s are exposed to the feature, and you check out your dashboard a month later and see that you’re conversion metric is 5% higher than a month before. So it worked right?</p>
<p>Not necessarily - and rarely will you get such a clean answer watching a metric time series. What if you had an effective marketing campaign in the last month that brought in really high quality leads? And what if conversion rate happens to be seasonally better this month than the prior month? Than</p>
</section>
<section id="getting-buy-in" class="level1">
<h1>Getting buy in</h1>
<p>In my experience, I’ve typically found myself in 3 types of situations that are opportunities for experiments:</p>
<ol type="1">
<li>Someone comes to you because they want to see if their feature improves the business (great!)</li>
<li>You notice other teams want to roll out a feature and their measurement plan will lead them to a mis-represented understanding of the impact (not so great)</li>
<li>You notice other teams are rolling out features with a mis-represented understanding of the impact (dangerous)</li>
</ol>
<p>If you find yourself in the first category, then great you’ve got a much easier road ahead of you. But it’s not always that easy. Unless you’re at a very mature org, you’re likely going to see situations 2 and 3 happening more than you’d like. But that’s ok, those are opportunities to teach teams why experimentation is so important.</p>
<section id="convincing-other-teams-to-start-experimenting-properly" class="level2">
<h2 class="anchored" data-anchor-id="convincing-other-teams-to-start-experimenting-properly">Convincing other teams to start experimenting properly</h2>
<p>What do you do if you see a plan to roll out a feature?</p>
<p>Let’s not forget that experimentation is slow and can be expensive early on at a company. It only makes sense that many teams at early stage companies find themselves making common sense and qualitatively informed decisions and hopefully watching time series of their metrics grow over time. So don’t get mad at teams for still making uncontrolled decisions. A goal for experiment teams should be to build a culture of quantitative decision making throughout the company, and to do that you need other teams to want to work with you.</p>
</section>
</section>
<section id="desigining-the-experiment" class="level1">
<h1>Desigining the experiment</h1>
<p>You’ve got buy in, you’ve got other teams coming to you - now what?</p>
<ol type="1">
<li>Listen to the company’s needs</li>
<li>Know your options</li>
<li>Make a recommendation</li>
<li>Compromise</li>
</ol>
</section>
<section id="overview" class="level1">
<h1>Overview</h1>
<p>This post will go over some important considerations for designing an A/B test and how to get started. It will cover</p>
<ul>
<li>The research question</li>
<li>The tech stack</li>
<li>The experiment design itself</li>
<li>Experiment Monitoring</li>
<li>Reporting Results</li>
<li>Rolling out your variant</li>
<li>Secondary Analysis</li>
</ul>
<p>This is going to assume you have a basic understanding of statistics.</p>
</section>
<section id="fundamentals-of-good-experiment-design" class="level1">
<h1>Fundamentals of good experiment design</h1>
<ul>
<li>The research question can be clearly answered by the experiment results</li>
<li>The experiment results are actionable</li>
<li>The measured effect of the experiment is consistent with the effect you’d see if you rolled out your treatment into production</li>
<li>Effects of one treatment group are independent of the other treatment group(s)</li>
<li>The measured observable effect of the experiment is equivalent to the true average treatment effect</li>
<li>The outcome of the experiment isn’t gameable.</li>
</ul>
</section>
<section id="randomized-controlled-experiments" class="level1">
<h1>Randomized Controlled Experiments</h1>
<section id="the-ab-test" class="level2">
<h2 class="anchored" data-anchor-id="the-ab-test">The A/B Test</h2>
<p>This design is the most common experiment you’ll see. Let’s say you want to test the impact of a new checkout page. You simply send half of your web traffic randomly to your current checkout page, and half of your traffic to the new variant checkout page.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-1">flowchart TB
  A[Web Traffic] --&gt; B{Randomize}
  B --50%--&gt; D[A]
  B --50%--&gt;  E[B]
</pre>
<div id="mermaid-tooltip-1" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<p>This allows you to have a clean comparison between groups that aligns with the average treatment effect.</p>
<section id="varying-the-bucketing-allocation" class="level3">
<h3 class="anchored" data-anchor-id="varying-the-bucketing-allocation">Varying the bucketing allocation</h3>
<p>You also don’t need to use a %50/%50 split in traffic. You could use 90/10 allocation for instance, or 60/40. Just note that having unequal bucketing allocation requires more sample size. This is because one group ends up with less traffic and is therefore less precise, making it more difficult to rule out noise. You also shouldn’t change bucketing allocation throughout the experiment, it should stay consistent throughout, or you could end up with a biased result. You can of course correct for this, but simpler experiments are always better.</p>
</section>
<section id="running-multiple-experiments-concurrently" class="level3">
<h3 class="anchored" data-anchor-id="running-multiple-experiments-concurrently">Running Multiple Experiments Concurrently</h3>
<p>Running multiple experiments at the same time can lead to bias and confusion. That doesn’t mean we shouldn’t do it, but it does mean we should be careful about how we do it.</p>
<p>One of the key tenants of an A/B test is that the Treatment Effect you measure in your experiment is the same lift you’d see if you were to roll out your winning variant to 100% of your web traffic. Non-representative sample bias is a common consequence of running concurrent experiments that can lead to this.</p>
</section>
</section>
<section id="the-abn-test" class="level2">
<h2 class="anchored" data-anchor-id="the-abn-test">The A/B/n test</h2>
<p>This design is the same as an A/B test, but involves n total experiment variants, instead of just 2.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-2">flowchart TB
  A[Web Traffic] --&gt; B{Randomize}
  B --33%--&gt; D[A]
  B --33%--&gt;  E[B]
  B --33%--&gt; F[C]
  B --33%--&gt; G[D]
</pre>
<div id="mermaid-tooltip-2" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="the-multivariate-test" class="level2">
<h2 class="anchored" data-anchor-id="the-multivariate-test">The Multivariate Test</h2>
</section>
<section id="bandit-optimization" class="level2">
<h2 class="anchored" data-anchor-id="bandit-optimization">Bandit Optimization</h2>
</section>
</section>
<section id="quasi-experiments" class="level1">
<h1>Quasi-Experiments</h1>
<section id="interrupted-time-series" class="level2">
<h2 class="anchored" data-anchor-id="interrupted-time-series">Interrupted Time Series</h2>
</section>
<section id="regression-discontinuity-design" class="level2">
<h2 class="anchored" data-anchor-id="regression-discontinuity-design">Regression Discontinuity Design</h2>
<ul>
<li>A/B</li>
<li>A/B/C</li>
<li>Interrupted Time Series</li>
<li>Regression Discontinuity</li>
<li>IPSW</li>
</ul>
</section>
</section>
<section id="overview-1" class="level1">
<h1>Overview</h1>
<p>This post will go over some common experiment designs in industry and important aspects to consider when designing an experiment.</p>
</section>
<section id="randomized-controlled-experiments-1" class="level1">
<h1>Randomized Controlled Experiments</h1>
<section id="the-ab-test-1" class="level2">
<h2 class="anchored" data-anchor-id="the-ab-test-1">The A/B Test</h2>
<p>This design is the most common experiment you’ll see. Let’s say you want to test the impact of a new checkout page. You simply send half of your web traffic randomly to your current checkout page, and half of your traffic to the new variant checkout page.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-3">flowchart TB
  A[Web Traffic] --&gt; B{Randomize}
  B --50%--&gt; D[A]
  B --50%--&gt;  E[B]
</pre>
<div id="mermaid-tooltip-3" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
<p>This allows you to have a clean comparison between groups that aligns with the average treatment effect.</p>
<section id="varying-the-bucketing-allocation-1" class="level3">
<h3 class="anchored" data-anchor-id="varying-the-bucketing-allocation-1">Varying the bucketing allocation</h3>
<p>You also don’t need to use a %50/%50 split in traffic. You could use 90/10 allocation for instance, or 60/40. Just note that having unequal bucketing allocation requires more sample size. This is because one group ends up with less traffic and is therefore less precise, making it more difficult to rule out noise. You also shouldn’t change bucketing allocation throughout the experiment, it should stay consistent throughout, or you could end up with a biased result. You can of course correct for this, but simpler experiments are always better.</p>
</section>
<section id="running-multiple-experiments-concurrently-1" class="level3">
<h3 class="anchored" data-anchor-id="running-multiple-experiments-concurrently-1">Running Multiple Experiments Concurrently</h3>
<p>Running multiple experiments at the same time can lead to bias and confusion. That doesn’t mean we shouldn’t do it, but it does mean we should be careful about how we do it.</p>
<p>One of the key tenants of an A/B test is that the Treatment Effect you measure in your experiment is the same lift you’d see if you were to roll out your winning variant to 100% of your web traffic. Non-representative sample bias is a common consequence of running concurrent experiments that can lead to this.</p>
</section>
</section>
<section id="the-abn-test-1" class="level2">
<h2 class="anchored" data-anchor-id="the-abn-test-1">The A/B/n test</h2>
<p>This design is the same as an A/B test, but involves n total experiment variants, instead of just 2.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<p>
</p><pre class="mermaid" data-tooltip-selector="#mermaid-tooltip-4">flowchart TB
  A[Web Traffic] --&gt; B{Randomize}
  B --33%--&gt; D[A]
  B --33%--&gt;  E[B]
  B --33%--&gt; F[C]
  B --33%--&gt; G[D]
</pre>
<div id="mermaid-tooltip-4" class="mermaidTooltip">

</div>
<p></p>
</div>
</div>
</div>
</section>
<section id="the-multivariate-test-1" class="level2">
<h2 class="anchored" data-anchor-id="the-multivariate-test-1">The Multivariate Test</h2>
</section>
<section id="bandit-optimization-1" class="level2">
<h2 class="anchored" data-anchor-id="bandit-optimization-1">Bandit Optimization</h2>
</section>
</section>
<section id="quasi-experiments-1" class="level1">
<h1>Quasi-Experiments</h1>
<section id="interrupted-time-series-1" class="level2">
<h2 class="anchored" data-anchor-id="interrupted-time-series-1">Interrupted Time Series</h2>
</section>
<section id="regression-discontinuity-design-1" class="level2">
<h2 class="anchored" data-anchor-id="regression-discontinuity-design-1">Regression Discontinuity Design</h2>
<ul>
<li>A/B</li>
<li>A/B/C</li>
<li>Interrupted Time Series</li>
<li>Regression Discontinuity</li>
<li>IPSW</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>