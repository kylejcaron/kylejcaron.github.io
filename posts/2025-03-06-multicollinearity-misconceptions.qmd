---
layout: post
title:  "Common Misconceptions with Multicollinearity"
image: "../../assets/img/placeholder.png"
date: "2025-03-06"
categories:
 - multicollinearity
 - causal inference
 - regression
---


I recently saw a viral linkedin post discussing how multicollinearity will ruin your regression estimates. The solution? Simply throw out variables with high variance inflation factors and re-run your regression. 

Let me tell you, __don't do this__. A fear of multicollinearity is this misconception in data science that is far too prevalent. 

I've seen the same assumptions with correlation - if two variables are very highly correlated people assume they shouldn't be in the same model. I'm going to show you why 1) these approaches are a mistake and 2) you can't escape domain knowledge when informing your regression.

# A simulation

We're going to simulate a fake scenario. You want to know the effect of some variable $X_3$ on $y$ with your regression. The data generating process is below

```{dot}
digraph G {
  X1 -> X3 -> Y;
  X1 -> Y;
  X2 -> Y;
}
```

The simulation below makes it clear the true effect of $X_3$ on $y$ is 0.7, so we know our regression _should hopefully_ return it as an estimate

```{python}
import numpy as np
import pandas as pd
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor as vif
import matplotlib.pyplot as plt

N = 250
SIG = 0.5
TRUE_EFFECT = 0.7

rng = np.random.default_rng(99)
df = (
    pd.DataFrame({
    "x1":rng.normal(0, 1, size=N), 
    "x2":rng.normal(0, 1, size=N)}
    )
    # simulate x3 as a function of x1
    .assign(x3=lambda d: rng.normal(1.1 + d.x1*3.8, SIG))
    # simulate y as a function of x1,x2,x3
    .assign(y = lambda d: rng.normal(0.5 + d.x1*-4 + d.x2*-0.5 + d.x3*TRUE_EFFECT, SIG))
)
df.head()
```

Lets take a look at the variance inflation factors below

```{python}
X = df.filter(like='x')
pd.DataFrame(
    {"VIF": [vif(X.values, i) for i in range(X.shape[1])]}, 
    index=X.columns
).round(2)
```

Based on this, we supposedly should remove X1 from our regression (VIFs of 5-10 are considered high).

If we look at the correlation, we reach the same conclusions - x1 has high correlation with x3 so supposedly "they provide the same information and only 1 is useful"

```{python}
X.corr().loc['x3']
```

# Does it work?

We're going to fit two regressions - one that follows the advice of throwing out variables with high VIFs or correlation - and another that is informed by domain knowledge.

```{python}
# vif/correlation informed variable selection
m1 = sm.OLS.from_formula("y ~ x2 + x3", data=df).fit()

# domain knowledge informed variable selection
m2 = sm.OLS.from_formula("y ~ x1 + x2 + x3", data=df).fit()

def get_ci(model):
    lb = (model.params - model.bse*2)
    ub = model.params + model.bse*2
    return lb, ub

lb, ub = get_ci(m1)
plt.hlines(0, lb.loc['x3'], ub.loc['x3'], lw=2, label='VIF informed model', color='C1')
plt.scatter(m1.params.loc['x3'], 0, facecolor='white', edgecolor='C1', zorder=10, s=10)

lb, ub = get_ci(m2)
plt.hlines(1, lb.loc['x3'], ub.loc['x3'], lw=2, label='Causally informed model')
plt.scatter(m2.params.loc['x3'], 1, facecolor='white', edgecolor='C0',zorder=10, s=10)

plt.axvline(0, ls='--', color='k')
plt.axvline(TRUE_EFFECT, color='r', ls='--', lw=1, label='True Effect')
plt.xlim(-1, 1)
plt.ylim(-1,2)
plt.yticks([])
plt.title("Estimated effect of X3 -> y")
plt.xlabel("Beta Coefficient")
plt.legend()
plt.show()
```

Not only is the VIF informed model wrong, but more importantly it actually thinks x3 has a negative effect instead of a positive effect! 

# Why did this happen?

Lets go back to our data generating process

```{dot}
digraph G {
  X1 -> X3 -> Y;
  X1 -> Y;
  X2 -> Y;
}
```

It's clear that $X_1$ causally effects both $X_3$ and $y$ - this makes it a confounding variable, or a "backdoor" for $X_3$. If we want our regression to have proper estimates of $X_3$, we therefore need to make sure our regression model accounts for $X_1$ to de-bias $X_3$. 

This is why its so important to incorporate domain knowledge in your modeling. Mapping out the data generating process and using it to inform your model is always the right choice. For more on this check out [A Crash Course on Good and Bad Controls](https://ftp.cs.ucla.edu/pub/stat_ser/r493.pdf). I also really like Richard McElreath's discussion on this in his 2nd edition of Statistical Rethinking.
